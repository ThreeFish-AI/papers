# Introduction to Agents and Agent architectures
# 智能体和智能体架构导论

November 2025
2025年11月

2

## Acknowledgements
## 致谢

### Content contributors
### 内容贡献者

Enrique Chan
Mike Clark
Derek Egan
Anant Nawalgaria
Kanchana Patlolla
Julia Wiesinger

### Curators and editors
### 策展人和编辑

Anant Nawalgaria
Kanchana Patlolla

### Designer
### 设计师

Michael Lanning

---

## Table of contents
## 目录

<!-- Page 3 -->

### From Predictive AI to Autonomous Agents
### 从预测性AI到自主智能体
6

### Introduction to AI Agents
### AI智能体介绍
8

### The Agentic Problem-Solving Process
### 智能体问题解决过程
10

### A Taxonomy of Agentic Systems
### 智能体系统分类法
14

#### Level 0: The Core Reasoning System
#### 第0级：核心推理系统
15

#### Level 1: The Connected Problem-Solver
#### 第1级：连接的问题解决器
15

#### Level 2: The Strategic Problem-Solver
#### 第2级：战略性问题解决器
16

#### Level 3: The Collaborative Multi-Agent System
#### 第3级：协作多智能体系统
17

#### Level 4: The Self-Evolving System
#### 第4级：自我进化系统
18

### Core Agent Architecture: Model, Tools, and Orchestration
### 核心智能体架构：模型、工具和编排
19

#### Model: The "Brain" of your AI Agent
#### 模型：AI智能体的"大脑"
19

#### Tools: The "Hands" of your AI Agent
#### 工具：AI智能体的"双手"
20

#### Retrieving Information: Grounding in Reality
#### 检索信息：基于现实的 grounding
21

#### Executing Actions: Changing the World
#### 执行动作：改变世界
21

#### Function Calling: Connecting Tools to your Agent
#### 函数调用：将工具连接到您的智能体
22

<!-- Page 4 -->

### The Orchestration Layer
### 编排层
22

### Core Design Choices
### 核心设计选择
23

#### Instruct with Domain Knowledge and Persona
#### 使用领域知识和角色指令
23

#### Augment with Context
#### 使用上下文增强
24

### Multi-Agent Systems and Design Patterns
### 多智能体系统和设计模式
24

### Agent Deployment and Services
### 智能体部署和服务
26

### Agent Ops: A Structured Approach to the Unpredictable
### 智能体运维：应对不可预测性的结构化方法
27

#### Measure What Matters: Instrumenting Success Like an A/B Experiment
#### 测量重要指标：像A/B实验一样工具化成功
29

#### Quality Instead of Pass/Fail: Using a LM Judge
#### 质量而非通过/失败：使用语言模型评判器
29

#### Metrics-Driven Development: Your Go/No-Go for Deployment
#### 指标驱动开发：您部署的通过/不通过标准
30

#### Debug with OpenTelemetry Traces: Answering "Why?"
#### 使用OpenTelemetry跟踪进行调试：回答"为什么"
30

#### Cherish Human Feedback: Guiding Your Automation
#### 珍视人类反馈：指导您的自动化
31

### Agent Interoperability
### 智能体互操作性
31

#### Agents and Humans
#### 智能体与人类
32

#### Agents and Agents
#### 智能体与智能体
33

#### Agents and Money
#### 智能体与金钱
34

<!-- Page 5 -->

### Securing a Single Agent: The Trust Trade-Off
### 保护单个智能体：信任权衡
34

#### Agent Identity: A New Class of Principal
#### 智能体身份：新的主体类别
35

#### Policies to Constrain Access
#### 限制访问的策略
37

#### Securing an ADK Agent
### 保护ADK智能体
37

### Scaling Up from a Single Agent to an Enterprise Fleet
### 从单个智能体扩展到企业级智能体群
39

### Security and Privacy: Hardening the Agentic Frontier
### 安全与隐私：加固智能体前沿
40

### Agent Governance: A Control Plane instead of Sprawl
### 智能体治理：控制平面而非无序扩展
40

### How agents evolve and learn
### 智能体如何进化和学习
42

#### How agents learn and self evolve
#### 智能体如何学习和自我进化
43

#### Simulation and Agent Gym - the next frontier
#### 模拟和智能体训练场 - 下一个前沿
46

### Examples of advanced agents
### 高级智能体示例
47

#### Google Co-Scientist
#### Google合作科学家
47

#### AlphaEvolve Agent
#### AlphaEvolve智能体
49

### Conclusion
### 结论
51

### Endnotes
### 结束语
52

---

<!-- Page 7 -->

## From Predictive AI to Autonomous Agents
## 从预测性AI到自主智能体

它能够处理复杂的、多步骤的任务，这是单个模型无法做到的。关键能力是智能体可以自主工作，找出达到目标所需的下一步，而不需要一个人在每个转弯处指导它们。

本文档是五部分系列中的第一部分，作为从概念验证转向强大的、生产级智能体系统的开发者、架构师和产品负责人的正式指南。虽然构建简单的原型是直接的，但确保安全性、质量和可靠性是一个重大挑战。本文提供了一个全面的基础：

*   **核心解剖学**：将智能体分解为三个基本组成部分：推理模型、可执行工具和治理编排层。
*   **能力分类法**：将智能体从简单的、连接的问题解决器到复杂的、协作的多智能体系统进行分类。
*   **架构设计**：深入每个组件的实际设计考虑，从模型选择到工具实现。
*   **生产构建**：建立所需的智能体运维（Agent Ops）原则，用于评估、调试、保护和扩展智能体系统，从单个实例到具有企业治理的智能体群。

基于之前的《智能体白皮书》¹和《智能体伴侣》²；本指南提供了成功构建、部署和管理新一代智能应用程序所需的基础概念和战略框架，这些应用程序可以推理、行动和观察以完成目标³。

<!-- Page 8 -->

## Introduction to AI Agents
## AI智能体介绍

用言语来描述人类如何与AI互动是不足够的。我们倾向于拟人化并使用人类术语如"思考"和"推理"和"知道"。我们还没有词汇来区分"具有语义意义的知道"和"具有最大化奖励函数高概率的知道"。这是两种不同类型的知道，但99.X%的时间结果是相同的。

在最简单的术语中，AI智能体可以定义为模型、工具、编排层和运行时服务的组合，这些服务使用语言模型（LM）在循环中完成目标。这四个元素构成了任何自主系统的基本架构。

*   **模型（"大脑"）**：核心语言模型（LM）或基础模型，作为智能体的中央推理引擎来处理信息、评估选项和做出决策。模型的类型（通用、微调或多模态）决定了智能体的认知能力。智能体系统是语言模型输入上下文窗口的最终策展人。

*   **工具（"双手"）**：这些机制将智能体的推理与外部世界连接，实现超越文本生成的行动。它们包括API扩展、代码函数和数据存储（如数据库或向量存储），用于访问实时、事实信息。智能体系统允许语言模型计划使用哪些工具，执行工具，并将工具结果放入下一个语言模型调用的输入上下文窗口中。

*   **编排层（"神经系统"）**：管理智能体操作循环的治理过程。它处理计划、记忆（状态）和推理策略执行。该层使用提示框架和推理技术（如

<!-- Page 9 -->

思维链⁴或ReAct⁵）来将复杂目标分解为步骤，并决定何时思考与使用工具。该层还负责给智能体提供"记住"的记忆。

*   **部署（"身体和腿"）**：虽然在笔记本电脑上构建智能体对于原型制作是有效的，但生产部署使其成为可靠和可访问的服务。这涉及在安全、可扩展的服务器上托管智能体，并将其与必要的生产服务集成以进行监控、日志记录和管理。一旦部署，智能体可以通过图形界面被用户访问，或者通过智能体对智能体（A2A）API以编程方式被其他智能体访问。

归根结底，构建生成式AI智能体是开发解决方案以完成任务的新方式。传统开发者扮演"砌砖工"的角色，精确定义每个逻辑步骤。相比之下，智能体开发者更像导演。您不需要为每个动作编写显式代码，而是设置场景（指导指令和提示），选择演员（工具和API），并提供必要的上下文（数据）。主要任务变成指导这个自主"演员"提供预期的性能。

您很快会发现，语言模型的最大优势——其令人难以置信的灵活性——也是您最大的头痛。大型语言模型做任何事情的能力使得难以强制它可靠而完美地做一件特定的事情。我们过去称为"提示工程"而现在称为"上下文工程"引导语言模型生成所需的输出。对于语言模型的任何单次调用，我们输入我们的指令、事实、可调用的可用工具、示例、会话历史、用户配置文件等——用恰到好处的信息填充上下文窗口以获得我们需要的输出。智能体是管理语言模型输入以完成工作的软件。

当问题出现时，调试变得必不可少。"智能体运维"本质上重新定义了熟悉的测量、分析和系统优化循环。通过跟踪和日志，您可以监控智能体的"思维过程"以识别与预期执行路径的偏差。随着模型的演进和框架的改进，开发者的角色是提供

<!-- Page 10 -->

关键组件：领域专业知识、定义的人格，以及与实用任务完成所需工具的无缝集成。至关重要的是要记住，全面的评估和评估通常超过初始提示的影响。

当智能体精确配置了清晰的指令、可靠的工具和作为记忆的集成上下文、出色的用户界面、计划和解决问题的能力以及一般世界知识时，它超越了单纯"工作流自动化"的概念。它开始作为一个协作实体发挥作用：一个高度高效、独特适应和显著能力的新团队成员。

本质上，智能体是一个致力于上下文窗口策展艺术的系统。它是一个不懈的循环：组装上下文、提示模型、观察结果，然后为下一步重新组装上下文。上下文可能包括系统指令、用户输入、会话历史、长期记忆、来自权威来源的基础知识、可以使用什么工具以及已经调用的工具的结果。这种对模型注意力的复杂管理允许其推理能力为新情况解决问题并完成目标。

## The Agentic Problem-Solving Process
## 智能体问题解决过程

我们将AI智能体定义为完整的、目标导向的应用程序，集成推理模型、可执行工具和治理编排层。简短版本是"语言模型在循环中与工具一起完成目标"。

但这个系统实际上是如何工作的？智能体从接收请求到交付结果的时刻做了什么？

<!-- Page 11 -->

在其核心，智能体操作连续的、循环的过程以实现其目标。虽然这个循环可能变得高度复杂，但它可以分解为五个基本步骤，如《智能体系统设计》⁶一书中详细讨论的那样：

1.  **获取任务**：过程由特定的、高级别的目标发起。这个任务由用户（例如，"为我即将到来的会议组织团队旅行"）或自动化触发器（例如，"一个新的高优先级客户工单已到达"）提供。

2.  **扫描场景**：智能体感知其环境以收集上下文。这涉及编排层访问其可用资源："用户的请求说了什么？"、"我的术语记忆中有什么信息？我是否已经尝试过做这个任务？用户上周给了我指导吗？"、"我可以从我的工具访问什么，比如日历、数据库或API？"

3.  **深入思考**：这是智能体的核心"思考"循环，由推理模型驱动。智能体分析任务（步骤1）与场景（步骤2）并制定计划。这不是单个思考，而通常是推理链："要预订旅行，我首先需要知道团队中有谁。我将使用get_team_roster工具。然后我需要通过calendar_api检查他们的可用性。"

4.  **采取行动**：编排层执行计划的具体第一步。它选择并调用适当的工具——调用API、运行代码函数或查询数据库。这是智能体超越其自身内部推理对世界采取行动。

5.  **观察和迭代**：智能体观察其行动的结果。get_team_roster工具返回五个名字的列表。这个新信息被添加到智能体的上下文或"记忆"中。然后循环重复，返回到步骤3："既然我已经有了名单，我的下一步是检查这五个人的日历。我将使用calendar_api。"

<!-- Page 12 -->

这个"思考、行动、观察"循环继续——由编排层管理、由模型推理、由工具执行——直到智能体的内部计划完成且初始任务实现。

**图1：智能体AI问题解决过程**
![图1：智能体AI问题解决过程](images/figure_1_agentic_ai_problem_solving_process.png)

让我们以客户支持智能体如何在这个5步骤循环中操作为例：

想象用户询问，"我的订单#12345在哪里？"

<!-- Page 13 -->

与其立即行动，智能体首先进入其"深入思考"阶段以制定完整的策略。它推理：

"用户想要配送状态。要提供完整的答案，我需要多步骤计划：
1.  **识别**：我必须首先在我们的内部数据库中找到订单以确认其存在并获取其详细信息。
2.  **跟踪**：从那些详细信息中，我需要提取运输承运商的跟踪号码。然后，我将查询外部承运商API获取实时状态。
3.  **报告**：最后，我必须将我收集的信息合成为对用户清晰、有用的回应。"

有了这个多步骤计划，智能体开始执行。

在其第一个"行动"阶段，它执行其计划的第一步，调用find_order("12345")工具。它观察结果——一个完整的订单记录，包括跟踪号码"ZYX987。"

智能体的编排层认识到其计划的第一部分完成，立即进行到第二部分。它通过调用get_shipping_status("ZYX987")工具来行动。它观察新结果："正在配送。"

最后，成功执行其计划的数据收集阶段后，智能体移动到"报告"步骤。它感知到拥有所有必要的组件，计划最终消息，并通过生成回应来行动："您的订单#12345正在'配送中'！"

<!-- Page 14 -->

## A Taxonomy of Agentic Systems
## 智能体系统分类法

理解5步骤操作循环是谜题的第一部分。第二部分是认识到这个循环可以在复杂性上缩放以创建不同类别的智能体。对于架构师或产品负责人，一个关键的初始决策是确定要构建什么类型的智能体。

我们可以将智能体系统分为几个广泛的级别，每个级别都建立在前一个能力的基础上。

**图2：5步骤中的智能体系统**
![图2：5步骤中的智能体系统](images/figure_2_agentic_system_in_5_steps.png)

<!-- Page 15 -->

### Level 0: The Core Reasoning System
### 第0级：核心推理系统

在我们拥有智能体之前，我们必须从最基本形式的"大脑"开始：推理引擎本身。在这个配置中，语言模型（LM）孤立运行，仅基于其广泛的预训练知识响应，没有任何工具、记忆或与实时环境的交互。

其优势在于这种广泛训练，允许它解释已建立的概念并以极大的深度规划如何解决问题。权衡是完全缺乏实时感知；它在功能上对其训练数据之外的任何事件或事实都"视而不见"。

例如，它可以解释职业棒球的规则和纽约洋基队的完整历史。但如果你问，"昨晚洋基队比赛的最终比分是多少？"，它将无法回答。那场比赛是在其训练数据收集后发生的特定的、真实世界的事件，所以信息在其知识中根本不存在。

### Level 1: The Connected Problem-Solver
### 第1级：连接的问题解决器

在这个级别，推理引擎通过连接和使用外部工具——我们架构的"双手"组件——成为功能性智能体。其解决问题不再局限于其静态的、预训练的知识。

使用5步骤循环，智能体现在可以回答我们之前的问题。给定"任务"："昨晚洋基队比赛的最终比分是多少？"，其"思考"步骤认识到这是实时数据需求。其"行动"步骤然后调用工具，如具有适当日期和搜索词的Google搜索API。它"观察"搜索结果（例如，"洋基队5-3获胜"），并将该事实合成为最终答案。

<!-- Page 17 -->

### Level 2: The Strategic Problem-Solver
### 第2级：战略性问题解决器

第2级智能体引入了一个关键能力：战略规划。除了简单地将任务连接到工具之外，它可以拆解复杂的多步骤问题，并主动编排一系列操作以实现目标。

考虑用户问："我在加州米尔布雷附近哪里能找到好咖啡店？"

一个第1级智能体会直接调用google_places工具并返回原始结果。

而一个第2级智能体会使用其战略规划能力：

1.  **思考**："用户想要'好'咖啡店，这意味着高评分。我应该专门搜索高评分地点，以提供更有针对性的推荐。"
2.  **行动**：调用google_places工具，查询="coffee shop in Millbrae, CA"，min_rating=4.0。（这是上下文工程——它自动从上一步的输出创建了一个新的、集中的搜索查询。）
3.  **观察**："搜索返回了'Millbrae Coffee'和'The Daily Grind'。"
4.  **思考**："我将综合这些结果并呈现给用户。"

这种战略规划还支持主动辅助，比如一个智能体读取长长的航班确认邮件，工程化关键上下文（航班号、日期），并通过将其添加到您的日历来行动。

### Level 3: The Collaborative Multi-Agent System
### 第3级：协作多智能体系统

在最高级别，范式完全转变。我们不再构建单一的、全能的"超级智能体"，而是转向协调工作的"专家团队"，这直接反映了人类组织的模式。系统的集体力量在于这种劳动分工。

在这里，智能体将其他智能体视为工具。想象一个"项目经理"智能体接收一个"任务"："推出我们新的'Solaris'耳机。"

项目经理智能体本身不做全部工作。它通过为其专业智能体团队创建新任务来行动，就像现实生活中的工作方式一样：

1.  **委托给MarketResearchAgent**："分析降噪耳机的竞争对手定价。明天前返回摘要文档。"
2.  **委托给MarketingAgent**："'使用'Solaris'产品规格表作为上下文，起草三个版本的新闻稿。"
3.  **委托给WebDevAgent**："根据附附的设计模型生成新产品页面HTML。"

<!-- Page 18 -->

这种协作模式，虽然目前受到当今语言模型推理限制的约束，但代表了从头到尾自动化整个复杂业务工作流程的前沿。

### Level 4: The Self-Evolving System
### 第4级：自我进化系统

第4级代表了从委托到自主创造和适应的深刻飞跃。在这个级别，智能体系统能够识别自身能力中的差距，并动态创建新工具甚至新智能体来填补这些差距。它从使用固定资源集转向积极扩展它们。

按照我们的例子，负责'Solaris'发布的"项目经理"智能体可能会意识到需要监控社交媒体情绪，但其团队上不存在这样的工具或智能体。

1.  **思考（元推理）**："我必须跟踪'Solaris'的社交媒体热度，但我缺乏这种能力。"
2.  **行动（自主创建）**：不是失败，而是调用高级AgentCreator工具，并赋予新任务："构建一个新智能体，监控社交媒体关键词'Solaris耳机'，执行情绪分析，并报告每日摘要。"
3.  **观察**：一个新的、专门的SentimentAnalysisAgent被创建、测试，并即时添加到团队中，准备为原始任务做出贡献。

这种自主性水平——系统能够动态扩展自身能力——将智能体团队转变为真正学习和进化的组织。

<!-- Page 19 -->

## Core Agent Architecture: Model, Tools, and Orchestration
## 核心智能体架构：模型、工具和编排

我们知道智能体做什么以及它如何扩展。但我们实际上如何构建它？

从概念到代码的转换在于其三个核心组件的具体架构设计。

### Model: The "Brain" of your AI Agent
### 模型：AI智能体的"大脑"

语言模型是智能体的推理核心，其选择是一个关键的架构决策，决定了智能体的认知能力、运营成本和速度。

然而，将这种选择简单地视为挑选具有最高基准分数模型的问题，通常是失败的常见路径。智能体在生产环境中的成功很少由通用学术基准决定。

现实世界的成功需要擅长智能体基础的模型：卓越的推理能力来导航复杂、多步骤问题，以及可靠的工具使用来与世界互动⁷。

要做好这一点，首先定义业务问题，然后根据直接映射到该结果的指标测试模型。如果您的智能体需要编写代码，请在您的私有代码库上测试它。如果它处理保险索赔，请评估其从您特定文档格式中提取信息的能力。然后必须将此分析与成本和延迟的实际性交叉引用。"最佳"模型是在质量、速度和价格的最佳交叉点，适用于您的特定任务⁸。

<!-- Page 20 -->

您可以选择多个模型，一个"专家团队"。您不会用大锤来砸坚果。一个强大的智能体架构可能使用像Gemini 2.5 Pro这样的前沿模型来进行初始规划和复杂推理的重型工作，然后智能路由更简单、高流量的任务——比如分类用户意图或总结文本——到更快、更具成本效益的模型，如Gemini 2.5 Flash。模型路由可能是自动的或硬编码的，但这是优化性能和成本的关键策略⁹。

同样的原则适用于处理多样化的数据类型。虽然像Gemini实时模式¹⁰这样的原生多模态模型提供了处理图像和音频的简化路径，但另一种方法是使用专门的工具，如Cloud Vision API¹¹或Speech-to-Text API¹²。在这种模式中，世界首先被转换为文本，然后传递给仅语言模型进行推理。这增加了灵活性并允许最佳组件，但也引入了显著的复杂性。

最后，AI领域处于持续、快速进化的状态。您今天选择的模型将在六个月内被超越。"设置它就忘记它"的心态是不可持续的。为这种现实构建意味着投资于敏捷的操作框架——"智能体运维"实践¹³。通过强大的CI/CD管道，持续根据您的关键业务指标评估新模型，您可以降低风险并加速升级，确保您的智能体始终由最好的大脑驱动，而无需完全的架构改革。

### Tools: The "Hands" of your AI Agent
### 工具：AI智能体的"双手"

如果模型是智能体的大脑，工具就是将其推理与现实连接的双手。它们允许智能体超越其静态训练数据来检索实时信息并在世界中采取行动。一个强大的工具界面是三部分循环：定义工具能做什么、调用它和观察结果。

<!-- Page 21 -->

以下是智能体构建者将放入其智能体"手中"的几种主要工具类型。更完整的深入探讨，请参见本系列中专注于智能体工具的白皮书。

#### Retrieving Information: Grounding in Reality
#### 检索信息：基于现实的 grounding

最基础的工具是访问最新信息的能力。检索增强生成（RAG）给智能体一张"图书馆卡"来查询外部知识，通常存储在向量数据库或知识图中，范围从内部公司文档到通过Google搜索的网络知识。对于结构化数据，自然语言到SQL（NL2SQL）工具允许智能体查询数据库来回答分析问题，如"我们上个季度最畅销的产品是什么？"通过在说话前查找——无论是在文档还是数据库中——智能体基于事实进行基础，大幅减少幻觉。

#### Executing Actions: Changing the World
#### 执行动作：改变世界

当智能体从读取信息转向主动做事时，它们的真正力量被释放出来。通过将现有API和代码函数包装为工具，智能体可以发送电子邮件、安排会议或在ServiceNow中更新客户记录。对于更动态的任务，智能体可以即时编写和执行代码。在安全沙箱中，它可以生成SQL查询或Python脚本来解决复杂问题或执行计算，将其从知识渊博的助手转变为自主行动者¹⁴。

<!-- Page 22 -->

这还包括人类交互工具。智能体可以使用人在回路（HITL）工具暂停其工作流并请求确认（例如，ask_for_confirmation()）或从用户界面请求特定信息（例如，ask_for_date_input()），确保人员参与关键决策。HITL可以通过SMS短信和数据库中的任务来实现。

#### Function Calling: Connecting Tools to your Agent
#### 函数调用：将工具连接到您的智能体

为了智能体可靠地"函数调用"和使用工具，它需要清晰的指令、安全的连接和编排¹⁵。长期标准如OpenAPI规范提供了这一点，给智能体一个结构化合同，描述工具的目的、所需参数和预期响应。这个模式让模型每次都能生成正确的函数调用并解释API响应。对于更简单的工具发现和连接，开放标准如模型上下文协议（MCP）变得流行，因为它们更方便¹⁶。此外，一些模型具有原生工具，如具有原生Google搜索的Gemini，其中函数调用作为LM调用本身的一部分发生¹⁷。

### The Orchestration Layer
### 编排层

如果模型是智能体的大脑，工具是它的手，那么编排层是连接它们的中枢神经系统。它是运行"思考、行动、观察"循环的引擎，治理智能体行为的状态机，以及开发者精心制作的逻辑变得生动的地方。这一层不仅仅是管道；它是整个智能体交响乐的指挥家，决定模型何时应该推理，哪个工具应该行动，以及该行动的结果如何通知下一个动作。

<!-- Page 23 -->

#### Core Design Choices
#### 核心设计选择

第一个架构决策是确定智能体的自主程度。选择存在于一个范围内。一端是确定性、可预测的工作流，将LM调用为特定任务的工具——一点AI来增强现有流程。另一端是LM处于驾驶座，动态适应、规划和执行任务以实现目标。

一个平行的选择是实施方法。无代码构建者提供速度和可访问性，授权业务用户自动化结构化任务并快速构建简单智能体。对于更复杂、任务关键的系统，代码优先框架，如Google的智能体开发套件（ADK）¹⁸，提供工程师所需的深度控制、可定制性和集成能力。

无论方法如何，生产级框架都是必不可少的。它必须是开放的，允许您插入任何模型或工具以防止供应商锁定。它必须提供精确控制，使LM的非确定性推理由硬编码业务规则治理的混合方法成为可能。最重要的是，框架必须为可观察性而构建。当智能体行为异常时，您不能简单地在模型的"思想"中设置断点。一个强大的框架生成详细的跟踪和日志，暴露整个推理轨迹：模型的内部独白、它选择的工具、它生成的参数以及它观察到的结果。

#### Instruct with Domain Knowledge and Persona
#### 使用领域知识和角色指令

在这个框架内，开发者最强大的杠杆是用领域知识和独特的人格来指导智能体。这是通过系统提示或一组核心指令来完成的。这不仅仅是简单的命令；它是智能体的宪法。

<!-- Page 24 -->

在这里，您告诉它，"您是Acme Corp的有用客户支持智能体..."并提供约束、期望输出模式、参与规则、特定的语调以及关于何时以及为何应使用其工具的明确指导。指令中的几个示例场景通常非常有效。

#### Augment with Context
#### 使用上下文增强

智能体的"记忆"在运行时被编排到LM上下文窗口中。更完整的深入探讨，请参见本系列中专注于智能体记忆的白皮书。

短期记忆是智能体活动的"草稿板"，维护当前对话的运行历史。它跟踪来自正在进行的循环的（行动、观察）对序列，提供模型决定下一步所需的直接上下文。这可以实现为状态、人工制品、会话或线程等抽象。

长期记忆提供跨会话的持久性。在架构上，这几乎总是实现为另一个专门的工具——连接到向量数据库或搜索引擎的RAG系统。编排者给智能体预取和主动查询其自身历史的能力，使其能够"记住"用户的偏好或几周前类似任务的结果，以获得真正个性化和连续的体验¹⁹。

### Multi-Agent Systems and Design Patterns
### 多智能体系统和设计模式

随着任务复杂性增长，构建单一、全能的"超级智能体"变得低效。更有效的解决方案是采用"专家团队"方法，这反映了人类组织。这是多智能体系统的核心：复杂过程

<!-- Page 25 -->

被分割成离散的子任务，每个被分配给专门的、专门的AI智能体。这种劳动分工使每个智能体更简单、更专注，更容易构建、测试和维护，这对于动态或长期运行的业务流程是理想的。

架构师可能依赖经过验证的智能体设计模式，尽管智能体能力及模式正在快速发展²⁰。对于动态或非线性任务，协调器模式是必不可少的。它引入了一个"经理"智能体，分析复杂请求，分割主要任务，并智能地将每个子任务路由到适当的专业智能体（如研究员、作者或编码器）。然后协调器聚合每个专业人员的响应以制定最终的、全面的答案。

**图3：来自 https://cloud.google.com/architecture/choose-design-pattern-agentic-ai-system 的"迭代优化"模式**
![图3：迭代优化模式](images/figure_3_iterative_refinement_pattern.png)

对于更线性的工作流，顺序模式更合适，像一个数字装配线，其中一个智能体的输出成为下一个的直接输入。其他关键模式关注质量和安全。迭代优化模式创建反馈循环，使用"生成器"智能体创建内容和"评判器"智能体根据

<!-- Page 26 -->

质量标准评估它。对于高风险任务，人在回路（HITL）模式是关键的，在工作流中创建故意暂停，在智能体采取重要行动之前获得人的批准。

### Agent Deployment and Services
### 智能体部署和服务

在构建了本地智能体后，您需要将其部署到服务器上，它在那里全天候运行，其他人和智能体可以使用它。继续我们的类比，部署和服务将是智能体的身体和腿。智能体需要几个服务来有效，会话历史和记忆持久化等等。作为智能体构建者，您还将负责决定记录什么，以及为数据隐私、数据驻留和法规合规采取什么安全措施。在将智能体部署到生产环境时，所有这些服务都在范围内。

幸运的是，智能体构建者可以依赖几十年的应用程序托管基础设施。智能体毕竟是一种新形式的软件，许多相同的原则适用。构建者可以依赖专门的、特定的智能体部署选项，如Vertex AI智能体引擎，它在一个平台上支持运行时和其他一切²¹。对于想更直接控制其应用程序栈或在现有DevOps基础设施中部署智能体的软件开发者，任何智能体和大多数智能体服务都可以添加到docker容器中并部署到行业标准运行时，如Cloud Run或GKE²²。

<!-- Page 27 -->

**图4：来自 https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/overview 的Vertex AI智能体构建者**
![图4：Vertex AI智能体构建者](images/figure_4_vertex_ai_agent_builder.png)

如果您不是软件开发者和DevOps专家，部署第一个智能体的过程可能令人生畏。许多智能体框架通过部署命令或专用平台来部署智能体使这变得容易，这些应该用于早期探索和入职。升级到安全和生产就绪的环境通常需要更多的时间投资和应用最佳实践，包括CI/CD和为您的智能体进行自动测试²³。

### Agent Ops: A Structured Approach to the Unpredictable
### 智能体运维：应对不可预测性的结构化方法

当您构建第一个智能体时，您将一次又一次地手动测试行为。当您添加功能时，它工作吗？当您修复错误时，您是否引起了不同问题？测试对软件开发是正常的，但它在生成式AI中工作方式不同。

<!-- Page 28 -->

从传统的、确定性软件到随机的、智能体系统的转换需要新的操作哲学。传统的软件单元测试可以简单地断言output == expected；但当智能体的响应在设计上是概率性的时，这不起作用。另外，因为语言是复杂的，它通常需要LM来评估"质量"——智能体的响应做了它应该做的一切，没有它不应该做的，并有适当的语调。

**图5：DevOps、MLOps和GenAIOps操作域之间的关系 来自 https://medium.com/@sokratis.kartakis/genai-in-production-mlops-or-genaiops-25691c9becd0**
![图5：DevOps、MLOps和GenAIOps操作域关系](images/figure_5_devops_mlops_genaiops_relationships.png)

智能体运维是管理这种新现实的纪律性、结构化方法。它是DevOps和MLOps的自然演进，专为构建、部署和治理AI智能体的独特挑战量身定制，将不可预测性从负债转变为管理的、可测量的和可靠的特征²⁴。更完整的深入探讨，请参见本系列中专注于智能体质量的白皮书。

<!-- Page 29 -->

#### Measure What Matters: Instrumenting Success Like an A/B Experiment
#### 测量重要指标：像A/B实验一样工具化成功

在您可以改进智能体之前，必须在您的业务上下文中定义"更好"意味着什么。将您的可观察性策略框架化为A/B测试，并问自己：哪些关键绩效指标（KPI）证明智能体正在提供价值？这些指标应超越技术正确性并衡量现实世界影响：目标完成率、用户满意度分数、任务延迟、每次交互运营成本，以及——最重要的是——对收入、转化或客户保留等业务目标的影响。

这种自顶向下视图将指导您其余的测试，使您走上指标驱动开发的道路，并将让您计算投资回报。

#### Quality Instead of Pass/Fail: Using a LM Judge
#### 质量而非通过/失败：使用语言模型评判器

业务指标不能告诉您智能体是否正确行为。由于简单的通过/失败是不可能的，我们转向使用"LM作为评判器"来评估质量。这涉及使用强大的模型根据预定义的评分标准评估智能体的输出：它给出了正确答案吗？响应是否基于事实？它遵循指令了吗？这种自动评估，针对提示的黄金数据集运行，提供了一致的质量衡量。

创建评估数据集——包括理想（或"黄金"）问题和正确响应——可能是一个乏味的过程。要构建这些，您应该从现有的生产或开发与智能体的交互中采样场景。数据集必须覆盖您期望用户参与的完整用例范围，加上一些意外的。虽然对评估的投资很快得到回报，但评估结果应始终

<!-- Page 30 -->

由领域专家审查后才被接受为有效。越来越多，这些评估的策展和维护正在成为产品经理在领域专家支持下的关键责任。

#### Metrics-Driven Development: Your Go/No-Go for Deployment
#### 指标驱动开发：您部署的通过/不通过标准

一旦您自动化了数十个评估场景并建立了可信的质量分数，您就可以自信地测试开发智能体的更改。过程很简单：针对整个评估数据集运行新版本，并直接比较其分数与现有生产版本的分数。这个强大的系统消除了猜测，确保您对每次部署都有信心。虽然自动评估是关键的，但不要忘记其他重要因素，如延迟、成本和任务成功率。为最大安全，使用A/B部署缓慢推出新版本，并将这些现实世界生产指标与您的模拟分数进行比较。

#### Debug with OpenTelemetry Traces: Answering "Why?"
#### 使用OpenTelemetry跟踪进行调试：回答"为什么？"

当您的指标下降或用户报告错误时，您需要理解"为什么"。OpenTelemetry跟踪是智能体整个执行路径（轨迹）的高保真、逐步记录，允许您调试智能体的步骤²⁵。有了跟踪，您可以看到发送给模型的确切提示、模型的内部推理（如果可用）、它选择调用的特定工具、它为该工具生成的精确参数以及作为观察返回的原始数据。跟踪在您第一次看时可能很复杂，但它们提供了诊断和修复任何问题根本原因所需的细节。重要的跟踪细节可能转化为指标，但审查跟踪主要是为了调试，而不是生成业务指标。

#### Cherish Human Feedback: Guiding Your Automation
#### 珍视人类反馈：指导您的自动化

虽然自动评估是关键的，但没有任何东西能取代真实的人类反馈。人类反馈是黄金标准，提供自动系统可能错过的细微上下文和定性见解。系统化地收集和分析用户反馈以持续改进智能体性能。

### Agent Interoperability
### 智能体互操作性

<!-- Page 32 -->

#### Agents and Humans
#### 智能体与人类

最常见的人类-智能体交互形式是通过用户界面。在其最简单的形式中，这是一个聊天机器人，用户输入请求，智能体作为后端服务处理它并返回文本块。更高级的智能体可以提供结构化数据，如JSON，为丰富的动态前端体验提供动力。人在回路（HITL）交互模式包括意图细化、目标扩展、确认和澄清请求。

计算机使用是一种工具类别，LM控制用户界面，通常具有人类交互和监督。启用计算机使用的智能体可以决定下一个最佳操作是导航到新页面、突出显示特定按钮或用相关信息预填充表单²⁷。

不是智能体代表用户使用界面，LM可以改变UI以满足当前时刻的需求。这可以通过控制UI的工具（MCP UI）²⁸来完成，或者可以将客户端状态与智能体同步的专门UI消息系统（AG UI）²⁹，甚至生成定制界面（A2UI）³⁰。

当然，人类交互不仅限于屏幕和键盘。先进的智能体正在打破文本障碍，通过"实时模式"转向实时、多模态通信，创建更自然、类似人类的连接。像Gemini Live API³¹这样的技术支持双向流，允许用户与智能体交谈并中断它，就像他们在自然对话中一样。

这种能力从根本上改变了人类-智能体协作的性质。通过访问设备的摄像头和麦克风，智能体可以看到用户看到的内容并听到他们说的话，以模仿人类对话的延迟用生成的语音响应。

<!-- Page 33 -->

这开辟了大量文本根本不可能的用例，从技术人员在修理设备时获得免提指导到购物者获得实时风格建议。它使智能体成为一个更直观和可访问的伙伴。

#### Agents and Agents
#### 智能体与智能体

正如智能体必须与人类连接一样，它们也必须彼此连接。随着企业扩展其AI使用，不同团队将构建不同的专业智能体。没有共同标准，连接它们将需要构建杂乱、脆弱的自定义API集成网络，这是不可能维护的。核心挑战是双重的：发现（我的智能体如何找到其他智能体并知道它们能做什么？）和通信（我们如何确保它们说同一种语言？）。

Agent2Agent（A2A）协议是为解决此问题而设计的开放标准。它充当智能体经济的通用握手。A2A允许任何智能体发布数字"名片"，称为智能体卡片。这个简单的JSON文件宣传智能体的能力、其网络端点和与之交互所需的安全凭证。这使得发现变得简单和标准化。与专注于解决事务请求的MCP相比，Agent to Agent通信通常用于额外的问题解决。

一旦发现，智能体使用面向任务的架构进行通信。而不是简单的请求-响应，交互被框架化为异步"任务"。客户端智能体向服务器智能体发送任务请求，然后服务器智能体可以在长期连接上处理问题时提供流式更新。这个强大的、标准化的通信协议是谜题的最后一块，使协作的、第3级多智能体系统成为可能，这些系统代表了自动化的前沿。A2A将孤立智能体的集合转变为真正的、可互操作的生态系统。

<!-- Page 34 -->

#### Agents and Money
#### 智能体与金钱

随着AI智能体为我们做更多任务，其中一些任务涉及买卖、谈判或促进交易。当前的Web是为人类点击"购买"而构建的，责任在人身上。如果自主智能体点击"购买"，它会制造信任危机——如果出了问题，谁该负责？这些是授权、真实性和问责制的复杂问题。为了释放真正的智能体经济，我们需要新的标准，允许智能体安全可靠地代表其用户进行交易。

这个新兴领域远未确立，但两个关键协议正在铺平道路。智能体支付协议（AP2）是一个开放协议，旨在成为智能体商业的确定性语言。它通过引入加密签名的数字"授权书"来扩展像A2A这样的协议。这些充当用户意图的可验证证明，为每个交易创建不可否认的审计跟踪。这允许智能体基于用户的委托权威在全球范围内安全浏览、谈判和交易。补充这一点的是x402，一个开放的互联网支付协议，使用标准HTTP 402"需要付款"状态代码。它实现无摩擦的机器对机器微支付，允许智能体按使用付费为基础支付API访问或数字内容等，而不需要复杂的账户或订阅。这些协议共同构建了智能体Web的基础信任层。

### Securing a Single Agent: The Trust Trade-Off
### 保护单个智能体：信任权衡

当您创建第一个AI智能体时，您立即面临基本张力：实用性与安全性之间的权衡。为了使智能体有用，您必须给它权力——做出决策的自主权和执行发送电子邮件或查询数据库等行动的工具。然而，您授予的每一盎司权力都引入相应的风险措施。主要安全关注是流氓行动——意外或有害行为——

<!-- Page 35 -->

和敏感数据披露。您想给智能体足够长的皮带来完成其工作，但要足够短以防止它跑入交通，特别是当交通涉及不可逆的操作或您公司的私人数据时³²。

为了管理这一点，您不能仅依赖AI模型的判断，因为它可以通过提示注入等技术被操纵³³。相反，最佳实践是混合、深度防御方法³⁴。第一层包括传统的、确定性护栏——一组硬编码规则，作为模型推理之外的安全扼流点。这可能是一个阻止超过100美元的购买或要求明确用户确认才能与外部API交互的策略引擎。这一层为智能体的权力提供可预测的可审计硬限制。

第二层利用基于推理的防御，使用AI来帮助保护AI。这涉及训练模型对攻击更具弹性（对抗性训练）和雇用更小的、专门的"守卫模型"，它们像安全分析师一样工作。这些模型可以在执行前检查智能体的提议计划，标记潜在风险或违反政策的步骤以供审查。这种混合模型，结合代码的严格确定性和AI的上下文感知，即使对单个智能体也创建了强大的安全姿态，确保其权力始终与其目的一致。

#### Agent Identity: A New Class of Principal
#### 智能体身份：新的主体类别

在传统安全模型中，有使用OAuth或SSO的人类用户，以及使用IAM或服务账户的服务。智能体添加了第3类主体。智能体不仅仅是一段代码；它是一个自主行动者，一种新的主体，需要自己的可验证身份。就像员工被发放ID徽章一样，平台上的每个智能体都必须被发放安全的、可验证的"数字护照"。这个智能体

<!-- Page 36 -->

身份不同于调用它的用户身份和构建它的开发者身份。这是我们在企业中必须处理身份和访问管理（IAM）方式的根本转变。

让每个身份都被验证并拥有所有身份的访问控制，是智能体安全的基石。一旦智能体具有加密可验证的身份（通常使用SPIFFE³⁵等标准），它可以被授予自己特定的、最小特权权限。SalesAgent被授予CRM的读/写访问权限，而HRonboardingAgent被明确拒绝。这种细粒度控制至关重要。它确保即使单个智能体被破坏或行为异常，潜在的爆炸半径也被包含。没有智能体身份构造，智能体不能以有限的委托权威代表人类工作。

**表1：不同类别行为者认证的非详尽示例**

| 主体实体 | 认证/验证 | 注释 |
|---------|----------|------|
| 用户 | 使用OAuth或SSO认证 | 对其行为具有完全自主权和责任的人类行为者 |
| 智能体（新的主体类别） | 使用SPIFFE验证 | 智能体具有委托权威，代表用户采取行动 |
| 服务账户 | 集成到IAM中 | 应用程序和容器，完全确定性，对行为不负责任 |

<!-- Page 37 -->

#### Policies to Constrain Access
#### 限制访问的策略

策略是授权（AuthZ）的一种形式，不同于认证（AuthN）。通常，策略限制主体的能力；例如，"市场中的用户只能访问这27个API端点，不能执行DELETE命令。"随着我们开发智能体，我们需要对智能体、它们的工具、其他内部智能体、它们可以共享的上下文和远程智能体应用权限。这样想：如果您将所有API、数据、工具和智能体添加到您的系统中，那么您必须限制访问仅完成其工作所需的能力子集。这是推荐的方法：在保持上下文相关的同时应用最小特权原则³⁶。

#### Securing an ADK Agent
### 保护ADK智能体

有了身份和策略的核心原则，保护用智能体开发套件（ADK）构建的智能体成为通过代码和配置应用这些概念的实际练习³⁷。

如上所述，该过程需要明确定义身份：用户账户（例如OAuth）、服务账户（运行代码）、智能体身份（使用委托权威）。一旦处理了认证，下一层防御涉及建立策略来限制对服务的访问。这通常在API治理层完成，同时还有支持MCP和A2A服务的治理。

下一层是在您的工具、模型和子智能体中构建护栏以执行策略。这确保无论LM推理什么或恶意提示可能建议什么，工具自己的逻辑将拒绝执行不安全或违反策略的操作。这种方法提供可预测和可审计的安全基线，将抽象安全策略转化为具体、可靠的代码³⁸。

<!-- Page 38 -->

对于更适应智能体运行时行为的动态安全，ADK提供回调和插件。before_tool_callback允许您在工具调用运行前检查其参数，根据智能体当前状态验证它们以防止不对齐的操作。对于更可重用的策略，您可以构建插件。一个常见的模式是"Gemini作为评判器"³⁹，使用快速、廉价的模型如Gemini Flash-Lite或您自己微调的Gemma模型，实时筛选用户输入和智能体输出的提示注入或有害内容。

对于更喜欢这些动态检查的完全托管、企业级解决方案的组织，Model Armor可以作为可选服务集成。Model Armor充当专门的安全层，筛选提示和响应的各种威胁，包括提示注入、越狱尝试、敏感数据（PII）泄漏和恶意URL⁴⁰。通过将这些复杂安全任务卸载到专门服务，开发人员可以确保一致、强大的保护，而无需自己构建和维护这些护栏。ADK内的这种混合方法——结合强大身份、确定性工具内逻辑、动态AI驱动的护栏和可选托管服务如Model Armor——是您构建既强大又可信赖的单个智能体的方式。

**图6：来自 https://saif.google/focus-on-agents 的安全与智能体**
![图6：安全与智能体](images/figure_6_security_and_agents.png)

<!-- Page 39 -->

### Scaling Up from a Single Agent to an Enterprise Fleet
### 从单个智能体扩展到企业级智能体群

单个AI智能体的生产成功是一个胜利。扩展到数百个智能体群的挑战是架构。如果您构建一两个智能体，您的关注点主要是安全性。如果您构建许多智能体，您必须设计系统来处理更多。就像API蔓延一样，当智能体和工具在组织中激增时，

<!-- Page 40 -->

它们创建了一个新的、复杂的交互、数据流和潜在安全漏洞网络。管理这种复杂性需要一个更高阶的治理层，将您的所有身份和策略集成并报告到一个中央控制平面。

#### Security and Privacy: Hardening the Agentic Frontier
#### 安全与隐私：加固智能体前沿

企业级平台必须解决生成式AI固有的独特安全和隐私挑战，即使只运行单个智能体。智能体本身成为一个新的攻击向量。恶意行为者可以尝试提示注入来劫持智能体的指令，或数据中毒来破坏其用于训练或RAG的信息。此外，一个约束不当的智能体可能在其响应中无意中泄漏敏感客户数据或专有信息。

强大的平台提供深度防御策略来缓解这些风险。它从数据开始，确保企业的专有信息从不用于训练基础模型，并通过VPC服务控制等控制进行保护。它需要输入和输出过滤，充当提示和响应的防火墙。最后，平台必须提供合同保护，如训练数据和生成输出的知识产权赔偿，给企业在生产中部署智能体所需的法律和技术信心。

#### Agent Governance: A Control Plane instead of Sprawl
#### 智能体治理：控制平面而非无序扩展

随着智能体及其工具在组织中激增，它们创建了一个新的、复杂的交互和潜在漏洞网络，一个常被称为"智能体蔓延"的挑战。管理这需要超越保护单个智能体，实施更高阶的架构方法：一个中央网关，作为所有智能体活动的控制平面。

<!-- Page 41 -->

想象一个繁华的都市，有数千辆自动驾驶车辆——用户、智能体和工具——都有目的地移动。没有交通灯、车牌和中央控制系统，混乱将统治。网关方法创建控制系统，为所有智能体流量建立强制入口点，包括用户到智能体提示或UI交互、智能体到工具调用（通过MCP）、智能体到智能体协作（通过A2A）和直接对LM的推理请求。通过坐在这个关键交叉点，组织可以检查、路由、监控和管理每个交互。

## 这个控制平面提供两个主要的、相互连接的功能：
1.  **运行时策略执行**：它充当实现安全的架构扼流点。它处理认证（"我知道这个行为者是谁吗？"）和授权（"他们有权限这样做吗？"）。集中执行提供可观察性的"单一窗格"，为每个交易创建通用日志、指标和跟踪。这将不同的智能体和工作流的意大利面条转变为透明和可审计的系统。

2.  **集中治理**：为了有效执行策略，网关需要一个真相来源。这由中央注册表提供——智能体和工具的企业应用商店。这个注册表允许开发者发现和重用现有资产，防止冗余工作，同时给管理员完整的清单。更重要的是，它实现智能体和工具的正式生命周期，允许发布前的安全审查、版本控制和创建细粒度策略，指定哪些业务单元可以访问哪些智能体。

通过结合运行时网关与中央治理注册表，组织将混乱蔓延的风险转变为管理的、安全的和高效的生态系统。

<!-- Page 42 -->

#### Cost and Reliability: The Infrastructure Foundation
#### 成本和可靠性：基础设施基础

最终，企业级智能体必须既可靠又具有成本效益。经常失败或提供缓慢结果的智能体具有负ROI。相反，贵得令人望而却步的智能体无法扩展以满足业务需求。底层基础设施必须设计为管理这种权衡，安全并遵守法规和数据主权合规。

在某些情况下，您需要的功能是缩放到零，当您对特定智能体或子功能有不规则流量时。对于任务关键、延迟敏感的工作负载，平台必须提供专用、保证容量，如LM服务的预配置吞吐量⁴¹或Cloud Run等运行时的99.9%服务水平协议（SLA）⁴²。这提供可预测的性能，确保您最重要的智能体即使在重负载下也始终响应。通过提供这种基础设施选项范围，结合对成本和性能的综合监控，您为将AI智能体从有前途的创新扩展到企业的核心、可靠组件建立了最终的、必要的基础。

### How agents evolve and learn
### 智能体如何进化和学习

部署在现实世界中的智能体在动态环境中操作，其中政策、技术和数据格式不断变化。没有适应能力，智能体的性能会随时间退化——一个常被称为"老化"的过程——导致效力和信任的丧失。手动更新大量智能体群以跟上这些变化是不经济且缓慢的。更可扩展的解决方案是设计能够自主学习和进化的智能体，在工作上改进其质量，需要最少的工程努力⁴³。

<!-- Page 43 -->

#### How agents learn and self evolve
#### 智能体如何学习和自我进化

很像人类，智能体从经验和外部信号学习。这个学习过程由几个信息源驱动：

*   **运行时经验**：智能体从运行时工件学习，如会话日志、跟踪和记忆，这些捕获成功、失败、工具交互和决策轨迹。至关重要的是，这包括人在回路（HITL）反馈，提供权威纠正和指导。

*   **外部信号**：学习也由新的外部文档驱动，如更新的企业政策、公共监管指南或其他智能体的批评。

然后这些信息被用来优化智能体的未来行为。不是简单地总结过去的交互，高级系统创建可推广的工件来指导未来任务。最成功的适应技术分为两类：

*   **增强的上下文工程**：系统持续改进其提示、少样本示例和它从记忆中检索的信息。通过优化为每个任务提供给LM的上下文，它增加成功的可能性。

*   **工具优化和创建**：智能体的推理可以识别其能力中的差距并采取行动填补它们。这可能涉及获得新工具的访问权限、即时创建新工具（例如，Python脚本），或修改现有工具（例如，更新API模式）。

额外的优化技术，如动态重新配置多智能体设计模式或使用人类反馈强化学习（RLHF），是活跃的研究领域。

<!-- Page 44 -->

#### Example: Learning New Compliance Guidelines
#### 示例：学习新的合规指南

考虑一个在高度监管行业如金融或生命科学中运营的企业智能体。其任务是生成必须遵守隐私和监管规则（例如GDPR）的报告。

## 这可以使用多智能体工作流实现：
1.  **查询智能体**检索原始数据以响应用户请求。
2.  **报告智能体**将这些数据合成为草稿报告。
3.  **评判智能体**，配备已知的合规指南，审查报告。如果遇到模糊或需要最终签署，它会升级给人类领域专家。
4.  **学习智能体**观察整个交互，特别关注人类专家的纠正反馈。然后它将此反馈概括为新的、可重用的指南（例如，评判智能体的更新规则或报告智能体的精炼上下文）。

<!-- Page 45 -->

**图7：合规指南的示例多智能体工作流**
![图7：合规指南的示例多智能体工作流](images/figure_7_sample_multi_agent_workflow_compliance_guidelines.png)

例如，如果人类专家标记某些家庭统计信息必须匿名化，学习智能体记录此纠正。下次生成类似报告时，评判智能体将自动应用此新规则，减少人类干预的需要。这种评判、人类反馈和概括的循环允许系统自主适应不断发展的合规要求⁴⁴。

<!-- Page 46 -->

#### Simulation and Agent Gym - the next frontier
#### 模拟和智能体训练场 - 下一个前沿

我们提出的设计模式可以分类为在线学习，其中智能体需要用它们被工程化的资源和设计模式学习。现在正在研究更先进的方法，其中有一个专用平台，工程化为在离线流程中优化多智能体系统，具有不属于多智能体运行时环境的先进工具和能力。这种智能体训练场⁴⁵的关键属性是：

1.  **它不在执行路径中**。它是一个独立的离生产平台，因此可以获得任何LM模型的帮助，以及离线工具、云应用程序等
2.  **它提供模拟环境**，所以智能体可以对新数据"锻炼"和学习。这个模拟环境对于具有许多优化路径的"试错"非常出色
3.  **它可以调用先进的合成数据生成器**，指导模拟尽可能真实，并对智能体进行压力测试（这可以包括先进技术，如红队、动态评估和评判智能体家族）
4.  **优化工具库不是固定的**，它可以采用新工具（通过开放协议如MCP或A2A），或在更高级设置中 - 学习新概念并围绕它们制作工具
5.  **最后，甚至像智能体训练场这样的构造**，可能无法克服某些边缘情况（由于企业中"部落知识"的众所周知问题）。在这些情况下，我们看到智能体训练场能够连接到领域专家的人类结构，并与他们就正确的结果集进行咨询，以指导下一组优化

<!-- Page 47 -->

### Examples of advanced agents
### 高级智能体示例

#### Google Co-Scientist
#### Google合作科学家

Co-Scientist是一个先进的AI智能体，设计用作虚拟研究合作者，通过系统探索复杂问题空间来加速科学发现。它使研究人员能够定义目标，将智能体基于指定的公共和专有知识源，然后生成和评估新颖假设的景观。

为了能够实现这一点，Co-Scientist产生了一个相互协作的智能体整个生态系统。

**图8：AI合作科学家设计系统**
![图8：AI合作科学家设计系统](images/figure_8_ai_co_scientist_design_system.png)

<!-- Page 48 -->

将系统视为研究项目经理。AI首先采用广泛的研究目标并创建详细的项目计划。然后"主管"智能体充当经理，将任务委托给专业智能体团队并分配计算能力等资源。这种结构确保项目可以轻松扩展，团队的方法在他们朝着最终目标工作时得到改善。

**图9：合作科学家多智能体工作流**
![图9：合作科学家多智能体工作流](images/figure_9_co_scientist_multi_agent_workflow.png)

各种智能体工作数小时，甚至数天，并不断改进生成的假设，运行不仅改进生成的想法，还改进我们判断和创建新想法方式的循环和元循环。

<!-- Page 49 -->

#### AlphaEvolve Agent
#### AlphaEvolve智能体

另一个高级智能体系统的例子是AlphaEvolve，一个发现和优化数学和计算机科学复杂问题算法的AI智能体。

AlphaEvolve通过结合我们Gemini语言模型的创意代码生成和自动评估系统来工作。它使用进化过程：AI生成潜在解决方案，评估器对它们评分，最有前景的想法被用作下一代代码的灵感。

这种方法已经导致了重大突破，包括：
*   提高Google数据中心、芯片设计和AI训练的效率。
*   发现更快的矩阵乘法算法。
*   找到开放数学问题的新解决方案。

AlphaEvolve擅长验证解决方案质量远比首先找到它更容易的问题。

**图10：Alpha Evolve设计系统**
![图10：Alpha Evolve设计系统](images/figure_10_alpha_evolve_design_system.png)

<!-- Page 50 -->

AlphaEvolve设计用于人类和AI之间深入的、迭代的伙伴关系。这种协作以两种主要方式工作：

*   **透明解决方案**：AI以人类可读代码生成解决方案。这种透明性允许用户理解逻辑、获得见解、信任结果，并直接为他们需要修改代码。
*   **专家指导**：人类专业知识对于定义问题至关重要。用户通过改进评估指标和指导探索来指导AI，这防止系统利用问题定义中意外的漏洞。这种交互循环确保最终解决方案既强大又实用。

智能体的结果是代码的持续改进，不断改进人类指定的指标。

**图11：算法进化**
![图11：算法进化](images/figure_11_algorithm_evolution.png)

<!-- Page 51 -->

## Conclusion
## 结论

生成式AI智能体标志着一个关键进化，将人工智能从内容创建的被动工具转变为问题解决的主动、自主伙伴。本文档为理解和构建这些系统提供了正式框架，超越原型以建立可靠、生产级架构。

我们将智能体分解为其三个基本组件：推理模型（"大脑"）、可执行工具（"双手"）和治理编排层（"神经系统"）。正是这些部分的无缝集成，在连续的"思考、行动、观察"循环中操作，释放了智能体的真正潜力。通过分类智能体系统——从第1级连接的问题解决器到第3级协作多智能体系统——架构师和产品负责人现在可以战略性地界定他们的雄心以匹配手头任务的复杂性。

核心挑战和机遇在于新的开发者范式。我们不再仅仅是定义显式逻辑的"砌砖工"；我们是必须指导、约束和调试自主实体的"架构师"和"导演"。使LM如此强大的灵活性也是它们不可靠性的来源。因此，成功不仅仅在于初始提示，而在于应用于整个系统的工程严谨性：在强大的工具合同、弹性错误处理、复杂的上下文管理和全面评估中。

这里概述的原则和架构模式作为基础蓝图。它们是导航这个软件新前沿的指南标，使我们能够构建不仅仅是"工作流自动化"，而是我们团队中真正协作、有能力、适应性强的新成员。随着这项技术成熟，这种纪律性的架构方法将是利用智能体AI全部力量的决定性因素。

<!-- Page 52 -->

## Endnotes
## 结束语

1.  Julia Wiesinger, Patrick Marlow, et al. 2024 "Agents"。可在：https://www.kaggle.com/whitepaper-agents。
2.  Antonio Gulli, Lavi Nigam, et al. 2025 "Agents Companion"。可在：https://www.kaggle.com/whitepaper-agent-companion。
3.  Shunyu Yao, Y. et al., 2022, 'ReAct: Synergizing Reasoning and Acting in Language Models'。可在：https://arxiv.org/abs/2210.03629。
4.  Wei, J., Wang, X. et al., 2023, 'Chain-of-Thought Prompting Elicits Reasoning in Large Language Models'。可在：https://arxiv.org/pdf/2201.11903.pdf。
5.  Shunyu Yao, Y. et al., 2022, 'ReAct: Synergizing Reasoning and Acting in Language Models'。可在：https://arxiv.org/abs/2210.03629。
6.  https://www.amazon.com/Agentic-Design-Patterns-Hands-Intelligent/dp/3032014018
7.  Shunyu Yao, et. al., 2024, 'τ-bench: A Benchmark for Tool-Agent-User Interaction in Real-World Domains', 可在：https://arxiv.org/abs/2406.12045。
8.  https://artificialanalysis.ai/guide
9.  https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/vertex-ai-model-optimizer
10. https://gemini.google/overview/gemini-live/
11. https://cloud.google.com/vision?e=48754805&hl=en
12. https://cloud.google.com/speech-to-text?e=48754805&hl=en
13. https://medium.com/google-cloud/genaiops-operationalize-generative-ai-a-practical-guide-d5bedaa59d78
14. https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/code-execution/overview
15. https://ai.google.dev/gemini-api/docs/function-calling
16. https://github.com/modelcontextprotocol/
17. https://ai.google.dev/gemini-api/docs/google-search

<!-- Page 53 -->

18. https://google.github.io/adk-docs/
19. https://google.github.io/adk-docs/sessions/memory/
20. https://cloud.google.com/architecture/choose-design-pattern-agentic-ai-system
21. https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/overview
22. https://cloud.google.com/kubernetes-engine/docs/concepts/gke-and-cloud-run
23. https://github.com/GoogleCloudPlatform/agent-starter-pack
24. Sokratis Kartakis, 2024, 'GenAI in Production: MLOps or GenAIOps?'。可在：https://medium.com/google-cloud/genai-in-production-mlops-or-genaiops-25691c9becd0。
25. Guangya Liu, Sujay Solomon, 2025年3月 "AI Agent Observability - Evolving Standards and Best Practice"。可在：https://opentelemetry.io/blog/2025/ai-agent-observability/。
26. https://discuss.google.dev/t/agents-are-not-tools/192812
27. Damien Masson et. al, 2024, 'DirectGPT: A Direct Manipulation Interface to Interact with Large Language Models'。可在：https://arxiv.org/abs/2310.03691。
28. MCP UI是通过MCP工具控制UI的系统 https://mcpui.dev/。
29. AG UI是通过事件传递和可选共享状态控制UI的协议 https://ag-ui.com/。
30. A2UI是通过结构化输出和A2A消息传递生成UI的协议 https://github.com/google/A2UI。
31. https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini/2-5-flash-live-api。
32. https://saif.google/focus-on-agents。
33. https://simonwillison.net/series/prompt-injection/。
34. https://storage.googleapis.com/gweb-research2023-media/pubtools/1018686.pdf。
35. https://spiffe.io/。
36. https://openreview.net/pdf?id=l9rATNBB8Y。
37. https://google.github.io/adk-docs/safety/。

<!-- Page 54 -->

38. https://google.github.io/adk-docs/callbacks/design-patterns-and-best-practices/#guardrails-policy-enforcement
39. TKTK
40. https://cloud.google.com/security-command-center/docs/model-armor-overview
41. https://cloud.google.com/vertex-ai/generative-ai/docs/provisioned-throughput/overview
42. https://cloud.google.com/run/sla
43. https://github.com/CharlesQ9/Self-Evolving-Agents
44. Juraj Gottweis, et. al., 2025, 'Accelerating scientific breakthroughs with an AI co-scientist'。可在：https://research.google/blog/accelerating-scientific-breakthroughs-with-an-ai-co-scientist/。
45. Deepak Nathani et. al. 2025, 'MLGym: A New Framework and Benchmark for Advancing AI Research Agents', 可在：https://arxiv.org/abs/2502.14499。