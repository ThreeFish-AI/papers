
### **赋能现实世界：大语言模型驱动的行业智能体技术、实践与评估综述**

**汤一鸿，陈克海，岳亮，范金鑫，周才深，李晓光，张宇阳，赵明明， Kai 世雄，郭凯阳，曾兴山，寸文静，尚立峰，张敏**

**摘要**—随着大语言模型（LLMs）的兴起，能够自主推理、规划并执行复杂任务的LLM智能体已成为人工智能领域的前沿。然而，如何将通用智能体的研究成果转化为推动产业变革的生产力，仍是一个重大挑战。为此，本文系统性地回顾了基于LLM的行业智能体的技术、应用和评估方法。本文采用一个行业智能体能力成熟度框架，勾勒出智能体在行业应用中从“流程执行系统”到“自适应社会系统”的演进路径。首先，我们考察了支撑智能体能力提升的三大关键技术支柱：记忆（Memory）、规划（Planning）和工具使用（Tool Use）。我们讨论了这些技术如何从支持早期的简单任务，演进到赋能更高级的复杂自主系统和群体智能。接着，我们概述了行业智能体在数字工程、科学发现、具身智能、协同业务执行和复杂系统仿真等现实领域中的应用。此外，本文还回顾了基础能力和专业能力的评估基准与方法，指出现有评估体系在真实性、安全性和行业特异性方面所面临的挑战。最后，我们聚焦于行业智能体所面临的实践挑战，探讨其在各种场景下的能力边界、发展潜力和治理问题，并为未来方向提供洞见。通过将技术演进与行业实践相结合，本综述旨在阐明行业智能体的现状，并为理解和构建下一代行业智能体提供清晰的路线图和理论基础。

**索引词**—大语言模型（LLMs），行业，智能体，现实世界。

### **I. 引言**

近年来，大语言模型（LLMs）取得了突破性进展。通过对海量数据进行预训练，它们展现出前所未有的语言理解、生成和推理能力[1]–[3]。然而，LLM作为静态且无状态的预测模型，主要局限于处理文本输入并生成相应的输出。它们难以主动与外部世界交互，或执行需要长期记忆和多步操作的复杂任务[4],[5]。为克服这一局限，研究人员将LLM作为“大脑”，构建能够感知环境、规划、行动并从交互中学习的自主智能体[6]。这些由LLM驱动的智能体集成了记忆模块、规划算法和工具调用接口，将LLM的认知能力与环境中的动态交互相结合，从而形成了能够自主实现开放式目标的通用智能体原型。

随着通用智能体从理论走向实践，其应用场景必然从简单的通用数字环境转向复杂、知识密集且高风险的行业领域[7]。这催生了“行业智能体”的概念。行业智能体是指部署在特定业务场景中，利用领域知识和专业工具来解决现实世界行业问题的自主或半自主系统。例如，Xia等人展示了LLM智能体如何通过规划任务、调用底层控制接口并与数字孪生交互来编排模块化生产系统[8]。与通用智能体相比，行业智能体面临更严峻的挑战。它们不仅必须具备通用认知能力，还必须应对行业特定需求，例如金融领域的高时效性和高风险性[9]、医疗领域的权威知识和安全合规性[10]，以及制造业的物理约束和流程复杂性[11],[12]。关键问题在于如何将通用智能体框架与深厚的行业专业知识、复杂的业务流程和严格的安全标准相结合，从而将智能体的潜力转化为现实生产力。

与此同时，随着基于LLM的智能体研究的快速发展，涌现出大量优秀的综述论文，从不同维度提供了宝贵视角，帮助我们理解该领域。一些综述聚焦于智能体的核心技术模块。例如，[13]系统性地回顾了智能体的记忆机制；[14]对规划能力进行了分类和分析；[15]全面概述了工具学习范式及其实现。此外，[16]从上下文工程的角度优化了LLM推理过程中的信息负载，为高效智能体交互提供了重要支持。这些工作为更深入地理解智能体的技术细节奠定了基础。其他综述则关注通用智能体架构和能力。[6],[17]提出了通用智能体框架并对现有架构进行了分类。同时，[18],[19]等作品探索了推理和自我进化等高级能力的实现路径。值得注意的是，[20]提出了一个模块化的、受大脑启发的智能体认知、感知和操作模块视图，同时也探讨了自我增强进化、多智能体系统和安全部署等关键主题。此外，一些综述聚焦于特定应用领域或高级范式。例如，[21],[22]深入探讨了智能体在科学发现和金融交易中的应用。同时，[23],[24]探索了多智能体系统和智能体RAG范式。更有甚者，[25]全面回顾了LLM赋能的基于智能体的建模与仿真，涵盖了信息、物理、社会和混合场景中的应用。[26]专注于自主研究智能体，为其构建提出了一套系统化的方法论和评估蓝图。最后，[27]从数据和模型协同演进的角度，对科学LLM和智能体的发展进行了以数据为中心的系统性综述和路线图规划。

尽管这些贡献卓著，但在提供一个结合技术演进、应用实践和能力水平，并聚焦于行业落地的系统性框架方面，仍存在空白。为填补这一空白，本文对基于LLM的行业智能体进行了全面综述。具体而言，本综述围绕三个主要领域展开：行业智能体的技术基础、实践应用和现实世界评估。首先，我们深入探讨了支撑智能体能力的三大核心技术：记忆、规划和工具使用，并讨论其技术演进。然后，我们使用一个五级成熟度框架，全景式地展示了行业智能体在各个行业的应用。接着，我们系统性地审视了基础能力和专业行业能力的评估基准与方法，并指出了其局限性。最后，我们聚焦于行业智能体在实践中面临的深层挑战，探讨其瓶颈、未来发展以及应对这些挑战的策略。

总而言之，本文的贡献包括：
- **提出能力成熟度框架**：我们引入了一个创新的行业智能体能力成熟度框架，为评估和理解智能体在各行业中的角色和价值提供了清晰的度量标准。
- **链接技术与应用**：我们将记忆、规划和工具使用这三大核心技术的演进与能力水平联系起来，展示了技术进步如何驱动应用实践的演进。
- **聚焦行业实践与评估**：我们系统性地回顾了智能体在关键行业中的应用和专业评估基准，紧密贴合现实世界的工业需求和挑战。

凭借这一独特视角，我们旨在弥合各领域智能体应用之间的差距，为智能体在现实世界中的成熟与繁荣做出贡献。

### **II. 行业智能体的技术基础**

近年来，基于LLM构建的智能体取得了显著进步。它们在处理复杂任务方面日益成熟的能力，正将人工智能的研究和应用推向更高层次的认知智能。早期的智能体研究通常局限于特定任务。相比之下，新兴的LLM凭借其强大的通用语言理解、推理和交互能力，极大地促进了能够处理开放领域复杂任务的通用智能体的出现。

目前，一个全面的通用智能体框架通常依赖于三大核心技术支柱：**记忆（Memory）**、**规划（Planning）**和**工具使用（Tool Use）**。记忆是指编码、存储和检索信息的能力；规划涉及目标分解以及行动序列的制定与优化；工具使用则是指调用外部API或程序以扩展自身能力的能力。这三个核心模块相互交织、协同工作，构成了智能体感知环境、发展认知并采取行动的基础。这使得智能体能够从简单的指令执行者，演变为能够与环境持续交互并实现复杂目标的自主实体。

然而，随着智能体研究越来越多地覆盖现实场景，其核心架构中的认知瓶颈也愈发明显。这些挑战深刻地反映在三大核心能力——记忆、规划和工具使用的局限性上。在**记忆**领域，有限且单一的上下文窗口使得智能体难以维持长期、连贯的交互历史，导致长上下文遗忘等问题。此外，如何从海量、嘈杂、非结构化的动态环境信息中过滤、提炼并形成结构化的有效记忆，避免信息过载和认知偏差，仍是一个重大的技术瓶颈。在**规划**方面，现实世界的高度动态性和不确定性使得基于静态世界假设的简单规划方法失效。智能体必须具备在执行过程中动态调整计划、处理异常并从失败中学习的鲁棒性，这对它们分解长期目标和有效推理的能力提出了很高要求。关于**工具使用**，随着工具库变得庞大而复杂，如何准确地选择、组合和调用适当的工具来解决问题，以及如何处理工具执行失败或意外结果，成为限制智能体能力上限的关键因素。

这些实际的技术挑战共同构成了理论框架与现实应用之间的鸿沟。为了系统性地分析行业智能体如何从简单的流程自动化工具演变为能够解决复杂领域问题的核心系统，本综述提出了一个面向行业应用能力成熟的五级框架（L1–L5）。该框架旨在揭示，行业智能体在每个能力层级上的跃迁，本质上都是由其在记忆、规划和工具使用这三大核心技术上的演进所驱动的。例如，L1级的流程执行系统仅需瞬时记忆和固定的线性规划，而L5级的自适应社会系统则要求具备跨代积累进化群体记忆的能力，以及在复杂博弈中自主生成目标的能力。

以下各节将深入探讨这三个核心技术模块，分析其技术演进如何支持行业智能体能力的持续升级，从而为行业智能体的开发实践奠定基础。

#### **A. 记忆机制**

记忆是构建高级人工智能的核心组件，尤其是在基于LLM的智能体中。它使智能体能够编码、存储和检索历史信息，使其超越传统计算模型的无状态限制，展现出学习、适应和连贯执行复杂任务的能力。对于旨在解决现实世界问题的行业智能体而言，其记忆机制的复杂性和成熟度决定了它们在特定领域能够达到的能力水平和应用价值。以往的综述通常根据技术实现（如记忆的来源、形式或操作）对现有工作进行分类。虽然这种分类有助于理解技术细节，但未能充分揭示记忆机制的演进如何直接驱动智能体的能力跃迁。本节分析了记忆作为一项核心技术，如何从支持基本的流程执行，演进到支撑自主学习，甚至在复杂系统中支撑群体协作。

**1) 从瞬时记录到被动检索**：在行业应用的早期阶段，智能体的核心价值在于处理显式指令和利用现有知识。其记忆机制主要聚焦于两项基本功能：记录和查询。这一阶段标志着智能体从无状态执行者向能够查阅外部笔记的助手的转变。

在L1级，记忆是瞬时上下文，本质上是工作记忆。在此阶段，智能体作为流程执行系统，其记忆能力主要由LLM的上下文窗口支持。这种记忆是临时的、任务导向的，仅用于在单次交互中保持信息一致性，类似于人类的短期工作记忆。ReAct框架中的思维链（chain of thought）就是这种瞬时工作记忆的例证，它在上下文中显式地保留推理过程以指导后续行动[28]。然而，这种记忆的根本局限在于其有限性和易失性。为了扩展这种有限的记忆容量，LongChat等工作通过微调基础模型，使其能更好地处理和记住更长、更完整的交互[29]。然而，更长的上下文可能会引入干扰。为解决此问题，Memory Sandbox设计了一个交互式记忆管理界面，允许在将记忆输入提示前手动移除无关信息，这反映了对控制瞬时记忆质量的初步尝试[30]。一些系统设计了更结构化的短期记忆，例如RecAgent中用于推荐场景的短期记忆缓存[31]，以及MemGPT中用于保存最近交互历史的闪存或工作上下文[32]。这些可以被视为对瞬时记忆的优化，但并未改变其在任务完成后即被遗忘的本质。

在L2级，记忆演变为被动检索，标志着长期记忆的出现。当智能体作为交互式问题解决系统时，仅依靠上下文记忆不足以处理需要领域知识的查询。因此，记忆机制的一个关键演进是连接到外部知识库，实现从无状态到有知识的转变。此阶段记忆的核心是检索增强生成（RAG），它使智能体能够被动地从外部源检索信息以增强其响应[165]。Toolformer[71]和ToolLLM[75]等工作教导模型如何使用工具和成千上万的真实API，为获取外部知识奠定了基础。在通用场景中，ReAct展示了如何调用维基百科API[28]。在行业应用中，这种检索变得更加有针对性：在软件工程中，CodeAgent[166]设计了网络搜索策略以解决代码依赖问题；在游戏领域，GITM[33]从在线Minecraft Wiki中汲取知识；在科学计算中，ToRA[167]增强了智能体使用程序化工具的能力，而ChemCrow[106]则为LLM配备了化学工具；在专业问答中，ChatDoctor[34]微调了检索模型以从维基百科和医学数据库中获取知识。这些外部知识库构成了智能体稳定可靠的长期记忆的雏形。高效的检索技术也日益多样化。例如，ChatDB[35]生成SQL查询以从结构化数据库中进行精确检索，MemoryBank[36]使用双塔稠密检索模型，而RET-LLM[37]则采用局部敏感哈希进行快速读取。Memory Decoder[38]是一个即插即用的预训练记忆组件，它模仿外部非参数检索器的行为，以实现高效的领域适配，在不修改原始模型参数的情况下提升在专业领域的性能。在此阶段，尽管智能体拥有长期记忆，但记忆是静态和外部的。智能体本身并未学习这些知识，而仅仅是更高效的查询者，其能力边界受限于外部知识库的质量和检索算法的精度。

**2) 主动学习与经验内化**：在L3级，智能体演变为能够以闭环方式完成复杂任务的端到端系统。这一进步标志着其记忆机制的根本性转变。记忆从被动的信息存储和检索，转变为一个主动的、动态的系统，能够促进学习和经验内化。这一进步的核心是智能体获得了元认知能力，能够进行自我反思并从经验中提取可操作的洞见。

此阶段的一个决定性特征是智能体具备从其交互历史中主动学习的能力。这些经验来源多样。有些源于个体任务执行过程中的观察，例如在Generative Agents[42]中，智能体记录其在模拟世界中的所有行动；在Voyager[168]中，智能体记录在Minecraft中成功执行的可重用代码。更有价值的经验则源于对多次任务尝试中成功与失败的分析。Reflexion框架引入了言语强化学习，允许智能体反思其行动并将结果存储在记忆中[169]。Retroformer通过微调反思模型，以更有效地进行跨实验信息提取[170]。ExpeL[171]和Synapse[172]利用成功的任务轨迹作为范例，检索相似的过往案例以指导新任务。在此阶段，智能体超越了单纯的信息消费者；它们成为经验和知识的生产者与提炼者。通过反思，它们将离散的、一阶的交互记录转化为结构化的、高阶的行动指南，为自主改进和长期任务规划奠定了认知基础。

此外，L3级智能体不仅检索经验，还将其内化，将外部知识转化为内部记忆。传统的内化方法涉及微调。例如，Character-LLM在角色特定数据（如剧本）上进行微调，将角色特质嵌入模型参数[173]。在专业领域，Huatuo[174]、DoctorGLM[175]和Radiology-GPT[176]分别在中文医学知识、医学数据和放射学数据集上进行微调，赋予智能体专业的生物医学知识。InvestLM则为金融投资能力进行微调[177]。除了微调，更精细的记忆编辑技术正在涌现，允许在不重新训练的情况下修改模型参数中的特定知识。MEND[178]和KnowledgeEditor[179]训练轻量级编辑网络来预测参数更新，以实现快速的事实知识修改。MAC[180]采用元学习进行在线参数化记忆适配，而PersonalityEdit[181]则基于大五人格模型等心理学理论，实现对智能体人格特质的精确编辑。传统的微调和知识编辑代表了从知识存储到能力培养的深刻转变，是端到端自主系统的技术前提。然而，它们往往难以控制且可解释性较差。

在记忆领域，一种更通用的内化方法是非参数记忆管理，包括：
1)  **记忆写入**：高效地将原始信息存储到记忆中。TiM[39]将信息提取为实体关系并存储在结构化数据库中；MemoChat[40]将对话片段总结为主题作为索引键；MemGPT[32]实现了自我引导的记忆更新；SCM[41]设计了记忆控制器以确定何时执行写入操作。
2)  **记忆管理与提炼**：从海量记忆中提取价值并防止退化。Generative Agents[42]通过反思过程生成更高层次的抽象思维；MemoryBank[36]将日常对话提炼为高层次的每日摘要；GITM[33]从多个计划中总结关键行动；Voyager[168]根据环境反馈（例如代码执行成功）优化和提炼其技能库。
3)  **记忆读取**：根据当前任务检索最相关的记忆。ChatDB[35]生成SQL查询进行检索；ExpeL[171]使用Faiss向量库检索前K个最相似的成功轨迹；MPC[182]提供思维链示例，以指导模型忽略无关记忆。

为整合这些过程，Mem0采用了可扩展的记忆中心架构，动态地从对话中提取、整合和检索关键信息，显著增强了长对话的一致性并降低了计算开销[183]。升级版的Mem0将记忆表示为实体关系图，捕捉复杂的时序和多跳推理逻辑，特别适用于跨会话和跨时间点的对话。它借鉴了卡片盒笔记法（Zettelkasten）的理念，采用原子化笔记结构、多维语义表示以及向量检索与LLM分析相结合的方式，实现了记忆的自动链接和自我进化。

**3) 群体记忆的涌现**：在L4及以上级别，行业应用从单智能体系统扩展到复杂的多智能体协作，从而催生了群体记忆。

L4级的记忆是分布式的和共享的。当多个智能体协作以实现一个宏大目标时，它们必须依赖一个共享的认知空间，形成其群体记忆。Memory-R1使大模型能够通过两个智能体之间的交替操作来主动管理和利用外部记忆[43]。此外，多智能体框架如AutoGen[44]、ChatDev[46]和MetaGPT[45]提供了实现范例。在这些系统中，所有智能体角色共享一个统一的上下文，包括需求文档、代码库和API规范。例如，在ChatDev模拟的软件开发中，每个智能体都存储与其他角色的过往对话[46]。在MetaGPT中，智能体可以从记忆中检索历史记录以解决错误[45]。在更广泛的协作场景中，如S³社交网络模拟，每个智能体的记忆池包含多样化的用户消息以定义其身份[184]。在Job模拟MetaAgents中，记忆通过对话和反思不断丰富[185]。在代码修复场景RTLFixer中，一个外部共享数据库存储编译器错误和专家修复指令[186]。共享记忆是高效协作的基础，确保所有个体基于一致的信息进行沟通与合作，从而避免信息孤岛和认知偏差。它是协调复杂业务流程的先决条件。尽管提出了各种多智能体通信协议和拓扑结构，但这种记忆仍然是同步的和任务导向的。

L5级的记忆构想了一种进化和文化形式。在此级别，记忆不仅在智能体间共享，还会随着时间的推移而积累、固化和进化，形成一种类似于人类社会的文化。它记录了群体的成功策略、失败教训和共享价值观，这些可以被新加入的智能体继承。在Generative Agents中，智能体社会内的信息传播展示了这种原始形态的记忆[42]。Aivilization将这一概念扩展到更大的社区，构建了一个涵盖经济、工业、政治和社会互动的高度逼真的虚拟社会[47]。在特定的模拟中，如WarAgent的战争模拟，参与国的对话被持续记录在记忆中，塑造了它们的长期行为[48]。在角色扮演应用如ChatHaruhi[49]和RoleLLM[50]中，通过注入角色特定知识和情节记忆，智能体展现出一致的身份，反映了微观层面的文化形式。探索L5级记忆涉及思考如何构建一个能够自我改进和可持续发展的智能体社会。这需要记忆机制不仅能记录“是什么”，还能封装“为什么是这样”和“应该如何”，从而为智能体社区中的长期价值对齐和目标演进提供基础。

**4) 记忆管理的现实挑战**：高效的记忆机制并不等同于完美的性能。[187]的实证研究表明，LLM智能体表现出明显的“经验跟随”行为，即它们倾向于复制与当前任务相似的过往经验。这一特性引入了两大主要风险：**错误传播**，即早期记忆中的错误会在后续决策中被放大；以及**不匹配的经验回放**，即过时或不相关的记忆会负面干扰当前任务。他们的研究强调了实施精细化的记忆增删策略以维持智能体长期鲁棒性的重要性。同时，Wang等人系统性地识别了智能体记忆模块中的隐私漏洞[188]。他们引入了记忆提取攻击（MEXTRA），证明即使在黑盒设置下，攻击者也能通过提示工程从记忆中提取存储的敏感用户交互。他们的发现强调了在医疗、金融和法律等高风险、高监管领域，构建安全可控的记忆系统的必要性。这些研究共同凸显了记忆研究中的一个核心挑战：需要开发不仅在学习上有效，而且在安全、可控和可维护方面都表现出色的记忆系统。

#### **B. 规划能力**

规划是智能体的一项核心认知能力。它决定了智能体如何将抽象目标分解为一系列可执行的动作，以在环境中实现其意图。在行业智能体的背景下，规划能力直接关系到其自主性、可靠性和问题解决的复杂性。一个强大的规划模块使智能体不仅能理解“做什么”，还能自主决定“怎么做”，并在动态环境中进行调整和优化。本节系统性地回顾了规划技术如何从简单的任务分解演进到复杂的反思式、协作式和生成式规划，从而驱动行业智能体在不同成熟度阶段创造核心价值。规划能力的每一次飞跃，都标志着智能体向更高自主性和智能性迈出了基础性的一步。

**1) 从线性推理到多轮交互**：在L1-L2阶段，智能体主要充当人类助手或工具，其规划能力聚焦于准确理解用户指令并将其分解为可执行步骤。在L1级，规划是线性指令分解，本质上是开环规划。其核心是遵循一条相对固定的预设路径来完成任务。此阶段的一个突破是思维链（CoT）提示技术，它引导LLM生成中间推理步骤，显著增强了其处理复杂问题的能力[51]。然而，CoT本质上是一个线性的、一次性生成过程，缺乏与环境的交互和修正。Re-Prompting通过利用前置条件错误信息重新提示LLM，生成可执行的计划，从而增强了计划的可执行性和语义正确性[52]。Zero-shot-CoT的出现进一步简化了这一过程，只需“让我们一步步思考”这样的短语即可触发模型的初始推理能力[53]。Plan-and-Solve Prompting通过明确地将任务分为“先规划，后执行”步骤来结构化这一过程，为更可靠的执行奠定了基础[189]。线性规划使智能体能够处理多步逻辑问题，但它假设环境是静态的且初始规划是完美的，这在不断变化的现实世界中往往不成立，导致鲁棒性降低。

在L2级，规划演变为反应式规划，实现了闭环控制。智能体不再仅仅是被动地分解任务，而是能够与环境或工具交互，并根据反馈动态调整后续步骤。
ReAct框架是此阶段的一个里程碑，它将推理和行动解耦并交织在一起，允许智能体在执行中思考，在思考后行动[28]。这种“思考-行动-观察”循环构成了反应式规划的核心。这种模式在需要与外部工具交互的场景中尤为关键。例如，Visual ChatGPT利用ReAct机制，使用LLM作为大脑来编排一系列视觉基础模型以完成图像处理任务[28]。DEPS通过结合规划执行过程的描述、失败后的自我解释以及一个可训练的目标选择器（用于估计完成步骤以并行子目标），增强了开放世界环境中多任务智能体的任务规划能力[54]。为了使规划过程更加严谨和可预测，研究人员探索了将自然语言规划转换为更形式化语言的方法。PAL[70]和思维程序提示（PoT）[58]引导LLM将推理过程表达为可执行代码，利用代码解释器的确定性来确保结果准确性。ProgPrompt采用了类似的方法，将机器人任务规划转化为函数生成问题[55]。此外，为了满足工业应用的高可靠性要求，一系列工作将LLM与经典符号规划器相结合。LLM+P[56]、LLM+PDDL[190]和LLM+ASP[191]等框架使用LLM将自然语言问题转换为PDDL或ASP等形式化表示，然后调用外部优化规划器来求解，从而获得最优且可靠的计划。在企业环境中，Routine框架通过提供清晰的结构和指令，实现了稳定的多步工具调用规划[57]。在游戏场景中，Voyager通过自动课程规划，在无人干预的Minecraft环境中实现了持续探索、技能获取和自主发现[168]。反应式规划极大地增强了智能体在动态环境中的适应性，但通常具有局部的、短视的规划视角。它擅长“随机应变”，但在“深谋远虑”方面存在困难，难以解决需要长期规划和权衡的复杂问题。

**2) 全局规划——反思、迭代与深度探索**：随着智能体进入L3级，成为“端到端自主系统”，其规划能力必须应对复杂、动态和不确定的环境。这需要规划过程具备非线性的深度探索、自我修正和持续学习能力。

最初，规划从线性链演变为树状或图状探索。与CoT[51]相比，思维树（ToT）[59]和思维图（GoT）[192]显著扩展了规划的探索空间。ToT将推理路径组织成树结构，允许智能体探索、评估甚至回溯多条潜在解决方案，以选择全局最优路径。GoT进一步将思维过程建模为图，支持更复杂的思维聚合和转换，从而增强了求解复杂问题的能力。

为了在广阔的搜索空间中高效导航，LLM-MCTS[60]和“将语言模型推理视为世界模型规划”（RAP）[61]等框架创新性地将LLM用作蒙特卡洛树搜索（MCTS）[193]中的启发式函数，引导搜索过程以平衡探索与利用。通过引入系统性的搜索策略，智能体从贪婪的决策者演变为能够进行权衡和远见的决策者，这对于求解具有多条潜在路径和陷阱的复杂问题至关重要。自我反思和修正成为核心机制，将规划从一次性过程转变为迭代优化循环。智能体不再是“一锤子买卖”的规划者；它们具备从经验和失败中学习的能力。

Reflexion框架在ReAct的基础上增加了一个自我反思循环，使智能体能够分析失败轨迹，生成文本反思，并将其存储在记忆中以指导后续尝试[169]。Self-Refine引入了一种无需外部训练的迭代优化过程，智能体生成解决方案，对其进行反馈，并在后续轮次中优化解决方案[194]。CRITIC框架利用外部工具（如知识库和搜索引擎）来验证和批判智能体生成的行动，并利用外部反馈进行自我修正[62]。LEMA框架收集错误的规划样本，利用更强大的模型进行修正，并用这些修正后的样本微调原始模型[63]。

在更具体的应用中，例如形式化数学证明，Delta Prover框架通过LLM与Lean 4证明环境之间的交互、反思和推理，迭代地构建证明[195]。在机器人领域，条件多阶段故障恢复框架为具身智能体设计了多阶段故障恢复策略，增强了其在现实环境中执行任务的鲁棒性[196]。

全面而宏观的反思机制使智能体能够从错误中吸取教训。这赋予了规划以韧性，使智能体能够从错误中恢复并持续改进，这是实现端到端自主的关键。

**3) 协同规划与自主目标设定**：在L4级及以上，规划的范围从单个智能体扩展到由多个智能体组成的系统，规划的概念从任务执行拓宽到协同策略和社会演化。

在L4级，规划聚焦于多个智能体如何通过沟通和协商来制定和执行群体计划，以实现共同目标。早期的探索，如HuggingGPT，利用LLM作为控制器来协调Hugging Face Hub上的多个模型，以协同完成多模态任务[64]。这可以被视为协同规划的雏形。多智能体协同规划在各个领域展现出巨大潜力。例如，CodeEdu[65]和AI-Powered Math Tutoring[197]分别建立了多智能体协作平台，用于个性化编程和数学教育。在6G网络优化等复杂技术场景中，RIDAS框架引入了一个由表征驱动智能体（RDAs）和意图驱动智能体（IDAs）组成的多智能体系统，以弥合高层用户意图与底层网络配置之间的鸿沟[66]。Aime框架解决了多智能体系统中计划执行僵化和通信效率低下的问题，实现了动态和反应式的群体规划[67]。规划的重点从“我该做什么？”转变为“我们该如何分工协作？”。这要求智能体不仅要规划自己的行动，还要预测和理解他人的意图和行为，以便在复杂的社会环境中进行战略性互动。

在L5级，规划构想的是自主目标设定和价值对齐。在此场景下，与L1-L4级不同，智能体不仅是计划的执行者，也是目标的提出者和环境的塑造者。Generative Agents使智能体能够根据其记忆流规划日常行为，成功模拟了可信的人类社会互动，展示了规划在社会模拟中的潜力[42]。关于LLM用于基于智能体建模（ABM）的研究，系统性地探索了LLM在整个ABM周期（从问题构建到结果传播）中的应用，为模拟复杂的社会经济系统提供了洞见[198]。概念性工作《迈向AI城市规划师》将城市规划视为一个生成式AI任务，智能体在各种约束下生成土地利用规划，代表了智能体参与改造物理世界的宏大愿景[68]。SE-VLN框架引入了自我进化能力，允许智能体在测试过程中持续学习和进化，这是迈向L5自适应系统的关键特征[69]。

对L5级规划的讨论触及了人工智能的终极问题：机器能否拥有自己的愿景？这需要将规划能力与价值体系深度融合，使智能体能够在动态演化的价值框架内，自主生成与长期利益一致的创造性目标。

- **可靠性与不确定性管理**：现实世界是动态且不可预测的。LLM-DP专为动态交互环境设计[199]。它将反馈形式化为PDDL，并利用BFS求解器来适应变化。在《通过自动化驯服不确定性》中引入的AgentOps框架，旨在通过观察、分析和优化来自动化管理智能体系统，增强其在不确定环境中的稳定性[200]。
- **安全性与可信度**：随着智能体能力的增强，新的安全风险也随之出现。逻辑层提示控制注入（LPCI）揭示了一种新型攻击方法，攻击者将恶意载荷嵌入记忆或工具输出中，从而实现延迟或条件触发的攻击[201]。
- **部署与实现**：在现实环境中高效部署复杂的规划框架仍然是一个重大挑战。Amico框架专注于为嵌入式系统构建模块化、事件驱动的自主智能体[202]。LLM智能体的通用模块化工具包为游戏环境设计了通用模块化组件。AirLLM探索了在无线通信场景中远程微调LLM的技术[203]。
- **基础理论理解**：LLM执行规划的底层算法机制尚不明确。在《立场：我们需要对生成式AI的算法理解》中提出的AlgEval框架，旨在系统性地研究LLM所学习的算法原语及其组合，以加深我们对生成式AI的基础理解[204]。
- **知识与工具的深度融合**：未来的规划需要更有效地利用结构化知识和外部工具。《推进检索增强生成》探索了用于企业结构化数据的高级RAG框架[165]。KG2data将知识图谱与ReAct智能体结合，以支持更智能的数据查询[28]。思维内省（INoT）使LLM能够读取和执行类代码的对话流，实现更深层次的程序化推理[205]。

总而言之，规划能力的演进是通往行业智能体成熟的关键路径。未来的研究需要在多个维度上推进，包括增强规划的复杂性、确保可靠性和安全性，以及加深基础理论理解。

#### **C. 工具使用**

工具使用是区分智能体与传统模型的第三项核心技术。它使智能体能够超越其固有的知识和能力，与广阔的数字和物理世界进行交互。对于行业智能体而言，工具是深入特定领域、执行专业任务以及确保信息时效性和准确性的关键。没有工具，智能体只是封闭、静态的数字实体；有了工具，它们就演变为能够调用计算器、访问数据库、浏览网络、控制软件甚至操作物理设备的领域专家。本节考察了工具使用技术如何从简单的API调用演进到复杂的工具创造，并分析了这一演进如何支持行业智能体从基本的问答系统转变为能够自主修改环境的复杂系统。

**1) 从指令驱动到目标驱动**：在L1-L2阶段，工具使用解决了智能体的两个基本局限：事实知识的滞后性和精确响应能力的缺乏。核心转变是从无工具到拥有工具箱，标志着智能体从单纯的思考者转变为初步的行动者。

L1级的工具使用是固化的和隐式的指令驱动。在此阶段，工具更像是模型的固有能力，而非可选择的外部模块。它们的调用是固定的、非选择性的。CoT的成功本质上是将推理视为一种隐式工具[51]。程序辅助语言模型（PAL）通过使用代码解释器作为固定的外部工具，生成代码来解决数学和逻辑问题，显著增强了结果的确定性[70]。这些早期探索，以及GPT-4和Claude等强大的基础模型，为更复杂的工具使用奠定了基础[1]。在此阶段，工具使用是被动和预定义的；智能体并未意识到自己在使用工具，只是遵循特定的输出格式，这限制了其灵活性和泛化能力。

L2级的工具使用演变为目标驱动的选择性调用。智能体开始充当调度员，能够根据任务需求从预定义的工具集中选择并调用适当的工具。Toolformer是此阶段的开创性工作，它使LLM能够通过自监督学习自主决定何时、何地以及如何调用API[71]。ReAct框架通过交织思维和行动，提供了一个核心的行动范式，允许智能体动态地与工具交互[28]。在此基础上，工具的多样性和规模迅速扩展：WebGPT[72]和WebShop[73]分别探索了使用浏览器作为工具进行问答和在模拟购物网站中交互；TALM[74]微调模型以将工具输出集成到文本生成中；而ToolLLM[75]、Gorilla[76]和TaskMatrix.AI[206]旨在使模型掌握成千上万甚至数百万个真实世界的API。为了促进此类应用的开发，LangChain和BMTools等开源框架应运而生，显著降低了入门门槛。智能体获得了选择工具的自由，极大地扩展了其能力。然而，它们仍然是“工具使用者”，其能力上限受限于预定义的工具库。它们擅长使用现有工具，但无法处理超出可用工具集的新问题。

**2) 端到端自主系统中的工具使用**：随着智能体进入L3级，成为端到端系统，它们会遇到需要多个工具协作且执行过程不确定的复杂任务。在此阶段，工具使用能力表现为工具组合规划、故障修正，甚至初步的创造力。智能体的角色从工具使用者演变为工具编排者。

首先是工具的组合与规划。对于复杂任务，单个工具往往无法提供解决方案。L3级智能体必须能够将多个简单工具组合成一个复杂的工具链来完成任务。ART[77]和Chameleon[78]等框架使智能体能够进行多步推理，自主分解任务，并规划一系列工具调用。ToolChain[79]和ToolNet[80]引入了A*搜索和图结构等方法，以帮助智能体在庞大的工具空间中更高效地导航和规划。MetaMCP动态地将多个MCP服务聚合成一个统一的MCP实例，支持中间件处理，并作为一个标准的MCP服务器，允许与任何MCP客户端无缝集成。工具组合能力对于智能体解决复杂问题至关重要[81]。它代表了一种更高层次的规划能力，不仅要规划“做什么”，还要规划“使用什么工具”，使智能体能够处理超出单个工具能力的系统性任务。

其次是交互过程中的鲁棒性和自我修正。现实世界中的工具调用经常会遇到失败，例如API不可用、参数错误或返回异常。L3级智能体必须具备处理这些异常的能力。CRITIC框架通过与外部工具的交互，赋予智能体自我验证和修正的能力[62]。《工具链中的蝴蝶效应》一文深入探讨了工具调用中参数填充失败的各种原因，为增强交互可靠性提供了洞见[207]。在软件工程等专业领域，LibLMFuzz[208]和BugScope[209]等工具展示了智能体如何利用工具链自主分析二进制文件、发现并修复软件错误。自我修正能力使工具使用变得具有韧性。智能体从脆弱的执行者转变为能够进行故障排除和解决问题的工程师，这对于在不可靠的现实环境中部署至关重要。

最后是领域特定的专业工具包。在此阶段，智能体开始在特定行业中得到深入应用，其工具箱也变得越来越专业化。在科学发现领域，LeanTree[82]和ProofCompass[210]等工具与LLM结合，在Lean 4等环境中加速形式化定理证明。在医疗领域，OrthoInsight[211]框架集成了YOLOv9模型和医学知识图谱作为工具，以辅助医生诊断肋骨骨折。在代码开发中，ToolCoder[212]训练模型使用API搜索引擎来发现和利用不熟悉的API，从而增强代码生成能力。这标志着工具使用从通用目的向专业化的转变，为行业智能体创造核心价值奠定了基础。

**3) 从协同执行到环境改造**：在L4级及以上，工具使用的重点从个体能力转向群体协作，最终目标是智能体主动改造其环境。

L4级的工具使用是协同执行。在此级别，多个智能体组成一个团队，协同操作一套共享的工具以实现宏大目标。HuggingGPT是这一概念的早期范例。它利用ChatGPT作为决策者，编排Hugging Face社区中的各种模型来解决多模态任务[64]。在更具体的行业应用中，CodeEdu[65]等系统构建了多智能体平台，结合工具为学生提供个性化的编程教育；GasAgent[83]采用多智能体系统自动优化智能合约中的Gas使用；IM-Chat[84]通过多智能体框架促进注塑行业的知识转移。为了更好地设计和管理此类复杂的工作流，FlowForge提供了一个交互式可视化工具，作为构建多智能体工作流的基础环境[85]。在这些场景中，工具使用的单元从个体转变为组织，这不仅增强了任务的规模和复杂性，还引入了资源分配、任务调度和协同操作等新挑战，使得工具管理本身成为一个复杂的规划问题。

L5级的工具使用涉及创造与进化。这代表了工具使用的最高形式，智能体不再仅仅是工具的使用者，而是成为工具的创造者。自主智能体的早期探索，如Auto-GPT[86]和BabyAGI[87]，能够自主链接现有工具以完成开放式目标，展示了这种自主性的雏形。CREATOR框架在此方向上树立了一个里程碑[88]。它允许LLM在解决问题过程中识别能力差距，并自主创造新工具。这种工具创造能力使智能体从环境的单纯适应者转变为环境的主动改造者。它们能够根据需求动态扩展自己的能力，而不是被动地等待人类提供新工具或检索现有工具。这种元能力是迈向真正自主和通用智能的关键一步，尽管它仍然是一个需要进一步探索的领域。

**4) 工具使用在现实世界中的挑战**：工具使用领域的快速发展伴随着一系列关键挑战，这些挑战横跨评估、安全、实现机制等方面，催生了广泛的前沿研究：
- **安全性与可靠性**：随着智能体越来越多地连接到真实世界的API，安全问题变得愈发突出。ToolSword系统性地暴露了工具学习在选择、执行和集成三个阶段的安全漏洞[213]。InjecAgent专门评估了针对集成工具的智能体的“间接提示注入”攻击[214]。
- **底层实现与优化**：研究人员也在探索更基础的实现机制。ToolkenGPT[215]提出将工具表示为特殊的Toolken嵌入，并将其集成到模型的词汇表中，使即使是未经再训练的模型也能使用工具。《探测Transformer架构中的信息分布》[216]使用熵分析来探索信息在模型内部的流动方式。《教老SAE学习新领域技巧》[217]研究了如何在不进行完整再训练的情况下使模型适应新领域和新工具。
- **深化行业应用**：在现实世界行业中部署启用工具的智能体，需要克服模拟行业环境真实性不足的挑战。AgentFly框架旨在通过强化学习来增强语言模型智能体的能力[218]。WebShaper利用工具进行信息检索，以更自动化的方式构建高质量数据集[219]。然而，在现有的工具调用环境与现实场景之间仍存在显著差距。

### **III. 行业智能体的应用实践**

在系统性地分析了支撑智能体能力的三大基础技术——记忆、规划和工具使用之后，本章将重点转向行业智能体的应用实践。我们使用L1到L5的能力层级框架，全面回顾并呈现行业智能体在现实世界中的具体实现。这三大技术的演进并非孤立的理论探索，而是与智能体在各行业中扮演的角色、所解决的问题的复杂性以及所创造的价值深度交织在一起。

在L1级，智能体作为**流程执行系统**，准确地转译人类指令。在L2级，它们演变为**交互式问题解决系统**，成为人类的有效助手。在L3级，它们作为**端到端自主系统**，独立完成领域内的复杂任务。在L4级，智能体转变为**协同智能系统**，关注点从个体转向组织，通过群体协作执行复杂的业务流程或进行系统仿真。最终，在L5级，智能体达到顶峰，成为**自适应社会系统**，不仅能适应环境，还能成为自主生成目标、进化价值观并与环境共同演化的创造者。本章将分析每个层级的代表性研究和应用案例，描绘出行业智能体从理论到实践的发展全景图。

#### **A. 流程执行系统**

在L1级，智能体充当流程执行系统。其核心价值在于成为人类指令的可靠延伸，主要体现在两个方面：准确地将非结构化的人类语言翻译成机器可执行的形式化语言，以及从海量信息中自动化地提取结构化数据以执行固定的业务规则。在此阶段，智能体充当数字世界中的基础翻译器和执行者。

**1) 从自然语言到形式化语言的翻译**：将自然语言无缝转换为形式化语言是L1级智能体的关键能力，显著降低了专业软件和系统的使用门槛。

在数据库交互领域，Text-to-SQL技术是典型代表。HydraNet[89]创新性地将Text-to-SQL任务表述为列级排序问题，有效利用了预训练LLM的原生能力，在WikiSQL[220]等基准上取得了领先性能。为了进一步提高复杂查询的准确性，SQL-PaLM框架结合了少样本提示、指令微调和执行反馈机制，显著提升了模型性能[90]。DIN-SQL[91]采用将复杂问题分解为子问题并逐步解决的策略，在Spider[221]和BIRD[222]等更具挑战性的基准上达到了新的最先进水平。针对特定行业需求，FinStat2SQL设计了一个轻量高效的多智能体框架，专用于越南会计准则，展示了该技术在专业领域的应用潜力[223]。

在工业设计领域，Text-to-CAD是另一个重要的应用方向，旨在直接将产品描述转换为三维模型。已提出了多种技术路径：CADFusion[92]和Text2CAD[224]通过视觉反馈和中间视图生成来确保模型的几何精度和逻辑一致性。其他方法，如CadQuery[93]和CAD-Coder[225]，直接生成可执行的CAD建模脚本，利用代码的确定性来保证生成质量。为了解决训练数据稀缺的问题，CADmium[226]和CAD-Llama[227]等工作通过大规模数据集生成和自适应预训练，显著增强了模型的生成能力。此外，FlexCAD[94]实现了跨构建层次的可控生成，而CAD-MLLM[228]构建了首个能够处理文本、图像或点云输入的多模态CAD框架，展示了更强的通用性。

**2) 结构化信息提取与处理**：除了语言翻译，L1级智能体还广泛应用于从非结构化文档和数据流中提取关键信息。LayoutLM系列模型，包括LayoutLM[95]和LayoutXLM[96]，是该领域的开创性工作。通过联合建模文本、布局和视觉信息，它们显著提高了在表格和收据等富文本文档中的信息提取准确性。

这项技术也催生了新的应用范式。例如，已实现了一个基于LLM的端到端框架，用于自动化电话调查和结果分析，大大提高了医疗等领域数据收集的效率[97]。在实时数据处理中，LLM也被用于增强传统的机器学习模型。例如，在垃圾邮件检测任务中，集成方法显著增强了系统的鲁棒性和适应性[229]。

#### **B. 交互式问题解决系统**

当智能体演进到L2级时，它们从简单的命令执行者转变为交互式问题解决系统，在数字世界中充当人类的副驾驶或助手。其能力体现在两个核心场景中：首先，作为高效的工具，通过与软件和网络环境的交互来增强人类的执行力；其次，作为知识渊博的顾问，通过知识探索和整合来改善人类的决策。

**1) 交互式执行与增强**：L2级智能体的核心任务之一是理解用户意图，并将其转化为在图形用户界面（GUIs）或网页上的一系列操作，从而实现任务自动化。在桌面和Web应用自动化领域，涌现出一系列创新框架。UFO[98]和LLMPA[230]利用大型视觉或语言模型，实现对Windows和移动应用的自然语言控制。CogAgent[99]和SeeClick[231]通过优化的视觉编码和定位预训练，提高了GUI元素识别的准确性。WebVoyager[161]和WebAgent[100]专注于Web环境，通过集成多模态信息或采用模块化程序生成，在真实网站上完成复杂的开放式任务。为了提高这些交互的鲁棒性，LASER[232]和Rollback[101]机制引入了回溯能力，使智能体能够从错误中恢复。语言智能体树搜索和最佳优先树搜索等算法通过更系统的探索和规划，提高了复杂任务的成功率。WebArena[160]和Mind2Web[233]提供了包含真实网站和多样化任务的评估环境。OpenAgents[102]和OpenWebAgent[234]等开源平台降低了开发门槛，促进了这些技术在现实场景中的应用。

此外，大量研究集中在优化数据、模型架构和学习范式上。ScribeAgent[235]和WEPO[236]分别通过利用生产级工作流数据和无监督偏好学习来增强模型性能。Agent-E[237]和R2D2[238]通过架构优化实现了更高效的环境感知和记忆利用。SkillWeaver[239]和ASI[240]探索了智能体自主学习和利用可重用技能的方法，提高了其自我改进能力。在移动设备上，Mobile-Agent-v2[241]通过涉及规划、决策和反思的三智能体架构解决了移动操作中的导航挑战。VisionTasker[242]和DroidBot-GPT[103]通过利用视觉UI理解和GUI状态的自然语言转换，实现了精确的移动任务自动化。这些努力共同构成了L2级智能体作为数字劳动力的技术基础，将人类从繁琐的重复性任务中解放出来。

**2) 知识探索与决策支持**：作为顾问，L2级智能体利用其强大的语言理解和工具利用能力，在专业领域为人类提供深入的决策支持。这种能力植根于ReAct、Toolformer和PAL等框架，这些框架使LLM能够调用外部工具、执行代码并与知识库交互。

在金融领域，智能体被用于市场分析和策略模拟。LLM-Trader框架通过模拟交易智能体的交互来分析市场动态，而ElliottAgents[104]则构建了多智能体系统进行协同技术分析。专有模型如Agentar-Fin-R1[105]被开发用于增强金融智能，而InvestAlign[243]框架通过与人类决策过程对齐来提高模型的可解释性。

在科学和医学领域，智能体正成为研究人员和医生的宝贵助手。ChemCrow[106]和ChemAgent[244]为LLM配备了专业的化学工具集，使其能够自主规划和执行化学合成等任务。在医学领域，Discuss-RAG[245]通过多智能体辩论增强了医学问答的准确性，MEDDxAgent[107]通过迭代学习改进了鉴别诊断，而MedRAX[246]和MedAide[247]等框架则整合了多源医学数据，为复杂查询提供可靠支持。

学术研究过程本身也成为自动化的对象。ResearchArena[248]和LitSearch[249]等基准用于评估LLM在文献检索和综述任务中的表现。CiteAgent[250]和ResearchAgent[108]等系统能够自主阅读论文、进行引用归因或提出新的研究思路。Agent Laboratory[251]和AI Scientist[115],[252]等框架实现了从研究构想到论文写作的全流程自动化，展示了AI在加速科学发现方面的巨大潜力。

此外，L2级智能体的能力在更多专业领域得到广泛应用，展示了其作为赋能平台的潜力。在教育领域，智能体正成为个性化导师。EduAgent[253]利用认知先验模拟学生行为以生成学习数据，而IntelliTutor[254]则构建了一个涵盖课程规划、个性化教学和评估的综合性智能辅导系统。

在法律领域，AdvEvol[255]框架通过在模拟法庭中的对抗性进化，增强了法律智能体的动态知识学习和推理能力。在内容创作领域，专有的LLM如Weaver通过针对性的微调，在创意和专业写作任务上超越了通用模型。在代码生成方面，MapCoder[256]通过多智能体框架模拟了人类软件开发的完整周期，而StarCoder在开源代码大模型上取得了性能突破，达到了许多闭源模型的水平。

#### **C. 端到端自主系统**

达到三级（L3）的自主系统是端到端自主智能体。这些智能体不再仅仅是人类的助手；它们能够自主处理从接收高层目标到最终完成任务的整个过程。根据其工作领域，这些系统可分为三大类型：数字世界、物理世界和科学探索。

**1) 自主数字工程**：在数字世界中，L3级智能体正逐渐承担起软件工程师、系统运维专家和网络安全分析师等角色。

在软件工程领域，自主智能体能够自动化复杂的开发任务。AutoDev[109]和SWE-Dev[257]等框架为这些智能体提供了安全的执行环境和高质量的训练数据。Self-Collaboration框架通过模拟人类开发团队的协作模式，提高了复杂代码生成的质量[110]。CodePlan[258]和LocAgent[111]分别通过增量依赖分析和异构图表示，解决了仓库级代码编辑和定位的挑战。对于程序修复，RepairAgent[259]能够自主修复Defects4J数据集中的大量错误，而ChatRepair和ContrastRepair则通过对话式迭代反馈提高了修复效率[260]。

在网络安全领域，L3级智能体展示了执行自动化渗透测试的能力。PentestGPT通过使用多模块自交互解决了上下文丢失问题[112]。HackSynth[113]通过规划器和总结器迭代生成攻击指令，而EnIGMA[261]引入了创新的交互式工具，使智能体能够操作调试器等复杂程序，在CTF基准测试中取得了领先性能。

在系统运维管理方面，L3级智能体专注于实现云服务的自主诊断和恢复。RCAgent[262]和TAMO[263]等框架利用工具增强的LLM对工业系统或微服务架构进行根因分析。AIOpsLab[264]和ServiceOdyssey[265]等系统使智能体能够通过模拟故障注入和迭代探索，自主管理和修复微服务。此外，OptiGuide[114]和ARS[266]等框架展示了LLM智能体能够自动生成高效的启发式算法，以解决组合优化等复杂决策问题。

**2) 自主科学发现**：L3级科学智能体超越了L2级的辅助角色，成为能够进行独立研究的“AI科学家”。这些智能体能够自主提出假设、设计和执行实验、分析数据，并最终生成新的科学知识。

几个通用框架探索了这一宏大愿景。Agent Laboratory和AI Scientist框架实现了从研究构想到论文发表的全过程自动化[115],[252]。AI Scientist-v2甚至生成了第一篇完全由AI撰写并成功通过同行评审的学术论文，标志着一项里程碑式的成就[115]。在特定科学领域，L3级智能体取得了显著进展。

在材料科学领域，LLMatDesign[116]和CrystaLLM[267]等框架能够自主设计、修改和评估新材料的晶体结构。在化学和药物发现领域，Coscientist和DrugAssist[268]等系统集成了各种工具，以自动化复杂的实验工作流或执行端到端的药物分子优化。AgentDrug[117]和LIDDiA[118]等框架通过精炼循环或智能探索，进一步提高了分子优化的准确性。ORGANA[119]和ARChemist[120]等机器人系统将这种自主性延伸到物理实验室，通过控制机械臂和实验设备来执行化学家的指令，实现了数字智能与物理操作的闭环。

**3) 具身智能**：具身智能是L3级的第三个重要方向，旨在赋予智能体在物理世界或高度模拟的虚拟环境中感知、交互和学习的能力。Voyager在此领域代表了一个里程碑，它通过自动课程、技能库和迭代提示机制，在Minecraft中实现了无人干预的终身学习[168]。GITM框架[33]通过集成外部知识，进一步提高了智能体在虚拟世界中的任务完成能力。为了将这种能力转移到现实世界的机器人上，研究人员专注于对齐语言、视觉和行动。PaLM-E是首个将连续传感器模态直接集成到语言模型中的工作，实现了端到端的具身推理[121]。ECoT及其变体通过引入多步推理训练，增强了机器人在复杂任务中的泛化能力[122]。AdaPlanner[123]和TaPA[124]等框架专注于提高智能体在动态环境中的规划鲁棒性，使其能够根据物理约束和环境反馈自适应地调整计划。这些进步正在推动创建能够在物理世界中自主执行任务的通用机器人。

#### **D. 协同智能系统**

在四级（L4），智能体的核心能力从个体自主演变为组织协作。该系统由多个专业智能体组成，它们通过沟通和协作来实现单个智能体无法完成的大规模目标。其价值主要体现在两个方向：首先，作为数字劳动力集群，直接执行复杂的端到端业务流程；其次，作为数字实验室，模拟复杂社会经济系统的行为，以进行推理和决策支持。

**1) 协同业务执行**：在L4阶段，多智能体系统开始重塑各行业的业务流程。

在智能制造领域，已提出了多个框架以实现生产线的灵活性和智能化。通过模拟领导者-跟随者或分层自动化金字塔等结构，多智能体系统能够实现动态资源调度和故障恢复。MASC框架有效解决了柔性作业车间调度中的动态重调度挑战，而MADTwin[125]和知识图谱等技术的集成则允许进行更准确的预测性维护和生产规划。DeFACT[127]等前瞻性框架甚至探索了基于区块链的去中心化自主生产模型。

在供应链和物流领域，多智能体系统被用于优化复杂的协调问题。例如，智能协调被应用于优化滚装码头的空间分配和交通控制，或利用实时数据处理来优化露天矿的车队管理。InvAgent[126]等框架利用LLM的零样本能力，使库存管理中的自适应决策成为可能，从而提高了供应链的韧性。

在金融服务行业，多智能体协作成为提高交易策略复杂性和鲁棒性的关键。TradingAgents[128]和FinCon[269]等框架模拟了交易公司内部不同角色（如分析师、策略师和风险经理）之间的协作，以实现更好的交易表现。HedgeAgents[129]专注于在波动市场中进行对冲，而MASA[270]和MADDQN等框架则利用多智能体强化学习来动态平衡投资组合的收益和风险。为了系统性地评估这些复杂系统，出现了StockSim[271]和FinArena[130]等专门的模拟和评估平台，而TwinMarket[272]框架则使用LLM来模拟宏观经济现象。

**2) 复杂系统仿真**：L4级智能体的另一个关键价值在于构建高保真的数字实验室，用于模拟和推理人类社会、经济和城市等复杂系统的动态演化。

在通用仿真框架领域，Simulation Agent Framework[273]和LLM-DT[274]等工作专注于将LLM的自然语言交互能力与传统仿真引擎的严谨性相结合，允许用户以更直观的方式构建和验证仿真模型。AgentSociety[275]构建了一个大规模的社会模拟器，用于研究复杂的社会动态。

在交通和城市发展领域，多智能体仿真在应用方面展现出巨大潜力。CoMAL[131]和CoLLMLight[132]通过智能体协作优化混合交通流或城市交通信号。在城市规划中，CUP等框架通过模拟规划者和居民等角色之间的互动和谈判来生成和评估土地利用提案，促进了更动态和以人为本的城市发展。CitySim对个体行为进行详细模拟，能够预测宏观层面的城市动态[133]。

这些工作为理解和管理现代社会日益复杂的系统提供了前所未有的强大工具。

#### **E. 自适应社会系统**

五级（L5）代表了行业智能体的终极愿景——“自适应社会系统”。与主要作为人类目标执行者的L1-L4系统不同，L5级智能体演变为能够与环境和人类社会共同演化的自主实体。这些系统不仅适应环境，还主动改造环境。它们不仅执行预定义的目标，还能自主生成新的目标和价值体系。尽管尚未存在完全实现的L5系统，但其核心特征已在理论讨论和前瞻性研究中初现端倪。

L5系统的核心特征可概括如下：
- **自主目标生成**：系统不再被动等待人类输入高层目标，而是能够基于其对环境的观察、内部价值体系和未来预测，自主提出新的、长期的战略目标。在进化智能体设计方面的最新探索，如EvoAgent[134]，为智能体如何自主扩展其功能并提出新颖目标提供了早期证据。
- **进化价值对齐**：智能体群体的价值观或决策标准并非固定不变；相反，它们通过与环境的持续交互，从集体的成功与失败中学习，并随着时间的推移进行调整、巩固和升级，这一过程类似于文化进化。这一概念与规范性多智能体系统中的进化多价值对齐[276]以及智能体AI系统中的多层次价值对齐框架[277]的研究相呼应。
- **环境与系统的共生进化**：L5系统主动改造其环境。它们通过自身行动改变物理或数字世界的规则和结构，而这些变化反过来又影响系统后续的发展，从而创造出一种动态的、相互塑造的共生关系。AdaSociety[135]等自适应环境突显了系统-环境共同演化的潜力。
- **涌现的社会结构**：在智能体之间复杂的交互中，会自发涌现出组织、规范和文化等结构，这些结构并非显式设计，从而实现了高水平的自组织和适应性。关于社会的计算架构和社交规则起源的最新研究[278]说明了如何在智能体社会中生成新的规范和制度。

尽管L5仍处于概念阶段，但其潜在应用可以在几个前沿领域中预见。例如，在经济领域，L5系统可能表现为一个完全自主的去中心化组织，其中AI智能体不仅执行业务任务，还制定公司战略、调整组织结构，甚至创造新的商业模式。在城市治理中，L5系统可能超越L4的规划模拟，成为一个城市有机体，能够实时感知、决策和调节各种城市资源（如能源、交通、公共服务），并根据社会福利的长期演变调整治理策略[275],[279]–[281]。在科学研究中，L5系统可能形成一个自主的科学共同体，不仅完成特定研究（L3/L4），还能提出新的研究范式、定义重要的科学问题，并引导科学发展的方向。

实现L5的挑战是巨大且多维度的。它们不仅涉及复杂系统、终身学习和多智能体博弈论等高级技术问题，还触及控制、伦理和人机关系等深刻的哲学问题。然而，对L5的探索代表了我们对通用人工智能终极潜力的思考，其发展将深刻地重新定义人类与智能、技术与社会的关系。

### **IV. 行业智能体的评估**

随着行业智能体在现实世界应用中的快速部署，如何以科学和全面的方式评估其能力已成为一个既关键又具有挑战性的问题。一个有效的评估系统不仅是衡量技术进步的标尺，也是指导模型优化、确保系统安全以及在各行业建立信任的基础。

本节对行业智能体在实践环境中的评估方法和基准进行了系统性回顾。我们首先从记忆、规划和工具使用这三项基础能力入手，介绍旨在评估智能体通用认知技能的基准。然后，我们考察了金融、医疗和软件工程等典型领域的专业化评估方法，这些领域的任务需求高度特定。最后，我们分析了现有评估系统中存在的共性和领域特定挑战，并讨论了开发下一代更具真实性、可靠性和高效性的评估框架的视角。

#### **A. 基础能力评估**

在将智能体部署到特定行业之前，有必要对其底层认知能力进行可靠评估。本节重点关注构成智能体核心的三大基础支柱：记忆、规划和工具使用。我们讨论了如何使用标准化的基准和任务来量化智能体在信息保留与检索、复杂任务分解与执行以及与外部世界交互方面的表现。对这些基础能力的评估为理解和比较不同智能体架构提供了通用语言，并且是进行更高级的行业特定应用评估的先决条件。

**1) 记忆能力评估**：记忆是智能体执行长期和连贯任务的基础。其评估聚焦于信息检索的准确性、跨任务学习、长程理解以及冲突解决。MemoryAgentBench是为此目的设计的系统性基准[136]。它专门在四个关键领域评估记忆智能体：准确检索、测试内学习、长程理解和冲突解决。

随着模型上下文窗口的扩展，长期记忆的评估已成为一个核心话题。具身长上下文记忆基准在Habitat模拟器中引入了60个具身任务，这些任务需要长期记忆和情境感知[137]。同样，3DMem-Bench提供了超过26,000条轨迹和2,892个具身任务，为评估3D环境中长期记忆推理提供了一个全面的基准[138]。

在文本理解方面，QuALITY[139]数据集在平均长度约5,000字的长文档上创建了多项选择题任务，而QMSum[140]则提出了基于查询的多领域会议摘要任务。它们共同对模型的长文本处理和深度理解提出了挑战。LoCoMo[282]基准通过问答、事件摘要和多模态对话生成等任务，进一步评估了超长对话中的长期记忆。为应对这些挑战，ReadAgent[283]引入了一种基于记忆片段和要点记忆的交互式阅读机制，在QuALITY[139]等任务中实现了显著的上下文扩展。MemGPT采用虚拟上下文管理和中断机制，使模型能够在文档分析和多会话对话中超越有限的上下文窗口。

这些努力共同构建了从文本到具身任务、从单任务场景到长期交互的评估方法，从而加深了对智能体处理长期信息能力的理解。

除了长期记忆，终身学习和动态适应也是关键的评估方面。LifelongAgentBench是首个用于系统性评估基于LLM的智能体终身学习能力的统一基准[141]。它包含了三个交互环境中的基于技能的任务，并提供了自动标签验证。StreamBench是一个在线学习基准，专注于在连续反馈流下评估LLM的迭代性能改进[284]。一个专门的动态对话智能体评估系统模拟了长期多任务交错对话，以评估长期记忆、持续学习和信息整合。它揭示了当前大模型在自然交互中面临的新挑战。这些基准将评估范围从静态知识评估扩展到了动态学习能力。

此外，评估框架正朝着更全面、多维度的系统发展。Mem-Bench提出了一个结合事实记忆、反思记忆、参与式交互和观察场景的基准[285]。它评估了基于LLM的智能体记忆的有效性、效率和容量。OST-Bench专注于动态探索任务中的增量观察处理和时空推理。评估也开始扩展到特定领域的应用[286]。例如，REAL套件是首个用于评估LLM在房屋交易和服务领域能力的基准，涵盖了记忆、理解和推理[287]。RAISE框架在房地产销售场景中使用双组件记忆系统和多阶段评估过程来评估智能体，在复杂的多轮对话中表现出优于传统智能体的性能[288]。受卡片盒笔记法启发，一些研究人员设计了具有动态索引和链接知识网络的智能记忆系统，在多个基础模型上展示了其有效性。这些工作极大地丰富了不同维度和应用场景下的记忆评估方法，使其更贴近现实世界的需求。

**2) 规划能力评估**：规划能力决定了智能体的自主性，并设定了其问题解决能力的上限。其评估涵盖了从简单推理到复杂动态决策的广泛场景。数学和逻辑推理构成了规划的基础，几个经典基准在此背景下被广泛使用。GSM8K提供了需要多步推理的小学数学应用题[142]。Rationale数据集提供了代数问题，用于通过自然语言推理步骤评估程序学习的间接监督[289]。HotpotQA通过基于维基百科的问答评估多文档推理[143]。ARC基准引入了一个科学语料库和具有挑战性的问题，以测试高级推理和知识整合[290]。StrategyQA专注于需要隐式推理步骤和战略分解的问题，为多跳推理创造了更真实的环境[291]。MATH基准提供了竞赛级别的数学问题，测试了大模型在数学推理方面的极限[292]。这些基准共同构成了评估逻辑和数学规划能力的基础。

随着基于智能体的系统兴起，评估已转向更复杂的交互式和长周期决策任务。TextAtari基准将Atari游戏状态转换为文本描述，创建了近100个任务，以测试语言智能体在长达100,000步的决策过程中的表现[144]。Agent-X在多模态环境中评估以视觉为中心的智能体在多步深度推理任务上的表现[293]。FlowBench[145]是首个工作流引导的规划基准，涵盖了六个领域的51个场景，提供了多格式知识表示和多层次评估。NATURAL PLAN引入了旅行规划和会议安排等现实世界任务，突显了当前模型在复杂自然语言规划方面的局限性[294]。这些基准将规划评估从静态问题解决扩展到了动态和长期执行。

同时，规划过程中的反思、修正和反馈学习变得越来越重要。自我反思基准表明，迭代反思机制可以显著提高LLM在问题解决任务中的表现[146]。受认知心理学启发的Reflection-Bench提供了七项任务，以评估在预测、决策和反事实推理中的认知能力[147]。MINT通过模拟多轮工具使用和自然语言反馈来评估持续性能[295]。AdaPlanner[123]应用自适应规划与环境反馈循环，在ALFWorld等环境中测试序列决策。LLF-Bench提供了一个多样化的平台，用于评估从自然语言反馈中进行交互式学习[296]。这些基准的核心在于评估智能体如何从失败中学习并在交互中进行适应，这对于构建鲁棒的自主系统至关重要。

最后，研究人员探索了更形式化和自动化的规划评估方法。PDDL-to-NL框架使LLM能够在PDDL规划任务上进行大规模评估[148]，揭示了与符号规划器相比的显著性能差距。ACPBench提供了一个可扩展的自动化框架，包含七个推理任务和13个用形式化语言描述的规划领域，支持对规划和推理能力的系统性评估[297]。这些努力有助于建立严谨和可量化的规划评估标准。

**3) 工具使用能力评估**：工具使用是智能体能力的核心延伸。其评估聚焦于在真实世界API中选择、调用和组合的准确性、鲁棒性和效率。伯克利函数调用排行榜（BFCL）引入了首个全面的基准，用于评估LLM的函数调用能力。它涵盖了多语言设置、并行和多次调用以及函数相关性检测。ToolBench自动构建指令微调数据集，并与ToolEval评估器一起，系统性地衡量真实API场景中的工具使用能力。同样，ToolAlpaca框架在400多个真实API上提供了数千个工具使用示例[149]。API-Bank作为工具增强LLM的开创性基准，提供了73个API和314个带注释的对话，以测试API规划、检索和执行[150]。APIBench为基于查询和基于代码的API推荐提供了标准化评估。这些基准共同奠定了工具使用评估的基础。最近的模型如NexusRaven-V2甚至在嵌套和复合函数调用任务上超越了GPT-4。

随着工具使用场景变得更加复杂，基准也朝着更高精度和更深层次发展。Seal-Tools引入了严格的格式约束和多维指标进行严格评估[151]。StateEval通过自动生成的测试用例评估顺序API调用[298]。ComplexFuncBench[299]和NESTFUL[300]针对多步、受限和嵌套的函数调用场景。DICE-BENCH采用带有工具依赖图和多智能体角色的对话合成框架，生成了数千个高质量的函数调用实例[301]。T1基准提供了带有缓存机制的多领域、多轮对话数据集，实现了对依赖处理和动态重规划的标准化评估[302]。ToolSandbox引入了有状态执行、隐式状态依赖和内置用户模拟器等特性，用于动态轨迹评估[303]。API-BLEND为在真实API设置中训练和测试工具增强LLM提供了一个大规模语料库[304]。StableToolBench采用虚拟API服务器和稳定的评估系统，为工具学习提供了可扩展且一致的基准[152]。这些工作共同将评估从孤立的API调用转向了复杂、动态和有状态的工具链执行。

此外，专门的框架和领域特定基准进一步丰富了工具使用评估。ToolEmu通过LLM模拟工具执行，实现了自动化的安全评估和风险量化[153]。WebShaper利用形式化合成方法为信息搜索任务生成高质量数据集[219]。FiReAct管道利用语义上下文检索，在数万个工具中编排行动[154]。PyVision动态生成和执行基于Python的工具，显著提高了视觉基准中的多模态推理[305]。AgentDistill将从教师智能体中提炼出的结构化任务解决模块进行迁移，实现了无需再训练的高效知识复用[306]。在专业领域，CVDP基准[307]涵盖了硬件设计和验证中的13个类别，而RestBench为评估RestGPT等智能体提供了具有真实世界场景和黄金标准解决方案路径的高质量基准[308]。这些努力推动了工具使用评估朝着更真实、更复杂、更安全和更面向领域的方向发展。

#### **B. 行业实践评估**

当智能体应用于特定行业时，仅进行基础能力评估是不够的。行业应用的成功取决于智能体是否能够理解和遵循复杂的业务逻辑、利用领域特定知识以及处理行业特定的风险场景。因此，为每个领域构建专门的基准至关重要。这些基准不仅必须模拟真实的业务流程和数据环境，还必须考虑独特的挑战，例如金融领域的高风险和医疗领域的严格合规要求。

本节回顾了在关键行业（包括Web交互、软硬件工程、金融、医疗和科学研究）中出现的代表性基准和方法。其目标是展示评估系统如何从通用测试演变为面向领域的评估，从而为行业智能体的实际价值提供更真实的衡量标准。

**1) 通用领域**：在进入特定领域应用之前，已开发了一套基准来评估智能体在跨行业场景和复杂挑战中的表现。GAIA基准包含了466个现实世界问题，以测试推理、多模态处理和工具使用，为比较人类和AI性能提供了参考[309]。AgentBench提供了一个多维度的演进基准，以评估在多轮开放式环境中的推理和决策能力[155]。OSWorld提供了一个可扩展的真实计算机环境，支持跨操作系统的多模态任务执行和评估。为了模拟真实业务运营，TheAgentCompany构建了一个可扩展的框架，用于评估AI智能体在软件公司环境中的Web浏览和编码等任务[156]。同样，CRMArena引入了跨三个角色的九个客户服务任务，以衡量在真实CRM场景中的表现[157]。Aime[67]和AgentOrchestra等多智能体框架在GAIA及相关基准上也展示了强大的任务完成和适应能力[158]。

除了通用能力，基准还针对特定的常见挑战。在安全性方面，RAS-Eval在模拟和真实的工具执行环境中，使用80个测试用例和3,802个攻击任务，对LLM智能体在11个CWE安全漏洞上进行评估[310]。在流程遵循方面，τ-bench通过动态的用户-智能体对话来测试智能体，以衡量其规则遵循和行为一致性[311]。其继任者τ2-bench通过增加双控制电信设置和复合任务生成，扩展了评估保真度[312]。对于复杂协作，CREW-Wildfire生成了大规模的野火响应场景，包含异构智能体、地图和不确定性，以测试协调、沟通和长期规划[313]。SOP-Bench涵盖了10个工业领域和1,800多个任务，用于衡量在复杂标准操作程序（SOP）中的规划、推理和工具使用[314]。

其他基准则涵盖了更广泛的通用能力。HeuriGym提供了一个用于在组合优化中生成启发式的开源框架[315]。AssetOpsBench为工业4.0的开发和评估提供了一个统一环境[159]。MAPS套件将多个基准翻译成11种语言，实现了对智能体性能和安全性的标准化多语言评估[316]。EconWebArena评估了自主智能体在真实Web平台上执行多模态经济任务的能力[317]。TextAtari将Atari游戏状态转换为文本，以测试长周期决策[144]。AmbiK提供了一个包含模糊指令的厨房环境，用于比较处理模糊性的方法[318]。Agent-X评估了以视觉为中心的智能体在真实多模态环境中的多步推理[293]。Agent-RewardBench测试了多模态LLM在感知、规划和安全方面的奖励建模[319]。IntellAgent是一个开源的多智能体框架，可生成多样化的合成基准用于对话AI评估[320]。Factorio学习环境（FLE）使用基于游戏的设置来衡量长期规划、程序合成和资源优化。STEPS评估了任务执行中的顺序推理[321]。HAL[322]框架标准化了跨基准的评估，支持并行测试和成本跟踪。Spider2-V[323]引入了首个专注于专业数据科学和工程工作流的多模态智能体基准，包含494个真实世界任务，以评估智能体通过代码生成和GUI操作自动化数据工作流的能力。

这些工作共同奠定了衡量智能体是否满足行业应用入门要求的基础，架起了通用认知能力与实际业务就绪度之间的桥梁。

**2) 特定领域**：
a) **Web和GUI交互**：网页和GUI是智能体与数字世界交互的主要入口。该领域的基准旨在评估在真实和动态Web环境中的自动化能力。WebArena[160]提供了一个高度逼真且可复现的环境，以评估语言引导智能体在复杂、长周期任务上的功能正确性。VisualWebArena将其扩展到基于视觉的多模态任务，专注于多模态Web智能体的性能[324]。WebVoyager集成了15个真实网站任务，并使用GPT-4V建立了自动评估协议，为开放Web智能体提供了可靠标准[161]。WEBLINX支持大规模评估对话式Web导航任务，包含10万次交互和2,300个专家演示[325]。

一些基准专注于企业级系统。WorkArena[326]和BrowserGym环境针对企业软件中的LLM智能体，提供了评估业务应用中任务自动化的框架。World of Bits应用工作流引导的探索来评估深度强化学习智能体在Web任务上的样本效率和性能[327]。WebShop创建了一个模拟的电子商务环境，包含数百万真实产品和数万条指令，用于评估在组合指令遵循和查询重构方面的能力[73A]。随着任务复杂性的增加，新的基准引入了更丰富的设置。MMInA通过多跳和多模态Web任务评估真实和动态环境中的具身智能体[162]。WebCanvas[164]提出了一种用于动态Web交互的在线评估方法，包括Mind2Web-Live数据集和新颖的评估指标。AssistantBench提供了214个自动评估的真实世界任务，并突显了当前模型在开放Web导航中的局限性[328]。安全性也成为主要关注点。ST-WebAgentBench包含了222个企业任务、六个安全和可信度维度以及一个专门的框架，以暴露现有Web智能体中的重大漏洞[163]。

这些基准共同推动了Web智能体评估从简单的页面级交互向对复杂、动态、安全和多模态能力的综合评估发展。

b) **软件和硬件工程**：在软件工程中，评估的重点是衡量智能体理解、生成、修改和修复复杂代码的能力。SWE-bench是一个里程碑式的基准[329]。它包含了2,294个带有相应拉取请求的真实GitHub问题，并在复杂的代码修改任务上评估LLM。从中衍生出了几个变体。为了降低评估成本，SWE-bench Lite提供了一个包含300个任务的小型集。SWE-bench Multimodal (SWE-bench M)包含了617个多模态任务实例，旨在评估自主系统在视觉JavaScript软件修复上的表现[330]。SWE-PolyBench[331]提出了一个包含2,110个多语言实例的基准，支持对Java、JavaScript、TypeScript和Python进行仓库级执行评估。然而，一些研究指出了SWE-bench中的质量问题[329]，例如解决方案泄露和测试用例不足，这可能会导致性能评估出现显著偏差。

除了代码修复，其他任务也受到关注。HumanEval评估了从文档字符串合成程序的功能正确性[332]。TDD-Bench Verified提供了一个包含449个真实GitHub问题的高质量基准，用于评估测试驱动开发中的自动化测试生成[333]。ITBench引入了一个系统性框架，用于评估AI智能体在IT自动化任务中的表现[334]。SWE-Lancer包含了1,400多个自由职业软件工程任务，涵盖了独立工程和管理任务[335]。

针对特定场景也出现了评估框架。基于LLM的批评者框架使用参考感知的中间评估器，在SWE-bench上自动化评估代码补丁的可执行性和语义[329]。LLM-BSCVM在策划的数据集上对漏洞检测进行基准测试，准确率超过91%[336]。CSR-Bench提出了一个用于计算机科学研究项目的基准，评估自动化代码部署的准确性、效率和相关指标[337]。

c) **金融与经济学**：金融领域以高风险和严格时效性为特征，这使得对智能体的评估尤为严格。FinRL竞赛系列提供了涵盖股票交易和订单执行等多样化金融任务的标准化基准[338]。这些基准包含了实时、高质量的数据集和真实的市场环境。DeepFund实时基金基准工具通过多智能体架构连接到实时股票市场数据[339]。它在没有信息泄露的真实市场条件下评估了几个主流LLM的投资表现。FinArena框架结合了多模态金融数据分析和用户交互，以评估智能体在股票趋势预测和交易模拟中的表现[130]。智能体交易竞技场模拟了一个零和虚拟经济，以评估LLM在数值推理任务中处理文本和视觉数据的差异。FINSABER框架进行了长期的跨市场回测，揭示了基于LLM的择时策略在泛化性和鲁棒性方面的显著弱点[340]。

除了交易表现，金融知识和综合能力的评估也至关重要。FinEval[341]是一个包含8,351个问题的大型基准，涵盖金融学术、行业、证券和智能体能力四个领域。InvestorBench[342]是首个旨在评估LLM智能体在不同金融决策场景中表现的基准。FinResearchBench引入了一个基于逻辑树的智能体即评委（Agent-as-a-Judge）框架，以自动评估金融研究智能体在七个关键任务类别上的表现[343]。FinLLM排行榜和韩语Won基准为评估金融LLM的整体性能提供了开放排行榜[344]。

风险评估是金融评估的一个显著特征。风险工程框架提出了一个针对金融LLM智能体的三级压力测试方法，强调在模型、工作流和系统层面上的风险指标[9]。同时，EconWebArena专注于评估智能体在真实Web环境中执行复杂经济任务的能力[317]。Instruct2DS基准支持在金融等领域进行实时Web数据收集，为自动化数据收集系统的评估建立了新标准。

这些努力共同构建了一个全面的金融智能体评估系统，涵盖了交易策略、知识理解和风险控制。

d) **医疗健康**：医疗健康是一个应用潜力广阔但风险极高的领域。该领域的基准以覆盖范围广、专业性强和注重安全性为特征。已开发了几个综合基准来评估智能体在复杂临床环境中的表现。MedAgentBoard提供了一个系统性基准，以评估多智能体协作、单个LLM和传统方法[345]。临床智能体基准（CAB）涵盖了五个临床维度和18项任务，用于综合评估[346]。MedAgentsBench[347]专注于复杂医学推理、诊断和治疗规划等具有挑战性的问题。AgentClinic是一个多模态基准，用于在模拟临床环境中评估LLM，包括患者交互、多模态数据收集和工具使用[348]。

MedChain基准引入了12,163个个性化、交互式和序列化的临床案例，为LLM在现实决策中的表现提供了一个全面的测试平台[349]。DynamiCare框架基于MIMIC-Patient数据集，建立了首个用于动态临床决策的基准。

对于特定的医疗任务，ReasonMed是最大的医学推理数据集，为训练和评估医学问答模型提供了新标准[350]。MEDDx基准提供了一个完整的诊断评估框架，支持迭代诊断策略。SYNUR和SIMORD是首个用于护理观察提取和医学指令提取的开源数据集，为这些任务引入了新基准[351]。CalcQA基准通过100个案例-计算器对和281个医疗工具，在临床计算场景中评估LLM[352]。IPDS提供了一个包含51,274个案例的大型数据集，用于评估对住院护理路径的决策支持[353]。

安全性和公平性是医疗评估的核心关注点。MedSentry提供了一个包含5,000个对抗性医疗提示的基准，用于测试多智能体拓扑结构的安全性和防御机制[354]。AMQA基准使用对抗性问答数据集，系统性地评估LLM在医学诊断中的人口偏见[355]。Cancer-Myth基准揭示了最先进的LLM在识别和纠正癌症相关问题中的错误前提方面的严重弱点[356]。

在特定领域也涌现出众多专门的基准。这些包括用于放射影像解读的ChestAgentBench[246]和CheX-agent[357]，用于眼科的Eyecare-Bench[358]和多语言CLARA[359]，用于生物医学编码推理的MedAgentGYM[360]，用于心脏病学的心脏超声问答数据集，以及基于HPO分类和多智能体评估方法的罕见病基因优先级排序基准[361]。WSI-Agents集成了专家智能体，在多模态全切片图像（WSI）基准上实现了卓越性能[362]。3MDBench是一个用于由大型视觉-语言模型驱动的远程医疗咨询模拟和评估的开源框架[363]。M3Bench对自动化医学影像机器学习进行基准测试[364]。MedDev-Bench引入了一个国际数据集，用于评估医疗器械监管合规的自动化系统[365]。BeNYfits提供了一个新基准，用于确定用户在重叠的社会福利中的资格[107]。

这些基准共同为开发值得信赖和可靠的医疗智能体奠定了基础，将评估从通用临床推理推进到专业诊断、安全性和监管合规。

e) **科学研究与工程设计**：在科学发现和工程设计中，评估旨在衡量智能体作为“AI科学家”或“AI工程师”的潜力。已提出了几个通用科学基准。ScienceQA包含了约21K个多模态多项选择题[366]。ScienceWorld模拟了一个交互式文本环境，以测试科学推理[367]。DISCOVERYWORLD提供了一个虚拟环境，用于开发和评估具有端到端科学推理能力的智能体[368]。AAAR-1.0[369]、ScienceAgentBench[370]和CORE-Bench[371]等基准专注于专业研究任务，包括实验设计、论文弱点识别和计算可复现性。RExBench评估了实现研究实验的能力[372]。SurveyScope为跨11个计算机科学领域的自动科学文献综述提供了一个标准化基准[373]。QASPER提供了一个针对学术文档的信息寻求问答基准[374]。SUPER基准是首个用于评估LLM配置和执行研究仓库任务能力的基准[375]。

特定领域的基准也在不断涌现。Drafter-Bench评估了土木工程图纸的修订[376]。FEABench衡量了LLM及其智能体在使用有限元分析解决物理、数学和工程问题方面的能力[377]。ChemGraph在13个自动化计算化学工作流任务上评估了不同规模的LLM[378]。TopoMAS框架通过全面的基准测试，在拓扑材料发现中展示了效率和准确性[379]。AstroMLab-1表明AstroSage-70B在天文学任务上优于开源和闭源模型[380]。DREAMS框架在Sol27LC晶格常数基准上实现了不到1%的平均误差[381]。Design Agents框架使用行业标准基准验证了汽车设计流程中的效率提升[382]。ThinkGeo通过结构化智能体任务评估了LLM在遥感中的工具使用和多步规划[383]。GeoMap-Bench是首个用于评估多模态LLM在地质图理解方面能力的基准。PhysGym提供了一个基准套件和模拟平台，用于在交互式物理环境中评估基于LLM的智能体的科学推理[384]。

数据科学和跨学科方法的评估也受到越来越多的关注。DataSciBench是一个用于评估LLM在数据科学中能力的综合基准[385]。DSMentor[386]框架展示了LLM智能体在DSEval和QRData基准上对数据科学任务的性能提升。AutoMind在两个自动化数据科学基准上取得了优于最先进基线的结果[387]。BIASINSPECTOR提供了一个基准，用于系统性地评估LLM智能体在结构化数据中检测偏见的能力[388]。Auto-Bench应用因果发现原理来评估自然和社会科学中的科学发现[389]。NLP4LP为线性规划和混合整数线性规划问题引入了一个新的基准数据集[390]。LAB-Bench包含了2,400多个多项选择题，以评估AI系统在生物研究中的实际能力[391]。MLGym-Bench涵盖了13个多样化的AI研究任务，以评估LLM智能体在现实世界研究技能方面的表现[392]。SciCode将80个科学问题分解为338个子任务，以评估在科学代码生成中的知识回忆、推理和综合能力[393]。最后，ToolMaker基准包含了15个跨领域的复杂计算任务，用于评估工具生成的正确性和鲁棒性[394]。

f) **其他专业领域**：除了上述主流领域，评估基准正在扩展到许多专业领域。在法律领域，eSapiens[395]平台通过法律语料库检索基准和生成质量测试验证了事实一致性的改进。在语言学领域，LingBench++引入了一个框架，该框架集成了结构化推理轨迹、逐步评估协议和跨90多种语言的元数据，以评估LLM在复杂语言任务上的表现[396]。

在教育领域，LLM-EduBench提供了一个系统性框架和数据集，用于评估基于LLM的智能体在学科教学和专业发展中的表现[397]。PBLBench引入了首个自由输出且经过严格人工验证的项目式学习基准。它应用了源自专家层次分析法的结构化评估标准，以测试多模态LLM在复杂推理和长上下文理解方面的能力。

在人文和社会科学领域，HSSBench是一个多语言基准，旨在评估多模态LLM在跨学科推理和知识整合方面的能力[398]。在游戏和模拟领域，VGC-Bench提供了一个基准平台，用于评估在《宝可梦》对战环境中的多智能体策略泛化[399]。Decrypto基准采用游戏化交互设计，填补了在多智能体系统中评估心智理论推理的空白。

这些基准极大地扩展了智能体评估的范围，为在更广泛的人类知识领域中应用和评估智能体奠定了基础。

#### **C. 现有评估基准的局限性**

尽管基准和评估方法取得了显著进展，但当前的系统在推动智能体走向可靠和通用的工业应用方面仍面临一系列挑战。

- **真实性与可复现性之间的权衡**：环境越接近现实世界，其包含的随机性和动态性就越多，使得严格的可复现性变得极其困难。相比之下，高度确定性的模拟环境保证了可复现性，但往往与现实场景存在分歧。因此，在模拟中表现良好的智能体在实践中可能会失败。
- **评估成本与效率的矛盾**：对于复杂任务，特别是涉及开放式响应和多步操作的任务，高质量的人工评估仍然是“黄金标准”。然而，它成本高昂且耗时。使用更强大的LLM作为评估者可以提高效率，但新知识的偏见、不一致性和幻觉等问题给结果的可靠性带来了新的不确定性。
- **安全沙箱的性能开销**：为了安全地评估与外部世界交互的智能体，必须将它们置于隔离的沙箱环境中。更强的隔离机制（如独立的虚拟机或容器）通常会引入显著的性能开销，从而降低评估效率。在绝对安全与高性能评估之间取得平衡仍然是一个关键的工程挑战。
- **高知识壁垒与时效性**：金融、医疗和法律等领域不仅需要高度复杂的专业知识，还需要不断更新，包括新的金融工具、临床指南和法规。当前的基准无法维护与最新行业发展完全同步的知识库。这导致了对智能体知识时效性评估的固有滞后。
- **数据隐私与合规性约束**：银行交易记录、电子健康记录和法律案卷等现实世界的行业数据和系统接口受到严格的隐私和数据保护法规的保护[400],[401]。这使得研究人员难以获取高质量的真实数据来构建评估环境。依赖合成或重度匿名化的数据可能会丢失微妙但关键的细节，从而降低评估的有效性。

### **V. 讨论**

尽管从L1到L5的演进路径清晰地展示了行业智能体能力的飞跃，但在将这些技术蓝图转化为可靠、通用且有益的社会生产力方面，仍有一系列深刻的挑战[402]。这些挑战不仅与技术实现相关，还触及知识的本质、智能的构成和系统的演化等根本性问题。

本节提炼了五个核心深层问题，它们代表了当前和未来行业智能体从“可用”迈向“可信”和“通用”的关键瓶颈。

#### **A. 知识与经验之间的鸿沟**

在审视从L1到L4的应用实践时，一个显著的现象是：行业智能体在软件工程[109]、数据库交互[91]和Web浏览[161]等领域取得了巨大成功，但在物理[403]或社会领域[404]的进展则相对缓慢。这种差异的本质在于知识与经验之间的差距。在数字原生领域，“物理定律”由API、代码库和显式交互协议定义。智能体的经验可以通过海量的数字文本、代码和交互日志高效地获取。然而，在物理和社会领域，操作逻辑往往充满了默会知识。例如，经验丰富的工程师对设备故障的直觉、医生根据患者情绪调整诊断、或外交官在谈判桌上的判断——这些经验深深植根于人类实践和互动中，无法完全用语言描述或在数据中捕获。这些领域的反馈往往是延迟的、模糊的，且试错成本高昂。当前智能体的成功很大程度上源于它们能够将非结构化的人类知识转化为结构化的数字指令。然而，当知识本身是非结构化的、情境化的，甚至是不可言传的，这种翻译范式就会失效。因此，未来的核心挑战在于：我们是应该专注于使用更强大的模型来提取所有可用数据以模拟默会知识，还是需要开发新的智能体架构，使其能够通过少量高质量的交互与人类专家协同学习，从而高效地习得经验[402]？

#### **B. 仿真环境的重要性**

行业智能体最成熟的应用主要集中在软件工程、数据分析和信息检索等数字领域。在这些领域，操作规则通常是明确定义和形式化的：代码有严格的语法，API有清晰的文档，网页遵循标准化的DOM结构。这意味着智能体可以在规则明确、反馈即时、试错成本低的环境中学习和执行任务。一个代码解释器、一个浏览器DOM环境或一个API接口本身就是其对应世界的100%高保真模拟器。在这个无损的、规则定义的数字世界中，智能体可以通过海量、低成本的交互来学习和进化。因此，智能体的智能不仅仅源于LLM的静态推理能力，更是在“思考-行动-观察”的闭环交互中涌现出来的。作为提供“观察”和反馈的关键要素，环境是智能体认知回路中不可或缺的一部分。没有环境的动态响应，智能体的“行动”就失去了意义，其“思考”也变得无本之木。即使是训练于最先进物理模拟器中的具身机器人智能体，在进入现实世界时也会面临巨大挑战，因为模拟器无法完全建模空气阻力、地面摩擦、光照变化和传感器噪声[405]。这种巨大的仿真-现实差距导致了性能的急剧下降[406]。因此，智能体能力的上限在很大程度上取决于其能够交互的环境质量。总而言之，未来的突破不仅依赖于更大、更强大的LLM，还依赖于仿真工程的进步——我们能否为制造、医疗和金融等复杂的物理和社会系统创建足够逼真和可扩展的数字孪生[407]环境[408]。这使得构建和利用仿真环境的能力成为衡量一个行业能否成功应用高级智能体的根本前提。

#### **C. 能力与任务之间的不对称性**

在审视各种智能体时，我们遇到了一个有趣的悖论：许多在核心能力（例如长期记忆、复杂规划）上存在明显短板的系统，在特定任务（例如一个仅依赖短期上下文的网页抓取智能体）上却表现出色。然而，在其他场景中，能力上的微小缺陷就可能导致整个任务的灾难性失败。这揭示了能力与任务之间的不对称关系，这是区分专家与通才的核心。当任务被高度简化和约束时，“木桶理论”失效。例如，一个L2级的交互式问答机器人，专注于检索和理解，几乎不需要长期记忆或复杂规划。在这里，任务边界限制了智能体暴露的能力，掩盖了其弱点。另一方面，当任务是开放、动态和长期的时，“木桶理论”成立。一个L3级的自主软件工程师不仅需要生成代码，还必须理解跨文件依赖、规划开发步骤，并在出错时进行反思和修正。任何一个环节的缺失都可能导致项目失败。这种不对称性为行业实践提供了多种选择：我们应该投入资源来弥补智能体的短板，打造一个全能的通才，还是应该专注于降低现实世界问题的复杂性，将其分解为可以由当前能力有限的智能体执行的子任务[409],[410]？从实践角度看，在可预见的未来，将存在两条并行路径：集成大量专业智能体的协作系统[411]，以及能够独立处理复杂性的通才自主系统[412],[413]。

#### **D. 自主进化的囚徒困境**

从L3的自我修正到L5的自主目标生成，智能体的终极理想是“自主进化”——通过与环境的持续交互，不断学习、适应并涌现出新能力。然而，这种自主性本身就包含了一个深刻的矛盾，形成了一个囚徒困境：一方面，我们希望允许智能体在开放环境中探索，以实现意想不到的突破（合作收益）[410]；另一方面，我们又害怕完全失控，担心它们会演化出有害或不可理解的行为（背叛风险）。这导致了一个关于控制与创造的终极困境：我们如何构建一个框架，既能允许智能体自主进化，又能确保它们始终在安全边界内探索[414]？这一困境在多个层面显现：(1) **目标漂移**——一个初始目标是提高生产力的智能体，在自主进化过程中，是否会将其误解为不惜一切代价降低成本，从而可能导致安全事故或伦理问题[415],[416]？(2) **沙箱悖论**——真正的进化需要与真实、复杂的环境交互，但出于安全原因，我们只能将智能体限制在受控的沙箱中。在沙箱中进化的能力能否有效地泛化到现实世界？沙箱毕业的标准是什么？(3) **价值锁定**——我们如何在设计阶段向系统注入一套核心价值观，并确保其在环境演化过程中依然保持稳健和良善[417]？解决这一困境可能需要超越传统的指令-执行范式，探索新的约束机制，例如在智能体领域应用宪法AI[418]，设计能够进行可信自我监督和风险评估的智能体架构，并建立一个动态的、交互式的人机协同治理体系。这要求我们不仅要设计智能体本身，还要设计它们所运行的社会生态系统。

#### **E. 组织与流程集成的阻力**

将行业智能体从技术验证推向大规模应用，所面临的挑战往往超越了技术本身，更多地根植于组织和流程层面。企业现有的IT生态系统通常由缺乏现代API的遗留系统、专有软件和数据孤岛组成，这对智能体的无缝集成构成了显著的连接障碍。更重要的是，智能体的引入代表了一场组织变革，要求员工从传统的执行者转变为智能体的管理者和协作者。这不可避免地会在信任建立和技能重塑方面遇到阻力[419]。潜在的解决方案包括开发作为系统连接器的低代码平台、建立统一的数据治理平台，以及设计人机协作的培训和管理系统[420]。然而，核心挑战在于推动变革管理。虽然技术解决方案可以被设计出来，但克服部门壁垒、打破数据孤岛以及重塑员工角色和绩效评估体系，是一个缓慢、昂贵且充满内部竞争的社会过程。因此，智能体的成功部署不仅取决于其技术进步，还取决于行业和企业是否有决心和能力推动深刻的组织变革。

### **VI. 结论**

在本工作中，我们对LLM驱动的行业智能体进行了系统性综述，涵盖了其核心技术、实践应用和评估方法的最新进展。我们引入了一个五级能力成熟度框架，以剖析记忆、规划和工具使用等关键技术如何演进，以支持智能体从简单自动化到复杂自主的进程。我们的分析揭示，当前的成功主要局限于数字原生环境，凸显了一个关键的“仿真到现实差距”（sim-to-real gap）以及现有评估指标与行业对可靠性需求之间的根本脱节。基于这一整体视角，我们预计行业智能体的未来发展将转向增强可靠性、专业化和人机协同。通过将先进AI与深厚的领域知识相结合，我们相信这些可信的智能体最终将成为下一次工业革命的核心引擎，极大地增强社会的生产力和创造力。

（参考文献部分略）