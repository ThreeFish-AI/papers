"""Heartfelt Agent - å°è£…æ·±åº¦åˆ†æå’Œæ„Ÿæ‚Ÿç”ŸæˆåŠŸèƒ½."""

import logging
from datetime import datetime
from pathlib import Path
from typing import Any

from .base import BaseAgent

logger = logging.getLogger(__name__)


class HeartfeltAgent(BaseAgent):
    """æ·±åº¦åˆ†æä¸“ç”¨ Agent."""

    def __init__(self, config: dict[str, Any] | None = None):
        """åˆå§‹åŒ– HeartfeltAgent.

        Args:
            config: é…ç½®å‚æ•°
        """
        super().__init__("heartfelt", config)
        self.papers_dir = Path(
            config.get("papers_dir", "papers") if config else "papers"
        )
        self.default_options = {
            "generate_summary": True,
            "generate_insights": True,
            "generate_reflections": True,
            "analyze_structure": True,
            "extract_key_points": True,
        }

    async def process(self, input_data: dict[str, Any]) -> dict[str, Any]:
        """å¤„ç†æ·±åº¦åˆ†æè¯·æ±‚.

        Args:
            input_data: åŒ…å« content å’Œç›¸å…³é€‰é¡¹

        Returns:
            åˆ†æç»“æœ
        """
        content = input_data.get("content")
        translation = input_data.get("translation")
        options = {**self.default_options, **input_data.get("options", {})}

        if not content:
            return {"success": False, "error": "No content provided"}

        return await self.analyze(
            {
                "content": content,
                "translation": translation,
                "paper_id": input_data.get("paper_id"),
                "options": options,
            }
        )

    async def analyze(self, params: dict[str, Any]) -> dict[str, Any]:
        """æ·±åº¦åˆ†ææ–‡æ¡£å†…å®¹.

        Args:
            params: åˆ†æå‚æ•°

        Returns:
            åˆ†æç»“æœ
        """
        content = params.get("content", "")
        translation = params.get("translation")
        paper_id = params.get("paper_id")
        options = params.get("options", {})

        try:
            # å‡†å¤‡ heartfelt skill çš„å‚æ•°
            skill_params = {
                "content": content,
            }

            # å¦‚æœæœ‰ç¿»è¯‘å†…å®¹ï¼Œä¹ŸåŒ…å«è¿›å»
            if translation:
                skill_params["translation"] = translation

            # æ·»åŠ åˆ†æé€‰é¡¹
            if options.get("generate_summary"):
                skill_params["generate_summary"] = True
            if options.get("generate_insights"):
                skill_params["generate_insights"] = True
            if options.get("generate_reflections"):
                skill_params["generate_reflections"] = True
            if options.get("analyze_structure"):
                skill_params["analyze_structure"] = True
            if options.get("extract_key_points"):
                skill_params["extract_key_points"] = True

            # è°ƒç”¨ heartfelt skill
            result = await self.call_skill("heartfelt", skill_params)

            if result["success"]:
                # å¤„ç†åˆ†æç»“æœ
                analysis_data = self._process_analysis_result(result["data"], content)

                # ä¿å­˜åˆ†æç»“æœ
                if paper_id:
                    await self._save_analysis(paper_id, analysis_data)

                return {"success": True, "data": analysis_data}
            else:
                return result

        except Exception as e:
            logger.error(f"Error in heartfelt analysis: {str(e)}")
            return {"success": False, "error": str(e)}

    def _process_analysis_result(
        self, data: dict[str, Any], original_content: str
    ) -> dict[str, Any]:
        """å¤„ç†åˆ†æç»“æœ.

        Args:
            data: åŸå§‹åˆ†ææ•°æ®
            original_content: åŸå§‹å†…å®¹

        Returns:
            å¤„ç†åçš„åˆ†ææ•°æ®
        """
        processed_data = {
            "content": data.get("content", ""),
            "analysis_timestamp": datetime.now().isoformat(),
        }

        # æå–æ‘˜è¦
        if "summary" in data:
            processed_data["summary"] = data["summary"]

        # æå–è¦ç‚¹
        if "key_points" in data:
            processed_data["key_points"] = data["key_points"]

        # æå–æ´å¯Ÿ
        if "insights" in data:
            processed_data["insights"] = data["insights"]

        # æå–æ„Ÿæ‚Ÿ
        if "reflections" in data:
            processed_data["reflections"] = data["reflections"]

        # ç»“æ„åˆ†æ
        if "structure" in data:
            processed_data["structure"] = data["structure"]

        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        processed_data["stats"] = {
            "original_word_count": len(original_content.split()),
            "analysis_word_count": len(data.get("content", "").split()),
            "key_points_count": len(data.get("key_points", [])),
            "insights_count": len(data.get("insights", [])),
        }

        return processed_data

    async def _save_analysis(self, paper_id: str, data: dict[str, Any]) -> None:
        """ä¿å­˜åˆ†æç»“æœ.

        Args:
            paper_id: è®ºæ–‡ID
            data: åˆ†ææ•°æ®
        """
        try:
            category = paper_id.split("_")[0] if "_" in paper_id else "general"
            output_dir = self.papers_dir / "heartfelt" / category
            output_dir.mkdir(parents=True, exist_ok=True)

            # ä¿å­˜ä¸»åˆ†æå†…å®¹
            output_file = output_dir / f"{paper_id}.md"
            with open(output_file, "w", encoding="utf-8") as f:
                f.write(data["content"])

            # ä¿å­˜ç»“æ„åŒ–æ•°æ®ï¼ˆJSONæ ¼å¼ï¼‰
            import json

            structured_file = output_dir / f"{paper_id}_analysis.json"
            structured_data = {
                "paper_id": paper_id,
                "analysis_timestamp": data["analysis_timestamp"],
                "summary": data.get("summary", ""),
                "key_points": data.get("key_points", []),
                "insights": data.get("insights", []),
                "reflections": data.get("reflections", []),
                "structure": data.get("structure", {}),
                "stats": data.get("stats", {}),
            }

            with open(structured_file, "w", encoding="utf-8") as f:
                json.dump(structured_data, f, ensure_ascii=False, indent=2)

            logger.info(f"Analysis saved to {output_file}")
            logger.info(f"Structured data saved to {structured_file}")

        except Exception as e:
            logger.error(f"Error saving analysis: {str(e)}")

    async def generate_reading_report(self, paper_id: str) -> dict[str, Any]:
        """ç”Ÿæˆé˜…è¯»æŠ¥å‘Š.

        Args:
            paper_id: è®ºæ–‡ID

        Returns:
            é˜…è¯»æŠ¥å‘Š
        """
        try:
            category = paper_id.split("_")[0] if "_" in paper_id else "general"
            analysis_file = (
                self.papers_dir / "heartfelt" / category / f"{paper_id}_analysis.json"
            )

            if not analysis_file.exists():
                return {"success": False, "error": "Analysis not found"}

            # è¯»å–åˆ†ææ•°æ®
            import json

            with open(analysis_file, encoding="utf-8") as f:
                analysis_data = json.load(f)

            # ç”ŸæˆæŠ¥å‘Š
            report = self._generate_report_content(analysis_data)

            # ä¿å­˜æŠ¥å‘Š
            report_file = (
                self.papers_dir / "heartfelt" / category / f"{paper_id}_report.md"
            )
            with open(report_file, "w", encoding="utf-8") as f:
                f.write(report)

            return {
                "success": True,
                "data": {
                    "report_content": report,
                    "report_file": str(report_file),
                    "stats": analysis_data.get("stats", {}),
                },
            }

        except Exception as e:
            logger.error(f"Error generating reading report: {str(e)}")
            return {"success": False, "error": str(e)}

    def _generate_report_content(self, analysis_data: dict[str, Any]) -> str:
        """ç”ŸæˆæŠ¥å‘Šå†…å®¹.

        Args:
            analysis_data: åˆ†ææ•°æ®

        Returns:
            æŠ¥å‘Šå†…å®¹
        """
        report_lines = [
            "# è®ºæ–‡æ·±åº¦é˜…è¯»æŠ¥å‘Š\n",
            f"**è®ºæ–‡ID**: {analysis_data['paper_id']}\n",
            f"**åˆ†ææ—¶é—´**: {analysis_data['analysis_timestamp']}\n",
        ]

        # æ·»åŠ æ‘˜è¦
        if analysis_data.get("summary"):
            report_lines.extend(
                [
                    "\n## ğŸ“ å†…å®¹æ‘˜è¦\n",
                    analysis_data["summary"],
                ]
            )

        # æ·»åŠ è¦ç‚¹
        if analysis_data.get("key_points"):
            report_lines.extend(
                [
                    "\n## ğŸ”‘ æ ¸å¿ƒè¦ç‚¹\n",
                ]
            )
            for i, point in enumerate(analysis_data["key_points"], 1):
                report_lines.append(f"{i}. {point}")

        # æ·»åŠ æ´å¯Ÿ
        if analysis_data.get("insights"):
            report_lines.extend(
                [
                    "\n## ğŸ’¡ æ·±åº¦æ´å¯Ÿ\n",
                ]
            )
            for i, insight in enumerate(analysis_data["insights"], 1):
                report_lines.append(f"{i}. {insight}")

        # æ·»åŠ æ„Ÿæ‚Ÿ
        if analysis_data.get("reflections"):
            report_lines.extend(
                [
                    "\n## ğŸ¤” è¯»åæ„Ÿæ‚Ÿ\n",
                ]
            )
            for i, reflection in enumerate(analysis_data["reflections"], 1):
                report_lines.append(f"{i}. {reflection}")

        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        if analysis_data.get("stats"):
            stats = analysis_data["stats"]
            report_lines.extend(
                [
                    "\n## ğŸ“Š é˜…è¯»ç»Ÿè®¡\n",
                    f"- åŸæ–‡è¯æ•°: {stats.get('original_word_count', 0)}\n",
                    f"- åˆ†æè¯æ•°: {stats.get('analysis_word_count', 0)}\n",
                    f"- è¦ç‚¹æ•°é‡: {stats.get('key_points_count', 0)}\n",
                    f"- æ´å¯Ÿæ•°é‡: {stats.get('insights_count', 0)}\n",
                ]
            )

        # æ·»åŠ ç»“æ„åˆ†æ
        if analysis_data.get("structure"):
            structure = analysis_data["structure"]
            report_lines.extend(
                [
                    "\n## ğŸ“š æ–‡ç« ç»“æ„\n",
                ]
            )
            for section, info in structure.items():
                report_lines.append(f"- **{section}**: {info}")

        report_lines.append("\n---\n*ç”± AI æ·±åº¦åˆ†æç”Ÿæˆ*")

        return "\n".join(report_lines)
