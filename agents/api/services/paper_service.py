"""Paper service for managing papers."""

import logging
import os
import shutil
from datetime import datetime
from pathlib import Path
from typing import Any

from fastapi import UploadFile

from agents.claude.batch_agent import BatchProcessingAgent
from agents.claude.heartfelt_agent import HeartfeltAgent
from agents.claude.workflow_agent import WorkflowAgent
from agents.core.config import settings

logger = logging.getLogger(__name__)


class PaperService:
    """论文处理服务."""

    def __init__(self) -> None:
        """初始化 PaperService."""
        self.papers_dir = Path(settings.PAPERS_DIR)
        self.workflow_agent = WorkflowAgent({"papers_dir": str(self.papers_dir)})
        self.batch_agent = BatchProcessingAgent({"papers_dir": str(self.papers_dir)})
        self.heartfelt_agent = HeartfeltAgent({"papers_dir": str(self.papers_dir)})

    async def upload_paper(self, file: UploadFile, category: str) -> dict[str, Any]:
        """处理文件上传.

        Args:
            file: 上传的文件
            category: 论文分类

        Returns:
            上传结果
        """
        # 生成唯一ID和文件路径
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        safe_filename = self._sanitize_filename(file.filename or "")
        paper_id = f"{category}_{timestamp}_{safe_filename}"

        # 确保目录存在
        source_dir = self.papers_dir / "source" / category
        source_dir.mkdir(parents=True, exist_ok=True)

        # 保存文件
        source_path = source_dir / paper_id
        try:
            with open(source_path, "wb") as f:
                shutil.copyfileobj(file.file, f)

            file_size = os.path.getsize(source_path)

            # 保存元数据
            metadata: dict[str, Any] = {
                "paper_id": paper_id,
                "filename": file.filename,
                "safe_filename": safe_filename,
                "category": category,
                "size": file_size,
                "upload_time": datetime.now().isoformat(),
                "status": "uploaded",
                "workflows": {},
            }

            await self._save_metadata(paper_id, metadata)

            logger.info(f"Paper uploaded successfully: {paper_id}")

            return {
                "paper_id": paper_id,
                "filename": file.filename,
                "category": category,
                "size": file_size,
                "upload_time": metadata["upload_time"],
            }

        except Exception as e:
            # 如果保存失败，删除可能已创建的文件
            if source_path.exists():
                source_path.unlink()
            logger.error(f"Error uploading paper: {str(e)}")
            raise

    async def process_paper(self, paper_id: str, workflow: str) -> dict[str, Any]:
        """启动处理流程.

        Args:
            paper_id: 论文ID
            workflow: 工作流类型

        Returns:
            处理结果
        """
        source_path = self._get_source_path(paper_id)
        if not source_path.exists():
            raise ValueError(f"Paper not found: {paper_id}")

        # 更新状态
        await self._update_status(paper_id, "processing", workflow)

        try:
            # 启动处理
            result = await self.workflow_agent.process(
                {
                    "source_path": str(source_path),
                    "workflow": workflow,
                    "paper_id": paper_id,
                }
            )

            if result["success"]:
                await self._update_status(paper_id, "completed", workflow)
            else:
                await self._update_status(
                    paper_id, "failed", workflow, result.get("error") or ""
                )

            # 创建任务记录
            task_id = (
                f"task_{paper_id}_{workflow}_{datetime.now().strftime('%Y%m%d%H%M%S')}"
            )
            await self._create_task_record(paper_id, task_id, workflow, result)

            return {
                "task_id": task_id,
                "paper_id": paper_id,
                "workflow": workflow,
                "status": "completed" if result["success"] else "failed",
                "result": result if result["success"] else None,
            }

        except Exception as e:
            await self._update_status(paper_id, "failed", workflow, str(e))
            logger.error(f"Error processing paper {paper_id}: {str(e)}")
            raise

    async def get_status(self, paper_id: str) -> dict[str, Any]:
        """获取论文处理状态.

        Args:
            paper_id: 论文ID

        Returns:
            状态信息
        """
        metadata = await self._get_metadata(paper_id)
        if not metadata:
            raise ValueError(f"Paper not found: {paper_id}")

        return {
            "paper_id": paper_id,
            "status": metadata.get("status", "unknown"),
            "workflows": metadata.get("workflows", {}),
            "upload_time": metadata.get("upload_time"),
            "updated_at": metadata.get("updated_at"),
            "category": metadata.get("category"),
            "filename": metadata.get("filename"),
        }

    # Alias methods for test compatibility
    async def get_paper_status(self, paper_id: str) -> dict[str, Any] | None:
        """获取论文处理状态（测试兼容方法）.

        Args:
            paper_id: 论文ID

        Returns:
            状态信息或None
        """
        try:
            return await self.get_status(paper_id)
        except ValueError:
            return None

    async def get_content(self, paper_id: str, content_type: str) -> dict[str, Any]:
        """获取论文内容.

        Args:
            paper_id: 论文ID
            content_type: 内容类型

        Returns:
            内容数据
        """
        # 根据内容类型构建文件路径
        category = await self._get_paper_category(paper_id)
        base_filename = paper_id

        if content_type == "source":
            # 源文件（PDF）
            source_path = self._get_source_path(paper_id)
            if not source_path.exists():
                raise ValueError(f"Source file not found: {paper_id}")
            return {
                "paper_id": paper_id,
                "content_type": "source",
                "format": "pdf",
                "file_path": str(source_path),
                "size": source_path.stat().st_size,
            }

        else:
            # Markdown 文件
            if content_type == "translation":
                content_dir = self.papers_dir / "translation" / category
            elif content_type == "heartfelt":
                content_dir = self.papers_dir / "heartfelt" / category
            else:
                raise ValueError(f"Unsupported content type: {content_type}")

            content_path = content_dir / f"{base_filename}.md"
            if not content_path.exists():
                raise ValueError(f"{content_type} content not found: {paper_id}")

            with open(content_path, encoding="utf-8") as f:
                content = f.read()

            return {
                "paper_id": paper_id,
                "content_type": content_type,
                "format": "markdown",
                "content": content,
                "word_count": len(content.split()),
                "file_path": str(content_path),
            }

    async def list_papers(
        self,
        category: str | None = None,
        status: str | None = None,
        limit: int = 20,
        offset: int = 0,
    ) -> dict[str, Any]:
        """获取论文列表.

        Args:
            category: 分类筛选
            status: 状态筛选
            limit: 返回数量限制
            offset: 偏移量

        Returns:
            论文列表
        """
        return await self._list_papers_internal(category, status, limit, offset)

    async def _list_papers_internal(
        self,
        category: str | None = None,
        status: str | None = None,
        limit: int = 20,
        offset: int = 0,
    ) -> dict[str, Any]:
        """内部方法：获取论文列表."""
        papers = []
        source_dir = self.papers_dir / "source"

        # 遍历所有分类目录
        for cat_dir in source_dir.iterdir():
            if cat_dir.is_dir():
                current_category = cat_dir.name

                # 分类筛选
                if category and current_category != category:
                    continue

                # 遍历分类下的所有文件
                for file_path in cat_dir.iterdir():
                    if file_path.is_file() and file_path.suffix == ".pdf":
                        paper_id = file_path.name

                        # 获取元数据
                        metadata = await self._get_metadata(paper_id)
                        if metadata:
                            # 状态筛选
                            if status and metadata.get("status") != status:
                                continue

                            papers.append(
                                {
                                    "paper_id": paper_id,
                                    "filename": metadata.get("filename", paper_id),
                                    "category": current_category,
                                    "status": metadata.get("status", "unknown"),
                                    "upload_time": metadata.get("upload_time"),
                                    "updated_at": metadata.get("updated_at"),
                                    "size": file_path.stat().st_size,
                                }
                            )

        # 排序（按上传时间倒序）
        papers.sort(key=lambda x: x["upload_time"], reverse=True)

        # 分页
        total = len(papers)
        papers = papers[offset : offset + limit]

        return {"papers": papers, "total": total, "offset": offset, "limit": limit}

    async def delete_paper(self, paper_id: str) -> bool:
        """删除论文及其相关数据.

        Args:
            paper_id: 论文ID

        Returns:
            删除结果
        """
        # Check if paper exists
        metadata = await self._get_metadata(paper_id)
        if not metadata:
            raise ValueError("Paper not found")

        try:
            # 获取分类
            category = await self._get_paper_category(paper_id)

            # 删除源文件
            source_path = self._get_source_path(paper_id)
            if source_path.exists():
                source_path.unlink()

            # 删除翻译文件
            translation_path = (
                self.papers_dir / "translation" / category / f"{paper_id}.md"
            )
            if translation_path.exists():
                translation_path.unlink()

            # 删除深度分析文件
            heartfelt_dir = self.papers_dir / "heartfelt" / category
            heartfelt_path = heartfelt_dir / f"{paper_id}.md"
            if heartfelt_path.exists():
                heartfelt_path.unlink()

            heartfelt_json_path = heartfelt_dir / f"{paper_id}_analysis.json"
            if heartfelt_json_path.exists():
                heartfelt_json_path.unlink()

            report_path = heartfelt_dir / f"{paper_id}_report.md"
            if report_path.exists():
                report_path.unlink()

            # 删除元数据
            await self._delete_metadata(paper_id)

            logger.info(f"Paper deleted successfully: {paper_id}")

            return True

        except Exception as e:
            logger.error(f"Error deleting paper {paper_id}: {str(e)}")
            raise

    async def batch_process_papers(
        self, paper_ids: list[str], workflow: str
    ) -> dict[str, Any]:
        """批量处理论文.

        Args:
            paper_ids: 论文ID列表
            workflow: 夥流类型

        Returns:
            批量处理结果
        """
        # 获取文件路径
        file_paths = []
        for paper_id in paper_ids:
            source_path = self._get_source_path(paper_id)
            if source_path.exists():
                file_paths.append(str(source_path))

        if not file_paths:
            raise ValueError("No valid paper files found")

        # 启动批处理
        result = await self.batch_agent.batch_process(
            {
                "files": file_paths,
                "workflow": workflow,
                "options": {"batch_size": 5, "parallel_tasks": 3},
            }
        )

        return {
            "batch_id": f"batch_{datetime.now().strftime('%Y%m%d%H%M%S')}",
            "total_requested": len(paper_ids),
            "total_files": len(file_paths),
            "workflow": workflow,
            "stats": result["stats"],
            "results": result["results"],
        }

    async def get_paper_report(self, paper_id: str) -> dict[str, Any]:
        """获取论文的深度阅读报告.

        Args:
            paper_id: 论文ID

        Returns:
            阅读报告
        """
        result = await self.heartfelt_agent.generate_reading_report(paper_id)

        if not result["success"]:
            raise ValueError(result.get("error", "Report generation failed"))

        return {"paper_id": paper_id, "report": result["data"]}

    async def get_paper_content(self, paper_id: str, content_type: str) -> str | None:
        """获取论文内容（测试兼容方法）.

        Args:
            paper_id: 论文ID
            content_type: 内容类型

        Returns:
            内容字符串或None
        """
        try:
            output_path = self._get_output_path(paper_id, content_type)
            if output_path.exists():
                with open(output_path, encoding="utf-8") as f:
                    return f.read()
            return None
        except Exception:
            return None

    async def get_paper_info(self, paper_id: str) -> dict[str, Any] | None:
        """获取论文完整信息（测试兼容方法）.

        Args:
            paper_id: 论文ID

        Returns:
            论文信息或None
        """
        metadata = await self._get_metadata(paper_id)
        if not metadata:
            return None

        # Add source file size if available
        source_path = self._get_source_path(paper_id)
        if source_path.exists():
            metadata["size"] = source_path.stat().st_size

        return metadata

    async def update_paper_metadata(
        self, paper_id: str, updates: dict[str, Any]
    ) -> bool:
        """更新论文元数据（测试兼容方法）.

        Args:
            paper_id: 论文ID
            updates: 更新的数据

        Returns:
            是否成功
        """
        try:
            await self._update_metadata(paper_id, updates)
            return True
        except Exception:
            return False

    # 私有辅助方法

    def _sanitize_filename(self, filename: str) -> str:
        """清理文件名."""
        # 处理空文件名
        if not filename:
            return "unnamed"

        # 移除特殊字符，只保留字母、数字、下划线、连字符和点
        import re

        safe_name = re.sub(r"[^\w\-_\.]", "_", filename)
        return safe_name

    def _get_source_path(self, paper_id: str) -> Path:
        """获取源文件路径."""
        # 从 paper_id 提取分类
        if "_" in paper_id:
            category = paper_id.split("_")[0]
        else:
            category = "general"

        return self.papers_dir / "source" / category / paper_id

    async def _get_paper_category(self, paper_id: str) -> str:
        """获取论文分类."""
        metadata = await self._get_metadata(paper_id)
        if metadata and "category" in metadata:
            return metadata["category"]

        # 从 paper_id 提取
        if "_" in paper_id:
            return paper_id.split("_")[0]
        return "general"

    async def _save_metadata(self, paper_id: str, metadata: dict[str, Any]) -> None:
        """保存元数据."""
        metadata_dir = self.papers_dir / ".metadata"
        metadata_dir.mkdir(exist_ok=True)

        metadata_file = metadata_dir / f"{paper_id}.json"
        import json

        with open(metadata_file, "w", encoding="utf-8") as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)

    async def _get_metadata(self, paper_id: str) -> dict[str, Any] | None:
        """获取元数据."""
        metadata_dir = self.papers_dir / ".metadata"
        metadata_file = metadata_dir / f"{paper_id}.json"

        if not metadata_file.exists():
            return None

        import json

        with open(metadata_file, encoding="utf-8") as f:
            return json.load(f)

    async def _update_metadata(self, paper_id: str, updates: dict[str, Any]) -> None:
        """更新元数据."""
        metadata = await self._get_metadata(paper_id) or {}
        metadata.update(updates)
        metadata["updated_at"] = datetime.now().isoformat()
        await self._save_metadata(paper_id, metadata)

    async def _delete_metadata(self, paper_id: str) -> None:
        """删除元数据."""
        metadata_dir = self.papers_dir / ".metadata"
        metadata_file = metadata_dir / f"{paper_id}.json"

        if metadata_file.exists():
            metadata_file.unlink()

    async def _update_status(
        self,
        paper_id: str,
        status: str,
        workflow: str | None = None,
        error: str | None = None,
    ) -> None:
        """更新状态."""
        updates = {"status": status}
        if workflow:
            workflows = (await self._get_metadata(paper_id) or {}).get("workflows", {})
            workflow_status = {
                "status": status,
                "updated_at": datetime.now().isoformat(),
            }
            if error:
                workflow_status["error"] = error
            workflows[workflow] = workflow_status
            updates["workflows"] = workflows

        await self._update_metadata(paper_id, updates)

    async def _create_task_record(
        self, paper_id: str, task_id: str, workflow: str, result: dict[str, Any]
    ) -> None:
        """创建任务记录."""
        # 这里可以实现任务记录保存逻辑
        # 例如保存到数据库或文件
        pass

    # Alias method for backward compatibility
    async def _load_metadata(self, paper_id: str) -> dict[str, Any] | None:
        """加载元数据（别名方法）."""
        return await self._get_metadata(paper_id)

    async def _list_all_metadata(self) -> list[dict[str, Any]]:
        """列出所有元数据文件."""
        metadata_list: list[dict[str, Any]] = []
        metadata_dir = self.papers_dir / ".metadata"

        if not metadata_dir.exists():
            return metadata_list

        import json

        for metadata_file in metadata_dir.glob("*.json"):
            try:
                with open(metadata_file, encoding="utf-8") as f:
                    metadata = json.load(f)
                    metadata_list.append(metadata)
            except Exception as e:
                logger.warning(f"Error loading metadata file {metadata_file}: {e}")

        return metadata_list

    def _get_metadata_path(self, paper_id: str) -> Path:
        """获取元数据文件路径."""
        return self.papers_dir / ".metadata" / f"{paper_id}.json"

    def _get_output_path(self, paper_id: str, output_type: str = "extracted") -> Path:
        """获取输出文件路径."""
        # 从 paper_id 提取分类
        if "_" in paper_id:
            parts = paper_id.split("_")
            # 找到时间戳后的文件名部分
            if len(parts) >= 3:
                # 第一个部分是category，第二个是timestamp，其余是filename
                category = parts[0]
                filename = "_".join(parts[2:])
            else:
                category = "general"
                filename = paper_id
        else:
            category = "general"
            filename = paper_id

        # 根据输出类型构建路径
        if output_type == "extracted":
            output_dir = self.papers_dir / "extracted" / category
        elif output_type == "translation":
            output_dir = self.papers_dir / "translation" / category
        elif output_type == "heartfelt":
            output_dir = self.papers_dir / "heartfelt" / category
        else:
            output_dir = self.papers_dir / output_type / category

        return output_dir / f"{filename}.json"

    async def translate_paper(self, paper_id: str) -> dict[str, Any]:
        """翻译论文.

        Args:
            paper_id: 论文ID

        Returns:
            翻译任务结果
        """
        source_path = self._get_source_path(paper_id)
        if not source_path.exists():
            raise ValueError(f"Paper not found: {paper_id}")

        # 更新状态
        await self._update_status(paper_id, "processing", "translate")

        try:
            # 启动翻译工作流
            result = await self.workflow_agent.process(
                {
                    "source_path": str(source_path),
                    "workflow": "translate",
                    "paper_id": paper_id,
                }
            )

            if result["success"]:
                await self._update_status(paper_id, "completed", "translate")
                task_id = (
                    f"translate_{paper_id}_{datetime.now().strftime('%Y%m%d%H%M%S')}"
                )
                await self._create_task_record(paper_id, task_id, "translate", result)
                return {
                    "task_id": task_id,
                    "paper_id": paper_id,
                    "status": "completed",
                    "result": result,
                }
            else:
                await self._update_status(
                    paper_id, "failed", "translate", result.get("error") or ""
                )
                raise ValueError(result.get("error", "Translation failed"))

        except Exception as e:
            await self._update_status(paper_id, "failed", "translate", str(e))
            logger.error(f"Error translating paper {paper_id}: {str(e)}")
            raise

    async def analyze_paper(self, paper_id: str) -> dict[str, Any]:
        """分析论文（深度阅读）.

        Args:
            paper_id: 论文ID

        Returns:
            分析任务结果
        """
        source_path = self._get_source_path(paper_id)
        if not source_path.exists():
            raise ValueError(f"Paper not found: {paper_id}")

        # 更新状态
        await self._update_status(paper_id, "processing", "heartfelt")

        try:
            # 启动深度分析工作流
            result = await self.heartfelt_agent.analyze({"paper_id": paper_id})

            if result.get("success", False):
                await self._update_status(paper_id, "completed", "heartfelt")
                analysis_id = (
                    f"analysis_{paper_id}_{datetime.now().strftime('%Y%m%d%H%M%S')}"
                )
                return {
                    "analysis_id": analysis_id,
                    "paper_id": paper_id,
                    "status": "processing"
                    if result.get("status") == "processing"
                    else "completed",
                    "result": result,
                }
            else:
                await self._update_status(
                    paper_id, "failed", "heartfelt", result.get("error") or ""
                )
                raise ValueError(result.get("error", "Analysis failed"))

        except Exception as e:
            await self._update_status(paper_id, "failed", "heartfelt", str(e))
            logger.error(f"Error analyzing paper {paper_id}: {str(e)}")
            raise

    async def batch_translate(self, paper_ids: list[str]) -> dict[str, Any]:
        """批量翻译论文.

        Args:
            paper_ids: 论文ID列表

        Returns:
            批量翻译结果
        """
        # 验证所有论文存在
        valid_paper_ids = []
        for paper_id in paper_ids:
            source_path = self._get_source_path(paper_id)
            if source_path.exists():
                valid_paper_ids.append(paper_id)
            else:
                logger.warning(f"Paper not found for batch translation: {paper_id}")

        if not valid_paper_ids:
            raise ValueError("No valid paper files found")

        # 启动批量翻译
        result = await self.batch_agent.batch_process(
            {"files": valid_paper_ids, "workflow": "translation", "options": {}}
        )

        return {
            "batch_id": f"batch_translate_{datetime.now().strftime('%Y%m%d%H%M%S')}",
            "total_requested": len(paper_ids),
            "total_valid": len(valid_paper_ids),
            "status": result.get("status", "processing"),
            "result": result,
        }
