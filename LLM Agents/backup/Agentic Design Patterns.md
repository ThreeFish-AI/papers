# 智能体设计模式

# 构建智能系统的实践指南 ¹, Antonio Gulli

## 目录 - 总计 424 页 = 1+2+1+1+4+9+103+61+34+114+74+5+4 11

献词, 1 页
致谢, 2 页 [最终, 最后读取完成]
前言, 1 页 [最终, 最后读取完成]
思想领袖的视角：权力与责任 [最终, 最后读取完成]
引言, 4 页 [最终, 最后读取完成]
什么让 AI 系统成为"智能体"?, 9 页 [最终, 最后读取完成]

## 第一部分 (总计: 103 页)

1. 第 1 章：提示链 (代码), 12 页 [最终, 最后读取完成, 代码正常]
2. 第 2 章：路由 (代码), 13 页 [最终, 最后读取完成, 代码正常]
3. 第 3 章：并行化 (代码), 15 页 [最终, 最后读取完成, 代码正常]
4. 第 4 章：反思 (代码), 13 页 [最终, 最后读取完成, 代码正常]
5. 第 5 章：工具使用 (代码), 20 页 [最终, 最后读取完成, 代码正常]
6. 第 6 章：规划 (代码), 13 页 [最终, 最后读取完成, 代码正常]
7. 第 7 章：多智能体 (代码), 17 页 [最终, 最后读取完成, 代码正常], 121

## 第二部分 (总计: 61 页)

8. 第 8 章：内存管理 (代码), 21 页 [最终, 最后读取完成, 代码正常]
9. 第 9 章：学习与适应 (代码), 12 页 [最终, 最后读取完成, 代码正常]
10. 第 10 章：模型上下文协议 (MCP) (代码), 16 页 [最终, 最后读取完成, 代码正常]
11. 第 11 章：目标设定与监控 (代码), 12 页 [最终, 最后读取完成, 代码正常], 182

## 第三部分 (总计: 34 页)

12. 第 12 章：异常处理与恢复 (代码), 8 页 [最终, 最后读取完成, 代码正常]
13. 第 13 章：人在回路 (代码), 9 页 [最终, 最后读取完成, 代码正常]
14. 第 14 章：知识检索 (RAG) (代码), 17 页 [最终, 最后读取完成, 代码正常], 216

## 第四部分 (总计: 114 页)

15. 第 15 章：智能体间通信 (A2A) (代码), 15 页 [最终, 最后读取完成, 代码正常]
16. 第 16 章：资源感知优化 (代码), 15 页 [最终, 最后读取完成, 代码正常]
17. 第 17 章：推理技术 (代码), 24 页 [最终, 最后读取完成, 代码正常]
18. 第 18 章：护栏/安全模式 (代码), 19 页 [最终, 最后读取完成, 代码正常]
19. 第 19 章：评估与监控 (代码), 18 页 [最终, 最后读取完成, 代码正常]
20. 第 20 章：优先级排序 (代码), 10 页 [最终, 最后读取完成, 代码正常 ]
21. 第 21 章：探索与发现 (代码), 13 页 [最终, 最后读取完成, 代码正常], 330

## 附录 (总计: 74 页)

22. 附录 A：高级提示技术, 28 页 [最终, 最后读取完成, 代码正常]
23. 附录 B - AI 智能体....：从 GUI 到现实世界环境, 6 页 [最终, 最后读取完成, 代码正常]
24. 附录 C - 智能体框架快速概述, 8 页 [最终, 最后读取完成, 代码正常],
25. 附录 D - 使用 AgentSpace 构建智能体（仅在线）, 6 页 [最终, 最后读取完成, 代码正常]
26. 附录 E - CLI 上的 AI 智能体（在线）, 5 页 [最终, 最后读取完成, 代码正常]
27. 附录 F - 深入探讨：智能体推理引擎内部视角, 14 页 [最终, 最后读取完成, 代码正常],
28. 附录 G - 编码智能体, 7 页 406
    结论, 5 页 [最终, 最后读取完成]
    术语表, 4 页 [最终, 最后读取完成]
    术语索引, 11 页 (由 Gemini 生成。推理步骤作为智能体示例包含) [最终, 最后读取完成]
    在线贡献 - 常见问题解答：智能体设计模式
    预印版：https://www.amazon.com/Agentic-Design-Patterns-Hands-Intelligent/dp/3032014018/

¹ 我的所有版税将捐赠给拯救儿童基金会

---

## 献词

致我的儿子布鲁诺，
你两岁时，为我的人生带来了崭新而灿烂的光芒。当我探索那些将定义我们未来的系统时，我首先想到的是你将要继承的世界。

致我的儿子莱昂纳多和洛伦佐，以及我的女儿奥罗拉，
我为你们成长为优秀的男女，以及正在建设的美好世界而感到骄傲。这本书是关于如何构建智能工具的，但我把它献给深切的希望——希望你们这一代能够以智慧和同情心来引导这些工具。如果我们学会利用这些强大的技术为人类服务并推动进步，未来对于你们和我们所有人来说都将是无限光明的。致我全部的爱。

---

## 致谢

我想向许多个人和团队表达我诚挚的谢意，是你们让这本书成为可能。

首先，我要感谢谷歌公司坚守其使命，赋能谷歌员工，并尊重创新的机会。我感谢 CTO 办公室给我探索新领域的机会，感谢它坚守"实用魔法"的使命，并具备适应新兴机遇的能力。

我要向威尔·格兰尼斯副总裁致以衷心的感谢，感谢他对人的信任和作为仆人式领导者的品质。感谢我的经理约翰·阿贝尔鼓励我追求我的活动，并总是以他英式的睿智提供卓越的指导。我感谢安托万·拉尔曼雅在代码 LLM 方面的工作，韩寒王在智能体讨论方面的贡献，以及黄英超在时间序列洞察方面的见解。感谢阿什温·拉姆的领导，梅西·马斯卡罗的鼓舞人心的工作，詹妮弗·贝内特的技术专长，布雷特·斯莱特金的工程才能，以及埃里克·申的启发性的讨论。OCTO 团队，特别是斯科特·彭伯西值得称赞。最后，深切感谢帕特里夏·弗洛里西对智能体社会影响的鼓舞愿景。

我还要感谢马可·阿金蒂提出的关于智能体增强人类劳动力的挑战性和激励性的愿景。感谢吉姆·兰齐昂和乔迪·里巴斯推动搜索世界和智能体世界之间的关系。

我也 indebted to Cloud AI 团队，特别是他们的 leader Saurabh Tiwary，推动 AI 组织向着有原则的进步发展。感谢区域技术主管 Salem Salem Haykal 作为一位鼓舞人心的同事。感谢谷歌 Agent 空间的联合创始人弗拉基米尔·武斯科维奇，感谢凯特（卡塔兹娜）奥尔谢夫斯卡在 Kaggle 游戏竞技场上的智能体合作，感谢内特·基廷充满激情地推动 Kaggle，这个社区为 AI 做出了如此多的贡献。我还要感谢卡梅莉亚·阿里亚法，领导专注于 Agent 空间和企业 NotebookLM 的应用 AI 和 ML 团队，以及雅恩·伍兰，一位真正专注于交付的领导者，也是一位总是在那里提供建议的个人朋友。

特别感谢黄英超是一位才华横溢的 AI 工程师，在你面前有伟大的职业前景，感谢韩寒王挑战我在 1994 年初次对智能体产生兴趣后重新回到这个领域，感谢李·布斯特拉在提示工程方面的惊人工作。

我还要感谢 5 Days of GenAI 团队，包括我们的副总裁艾莉森·瓦根费尔德对团队的信任，阿南特·纳瓦尔加里亚总是能够交付成果，以及佩奇·贝利的积极态度和领导力。

我也深深感谢迈克·斯蒂尔、图兰·布尔穆斯和坎查纳·帕托拉帮助我在谷歌 I/O 2025 上发布了三个智能体。感谢你们巨大的工作。

我想向托马斯·库里安表达我诚挚的谢意，感谢他在推动云和 AI 倡议方面坚定不移的领导力、激情和信任。我也深深感谢伊曼纽尔·塔罗帕，他鼓舞人心的"能做到"态度使他成为我在谷歌遇到的最杰出的同事，树立了真正深刻的榜样。最后，感谢菲奥娜·西科尼就谷歌进行的精彩讨论。

我向德米斯·哈萨比斯、普什米特·科利和整个 GDM 团队致以谢意，感谢他们在开发 Gemini、AlphaFold、AlphaGo 和 AlphaGenome 等项目以及其他项目方面的热情努力，以及他们为推动科学造福社会所做的贡献。特别感谢约西·马蒂亚斯对谷歌研究的领导，并始终提供宝贵的建议。我从你那里学到了很多。

特别感谢帕蒂·莫斯，她在 90 年代开创了软件智能体的概念，并始终专注于计算机系统和数字设备如何增强人们并协助他们处理记忆、学习、决策、健康和福祉等问题。你在'91 年的愿景今天已经成为现实。

我还要向保罗·德鲁加斯和施普林格的所有出版团队致以谢意，让这本书成为可能。

我深深地 indebted to 许多帮助将这本书带到生命的才华横溢的人。我衷心感谢马可·法戈的巨大贡献，从代码和图表到审阅整个文本。我也感谢马赫塔布·赛德的编码工作和安基塔·古哈在许多章节提供的极其详细的反馈。普里娅·萨克斯纳富有洞察力的修改，杰·李仔细的审阅，以及马里奥·达罗萨在创建 NotebookLM 版本方面的专门工作，都显著地提高了这本书的质量。我有幸拥有一支专家评审团队来审阅初始章节，我感谢阿米塔·卡普尔博士、法特玛·塔尔拉奇博士、亚历山德罗·科尔纳基亚博士和阿迪蒂亚·曼德尔卡提供他们的专业知识。我也真诚地感谢阿什利·米勒、阿米尔·约翰和帕拉克·卡姆达尔（瓦萨尼）的独特贡献。

对于他们坚定的支持和鼓励，最后要热情地感谢拉贾特·贾恩、阿尔多·帕霍尔、高拉夫·维尔马、帕维特拉·塞纳特、马里乌什·科茨瓦拉、阿比吉特·库马尔、阿姆斯特朗·方德杰、冉海明、乌迪塔·帕特尔和考尔纳卡尔·科塔。没有你们，这个项目真的不可能实现。

所有功劳都归功于你们，
所有的错误都是我的。

我的所有版税都将捐赠给拯救儿童基金会。

---

## 前言

人工智能领域正处于一个迷人的转折点。我们正在超越构建仅仅处理信息的模型，转向创造能够推理、规划并行动以实现复杂目标（任务模糊）的智能系统。正如本书如此恰当描述的那样，这些"智能体"系统代表了 AI 的下一个前沿，它们的发展是激发和激励我们谷歌的挑战。

《智能体设计模式：构建智能系统的实践指南》恰逢其时，为我们的旅程提供指导。本书正确地指出，大型语言模型的力量——这些智能体的认知引擎——必须通过结构和深思熟虑的设计来利用。正如设计模式通过提供通用语言和可重用的解决方案来解决常见问题，从而彻底改变了软件工程一样，本书中的智能体模式将成为构建健壮、可扩展和可靠智能系统的基石。

构建智能体系统的"画布"这个比喻与我们在谷歌 Vertex AI 平台上的工作产生了深刻共鸣。我们努力为开发者提供最强大和灵活的画布来构建下一代 AI 应用程序。本书提供了实用的、动手操作的指导，将赋能开发者充分利用该画布的潜力。

通过探索从提示链和工具使用到智能体间协作、自我纠正、安全和护栏等模式，本书为任何希望构建复杂 AI 智能体的开发者提供了全面的工具包。

AI 的未来将由能够构建这些智能系统的开发者的创造力和才华定义。《智能体设计模式》是一个不可或缺的资源，将有助于释放这种创造力。它提供了基本知识和实践示例，不仅能够理解智能体系统的"什么"和"为什么"，还能理解"如何"。

我很高兴看到这本书到达开发者社区手中。这些页面中的模式和原则无疑将加速创新和有影响力的 AI 应用程序的开发，这些应用程序将在未来几年塑造我们的世界。

萨鲁拉布·蒂瓦里
副总裁兼总经理，CloudAI @ 谷歌

---

## 思想领袖的视角：权力与责任

在我过去四十年见证的所有技术周期中——从个人电脑和网络的诞生，到移动和云的革命——没有一次感觉像这次这样。多年来，围绕人工智能的讨论是炒作与幻灭的熟悉节奏，即所谓的"AI 之夏"之后是漫长的"AI 之冬"。但这一次，有些不同。对话发生了明显的变化。

如果过去的十八个月是关于引擎——大型语言模型（LLMs）令人叹为观止的、几乎是垂直的崛起——那么下一个时代将是关于我们围绕它构建的汽车。它将是关于利用这种原始力量的框架，将其从生成可信文本的生成器转变为真正的行动代理。

我承认，我开始时是一个怀疑者。我发现，可信度往往与一个人对主题的了解程度成反比。早期模型尽管流利，但感觉像是在用一种冒名顶替综合症运作，为可信度而非正确性进行了优化。但随后出现了转折点，由一类新的"推理"模型带来的阶跃变化。突然间，我们不仅仅是在与预测序列中下一个单词的统计机器对话；我们正在窥视一种新生的认知形式。

当我第一次尝试使用一种新的智能体编码工具时，我感受到了那种熟悉的魔火花。我给它分配了一个我从未找到时间做的个人项目：将一个慈善网站从简单的网站构建器迁移到合适的现代 CI/CD 环境。在接下来的二十分钟里，它开始工作，提出澄清问题，请求凭据，并提供状态更新。感觉不像是在使用工具，更像是与初级开发人员合作。当它向我展示一个完全可部署的包，包含无可挑剔的文档和单元测试时，我被震撼了。

当然，它并不完美。它会犯错误。它会卡住。它需要我的监督，关键是，我的判断来引导它回到正轨。这段经历让我深刻体会到了我在漫长职业生涯中艰难学到的一课：你不能盲目信任。然而，这个过程是迷人的。窥视它的"思维链"就像看着大脑在工作——杂乱、非线性，充满开始、停止和自我纠正，就像我们自己的人类推理一样。它不是一条直线；它是朝向解决方案的随机游走。

这里孕育着新事物的种子：不仅是能够生成内容的智能，而且是能够生成计划的智能。

这就是智能体框架的承诺。它是静态地铁地图和动态 GPS 之间的区别，后者会实时重新规划你的路线。经典的基于规则的自动化器遵循固定路径；当遇到意外障碍时，它会崩溃。由推理模型驱动的 AI 智能体有潜力观察、适应并找到另一种方式。它拥有一种数字常识形式，使其能够驾驭现实中无数的边缘情况。它代表了一种转变，从简单地告诉计算机做什么，到解释为什么我们需要完成某事并信任它找出如何做。

正如这个新前沿令人振奋一样，它带来了一种深刻的责任感，特别是从我作为全球金融机构 CIO 的角度来看。风险极高。一个在创建"鸡三文鱼融合派"食谱时犯错的智能体只是一个有趣的轶事。一个在执行交易、管理风险或处理客户数据时犯错的智能体是一个真正的问题。我读过免责声明和警示故事：网络自动化智能体在登录失败后，决定给国会议员发邮件抱怨登录墙。这是一个黑色幽默的提醒，我们正在处理一种我们不完全理解的技术。

在这里，技艺、文化和对我们原则的不懈关注成为我们的基本指南。我们的工程准则不仅仅是页面上的文字；它们是我们的指南针。我们必须有目的地构建，确保我们设计的每个智能体都从清楚理解的客户问题开始。我们必须环顾四周，预见故障模式并设计具有弹性设计的系统。最重要的是，我们必须激发信任，对我们的方法保持透明，对我们的结果负责。

在智能体世界中，这些准则变得紧迫起来。严酷的真相是，你不能简单地将这些强大的新工具叠加到混乱、不一致的系统上并期望得到好的结果。混乱的系统加上智能体是灾难的根源。在"垃圾"数据上训练的 AI 不仅仅产生垃圾输出；它产生的是自信的、可信的垃圾，可能毒害整个过程。因此，我们最关键和最重要的任务是准备基础。我们必须投资于干净的数据、一致的元数据和定义良好的 API。我们必须建设现代化的"州际公路系统"，让这些智能体能够安全高速运行。这是构建可编程企业的艰难基础工作，即"作为软件的企业"，我们的流程和我们的代码一样架构良好。

归根结底，这段旅程不是要取代人类的聪明才智，而是要增强它。它要求我们每个人都具备一套新的技能：清晰解释任务的能力、授权的智慧，以及验证输出质量的勤奋。它要求我们谦逊，承认我们不知道的，并且永不停止学习。本书后续页面提供了构建这些新框架的技术地图。我的希望是，你们不仅会用它们来构建可能的东西，还会用来构建正确的、健壮的和负责任的东西。

世界要求每个工程师都挺身而出。我相信我们已准备好迎接挑战。享受这段旅程。

马可·阿金蒂，CIO，高盛

---

## 前言

欢迎阅读《智能体设计模式：构建智能系统的实践指南》。当我们纵观现代人工智能的图景时，我们看到了从简单、反应式程序到能够理解上下文、做出决策并与环境和其他系统动态交互的复杂、自主实体的清晰演进。这些就是智能智能体和它们组成的智能体系统。

强大的大型语言模型（LLMs）的出现为理解和生成人类般的内容（如文本和媒体）提供了前所未有的能力，作为许多这些智能体的认知引擎。然而，将这些能力协调成能够可靠实现复杂目标的系统需要的不仅仅是一个强大的模型。它需要结构、设计，以及对智能体如何感知、规划、行动和交互的深思熟虑的方法。

将构建智能系统想象成在画布上创作复杂的艺术品或工程。这个画布不是空白的视觉空间，而是为你的智能体存在和操作提供环境和工具的基础设施和框架。它是你将构建智能应用程序的基础，管理状态、通信、工具访问和逻辑流。

在这个智能体画布上有效构建需要的不仅仅是简单地将组件组合在一起。它需要理解经过验证的技术——模式——来解决在设计和实施智能体行为时面临的共同挑战。正如建筑模式指导建筑物的建造，或设计模式构建软件一样，智能体设计模式为在你选择的画布上让智能体焕发生机时面临的重复问题提供了可重用的解决方案。

### 什么是智能体系统？

在其核心，智能体系统是一个计算实体，旨在感知其环境（数字的和潜在的物理的），基于这些感知和一组预定义或学习到的目标做出明智的决策，并自主执行行动以实现这些目标。与传统软件遵循 rigid、逐步指令不同，智能体表现出一定程度的灵活性和主动性。

想象你需要一个系统来管理客户咨询。传统系统可能遵循固定脚本。然而，智能体系统可以感知客户查询的细微差别，访问知识库，与其他内部系统（如订单管理）交互，可能提出澄清问题，并主动解决问题，甚至可能预见未来需求。这些智能体在你的应用程序基础设施的画布上运行，利用它们可用的服务和数据。

智能体系统通常具有自主性、能够在没有持续人工监督的情况下行动；主动性，朝着其目标发起行动；和反应性，有效响应环境变化等特征。它们是目标导向的，不断朝着目标努力。一个关键能力是工具使用，使它们能够与外部 API、数据库或服务交互——有效地超出其直接画布的范围。它们拥有记忆，在交互中保留信息，并能够与用户、其他系统，甚至在相同或连接画布上运行的其他智能体进行通信。

有效实现这些特征带来了显著的复杂性。智能体如何在其画布上的多个步骤中维持状态？它如何决定何时以及如何使用工具？不同智能体之间的通信如何管理？你如何在系统中构建弹性以处理意外结果或错误？

### 为什么模式在智能体开发中很重要

这种复杂性正是为什么智能体设计模式不可或缺的原因。它们不是严格的规则，而是经过战斗测试的模板或蓝图，为智能体领域中的标准设计和实施挑战提供经过验证的方法。

通过识别和应用这些设计模式，你可以获得增强在你画布上构建的智能体的结构、可维护性、可靠性和效率的解决方案。使用设计模式有助于你避免重新发明基本解决方案，如管理对话流程、集成外部能力或协调多个智能体行动。它们提供了通用语言和结构，使你的智能体逻辑更清晰，更容易让其他人（和未来的你）理解和维护。实施专为错误处理或状态管理设计的模式直接有助于构建更健壮和可靠的系统。利用这些已建立的方法加速你的开发过程，让你能够专注于应用程序的独特方面，而不是智能体行为的基础机制。

本书提取了 21 个关键设计模式，代表了在各种技术画布上构建复杂智能体的基本构建块和技术。理解和应用这些模式将显著提高你有效设计和实施智能系统的能力。

### 书籍概述及如何使用

本书《智能体设计模式：构建智能系统的实践指南》旨在成为实用且易于理解的资源。其主要重点是清晰地解释每个智能体模式，并提供具体的、可运行的代码示例来演示其实施。

在 21 个专门章节中，我们将探索多样的设计模式，从基础概念如结构化顺序操作（提示链）和外部交互（工具使用）到更高级的主题如协作工作（多智能体协作）和自我改进（自我纠正）。

本书按章节组织，每章深入研究单一的智能体模式。在每个章节中，你会发现：

● 详细的模式概述，清晰解释模式及其在智能体设计中的作用。
● 实际应用和用例部分，说明模式在现实世界场景中的宝贵价值和带来的好处。
● 动手代码示例，提供实用的、可运行的代码，演示使用知名智能体开发框架的模式实施。在这里你将看到如何在技术画布的上下文中应用模式。
● 关键要点，总结最重要的观点以便快速回顾。
● 进一步探索的参考，提供有关模式和概念的更深入学习资源。

虽然章节按递进概念排序，但请随意将本书作为参考，跳转到解决你自己智能体开发项目中面临的具体挑战的章节。附录全面介绍了高级提示技术、在现实世界环境中应用 AI 智能体的原则，以及基本智能体框架的概述。为了补充这一点，包括实用的在线教程，提供使用特定平台如 AgentSpace 和命令行界面构建智能体的分步指导。整个强调的是实际应用；我们强烈鼓励你运行代码示例，进行实验，并调整它们以在你选择的画布上构建你自己的智能系统。

我听到的一个很好的问题是，'随着 AI 变化如此之快，为什么要写一本可能很快过时的书？'我的动机恰恰相反。正是因为事情变化如此之快，我们需要退后一步，识别正在固化的基本原则。像 RAG、反思、路由、记忆等模式，正在成为基本的构建块。这本书是对这些核心思想的反思邀请，它们提供了我们需要在其上构建的基础。人类需要对这些基础模式进行反思时刻

### 所用框架简介

为了为我们的代码示例提供可触摸的"画布"（另见附录），我们将主要利用三个知名的智能体开发框架。LangChain 及其有状态扩展 LangGraph 提供了将语言模型和其他组件链接在一起的灵活方式，为构建复杂序列和操作图提供了强大的画布。Crew AI 提供了专门设计用于协调多个 AI 智能体、角色和任务的结构化框架，作为特别适合协作智能体系统的画布。谷歌智能体开发工具包（Google ADK）提供了构建、评估和部署智能体的工具和组件，提供了另一个有价值的画布，通常与谷歌的 AI 基础设施集成。

这些框架代表了智能体开发画布的不同方面，各有其优势。通过在这些工具中展示示例，无论你为你的智能体系统选择什么特定的技术环境，你都将获得如何应用这些模式的更广泛理解。这些示例旨在清晰说明模式的核心逻辑及其在框架画布上的实施，专注于清晰性和实用性。

到本书结束时，你不仅将理解 21 个基本智能体模式背后的基本概念，还将拥有有效应用它们的实用知识和代码示例，使你能够在选择的开发画布上构建更智能、更有能力和更自主的系统。让我们开始这个实践之旅吧！

---

## 是什么让 AI 系统成为智能体？

简单来说，AI 智能体是一个旨在感知其环境并采取行动以实现特定目标的系统。它是从标准大型语言模型（LLM）的演进，增强了规划、使用工具和与周围环境交互的能力。

将智能体 AI 想象成一个在工作中学习的智能助手。它遵循一个简单的五步循环来完成任务（见图 1）：

1. 接受任务：你给它一个目标，比如"整理我的日程表"。
2. 扫描场景：它收集所有必要信息——阅读邮件、检查日历和访问联系人——以了解正在发生的事情。
3. 深入思考：它通过考虑实现目标的最优方法来制定行动计划。
4. 采取行动：它通过发送邀请、安排会议和更新你的日历来执行计划。
5. 学习改进：它观察成功结果并相应调整。例如，如果会议重新安排，系统会从这个事件中学习以提高未来性能。

![img_1_0_20251210_190214.png](../images/Agentic%20Design%20Patterns/img_1_0_20251210_190214.png)

图 1：智能体 AI 作为智能助手运行，通过经验不断学习。它通过简单的五步循环来完成任务。

智能体正以惊人的速度变得越来越受欢迎。根据最近的研究，大多数大型 IT 公司正在积极使用这些智能体，其中五分之一是在过去一年内开始的。金融市场也在关注。到 2024 年底，AI 智能体初创公司已筹集超过 20 亿美元，市场价值为 52 亿美元。预计到 2034 年，其价值将激增至近 2000 亿美元。简而言之，所有迹象都表明 AI 智能体将在我们未来的经济中发挥巨大作用。

在短短两年内，AI 范式发生了戏剧性转变，从简单自动化转向复杂的自主系统（见图 2）。最初，工作流依赖基本提示和触发器来用 LLMs 处理数据。这随着检索增强生成（RAG）而发展，通过基于事实信息锚定模型来增强可靠性。然后我们看到能够使用各种工具的个体 AI 智能体的发展。今天，我们正在进入智能体 AI 时代，在那里专门的智能体团队协同工作以实现复杂目标，标志着 AI 协作能力的重大飞跃。

![img_13_0_20251210_190215.png](../images/Agentic%20Design%20Patterns/img_13_0_20251210_190215.png)

图 2：从 LLMs 到 RAG，再到智能体 RAG，最后到智能体 AI 的过渡。

本书的意图是讨论专门智能体如何协调工作并协作以实现复杂目标的设计模式，你将在每章中看到一个协作和交互的范式。

在这样做之前，让我们审视一下跨越智能体复杂性范围的例子（见图 3）。

### 0 级：核心推理引擎

虽然 LLM 本身不是智能体，但它可以作为基本智能体系统的推理核心。在"0 级"配置中，LLM 在没有工具、记忆或环境交互的情况下运行，仅基于其预训练知识响应。它的优势在于利用其广泛的训练数据来解释既定概念。

这种强大的内部推理的权衡是完全缺乏当前事件意识。例如，如果 2025 年奥斯卡"最佳影片"获奖者在其预训练知识之外，它将无法说出名字。

### 1 级：连接的问题解决者

在这个级别，LLM 通过连接和利用外部工具成为功能性智能体。它的问题解决不再局限于其预训练知识。相反，它可以执行一系列行动来从互联网（通过搜索）或数据库（通过检索增强生成，或 RAG）等来源收集和处理信息。详细信息，请参阅第 14 章。

例如，为了找到新的电视节目，智能体认识到需要当前信息，使用搜索工具找到它，然后综合结果。关键是，它还可以使用专门的工具以获得更高的准确性，例如调用金融 API 来获取 AAPL 的实时股票价格。这种与外部世界跨多个步骤交互的能力是 1 级智能体的核心能力。

### 2 级：战略性问题解决者

在这个级别，智能体的能力显著扩展，包括战略规划、主动协助和自我改进，以提示工程和上下文工程作为核心使能技能。

首先，智能体超越单一工具使用，通过战略性问题解决来处理复杂的多部分问题。当它执行一系列行动时，它主动进行上下文工程：选择、包装和管理每个步骤最相关信息的过程。例如，为了在两个地点之间找到咖啡店，它首先使用地图工具。然后它工程这个输出，策划一个简短、集中的上下文——也许只是一个街道名称列表——输入到本地搜索工具中，防止认知过载并确保第二步高效准确。为了从 AI 获得最大准确性，必须给它简短、集中和强大的上下文。上下文工程是通过战略性地选择、包装和管理来自所有来源的最关键信息来完成这一点的学科。它有效地策划模型的有限注意力，以防止过载并确保在任何给定任务上高质量、高效的性能。详细信息，请参阅附录 A。

这个级别导致主动和持续操作。与你邮件关联的旅行助手通过工程化来自冗长航班确认邮件的上下文来展示这一点；它只选择关键细节（航班号、日期、地点）为后续调用你的日历和天气 API 打包。

在软件工程等专业领域，智能体通过应用这个学科来管理工作流程。当分配到一个错误报告时，它读取报告并访问代码库，然后战略性地工程这些大量信息源成为一个强大、集中的上下文，使其能够高效地编写、测试和提交正确的代码补丁。

最后，智能体通过改进其自己的上下文工程过程来实现自我改进。当它询问反馈提示如何可以改进时，它正在学习如何更好地策划其初始输入。这使它能够自动改进它为未来任务打包信息的方式，创建一个强大的、自动化的反馈循环，随着时间推移提高其准确性和效率。详细信息，请参阅第 17 章。

![img_14_0_20251210_190215.png](../images/Agentic%20Design%20Patterns/img_14_0_20251210_190215.png)

图 3：展示智能体复杂性范围的各种实例。

### 3 级：协作多智能体系统的兴起

在 3 级，我们看到了 AI 发展的重大范式转变，从追求单一的、全能的超级智能体转向复杂的、协作的多智能体系统。本质上，这种方法认识到复杂的挑战通常最好不是由单一通才解决，而是由专家团队协同工作解决。这种模型直接反映了人类组织的结构，在那里不同部门被分配特定角色并协作处理多方面目标。这种系统的集体力量在于劳动分工和通过协调努力创造的协同效应。详细信息，请参阅第 7 章。

为了让这个概念生动起来，考虑推出新产品的复杂工作流程。而不是一个智能体尝试处理每个方面，一个"项目经理"智能体可以作为中央协调者。这个经理将把任务委托给其他专门智能体来协调整个过程：一个"市场研究"智能体来收集消费者数据，一个"产品设计"智能体来开发概念，以及一个"营销"智能体来制作宣传材料。他们成功的关键将是他们之间无缝的通信和信息共享，确保所有个人努力与实现集体目标一致。

虽然这种自主的、基于团队的自动化愿景已经在开发中，但重要的是要承认当前的障碍。这种多智能体系统的有效性目前受到它们使用的 LLMs 推理限制的约束。此外，他们真正相互学习和作为有凝聚力的单元改进的能力仍处于早期阶段。克服这些技术瓶颈是关键的下一步，这样做将释放这个层级的深刻承诺：能够从头到尾自动化整个业务工作流程。

### 智能体的未来：5 个假设

AI 智能体开发正在前所未有的速度在软件自动化、科学研究、客户服务等领域推进。虽然当前的系统令人印象深刻，但这仅仅是开始。下一波创新可能会专注于使智能体更可靠、更协作，并更深入地集成到我们的生活中。以下是关于接下来什么的五个主要假设（见图 4）。

#### 假设 1：通用智能体的出现

第一个假设是 AI 智能体将从狭窄的专家演变为能够管理复杂、模糊和长期目标的真正通才，具有高可靠性。例如，你可以给智能体一个简单的提示，如"为我公司 30 人在里斯本的下季度外出静修做计划。"然后智能体将管理整个项目数周，处理从预算批准和航班谈判到场地选择和根据员工反馈创建详细行程的所有事情，同时提供定期更新。实现这种自主水平将需要 AI 推理、记忆和近乎完美可靠性的根本突破。

另一种但非互斥的方法是小型语言模型（SLMs）的兴起。这种"乐高式"概念涉及从小型、专门专家智能体组合系统，而不是扩展单一的、庞大的模型。这种方法承诺系统更便宜、调试更快、更容易部署。最终，大型通用模型的开发和较小专门模型的组合都是可行的前进道路，它们甚至可以互补。

#### 假设 2：深度个性化和主动目标发现

第二个假设假设智能体将成为深度个性化和主动的伙伴。我们正在见证一类新智能体的出现：主动伙伴。通过学习你独特的模式和目标，这些系统开始从仅仅跟随命令转向预见你的需求。当 AI 系统超越简单响应聊天或指令时，它们作为智能体运行。它们代表用户发起和执行任务，在过程中积极参与。这超越了简单的任务执行，进入了主动目标发现的领域。

例如，如果你正在探索可持续能源，智能体可能会识别你的潜在目标并主动支持它，建议课程或总结研究。虽然这些系统仍在发展中，但它们的轨迹是清晰的。它们将变得越来越主动，学习在高度确信行动会有帮助时代表你采取主动。最终，智能体成为不可或缺的盟友，帮助你发现和实现你尚未完全表达的雄心。

![img_17_0_20251210_190215.png](../images/Agentic%20Design%20Patterns/img_17_0_20251210_190215.png)

图 4：关于智能体未来的五个假设

#### 假设 3：具身化和物理世界交互

这个假设预见智能体打破纯粹数字限制在物理世界中运行。通过将智能体 AI 与机器人技术集成，我们将看到"具身智能体"的兴起。你不仅可以预约水管工，还可以要求你的家庭智能体修理漏水的水龙头。智能体将使用其视觉传感器感知问题，访问管道知识库制定计划，然后精确控制其机械臂执行修理。这将代表一个巨大步骤，弥合数字智能和物理行动之间的鸿沟，改变从制造业和物流到老年护理和家庭维护的一切。

#### 假设 4：智能体驱动的经济

第四个假设是高度自主的智能体将成为经济中的积极参与者，创造新的市场和商业模式。我们可以看到智能体作为独立经济实体行动，被赋予最大化特定结果（如利润）的任务。企业家可以启动一个智能体来运行整个电子商务业务。该智能体将通过分析社交媒体识别趋势产品，生成营销文案和视觉效果，通过与其他自动化系统交互管理供应链物流，并根据实时需求动态调整定价。

这种转变将创造一个新的、超高效的"智能体经济"，以人类无法直接管理的速度和规模运作。

#### 假设 5：目标驱动的、变形多智能体系统

这个假设假设从明确编程运行，而是从声明的目标运行的智能系统的出现。用户只需陈述期望的结果，系统就会自主找出如何实现它。这标志着向能够在个体和集体层面真正自我改进的变形多智能体系统的根本转变。

这将是一个动态实体，而不是单一智能体的系统。它将能够分析自己的性能并修改其多智能体工作队的拓扑结构，根据需要创建、复制或删除智能体，为手头的任务形成最有效的团队。这种进化发生在多个层面：

● 架构修改：在最深层次，单个智能体可以重写自己的源代码并重新架构其内部结构以获得更高效率，如原始假设中那样。
● 指令修改：在更高层次，系统持续执行自动提示工程和上下文工程。它优化给每个智能体的指令和信息，确保它们在没有人为干预的情况下以最优指导运行。

例如，企业家只需声明意图："启动一个成功的销售手工咖啡的电子商务业务。"系统，无需进一步编程，就会立即行动。它可能最初产生一个"市场研究"智能体和一个"品牌"智能体。基于初步发现，它可能决定移除品牌智能体并产生三个新的专门智能体：一个"标志设计"智能体，一个"网上商店平台"智能体，以及一个"供应链"智能体。它将不断调整它们的内部提示以获得更好的性能。如果网上商店智能体成为瓶颈，系统可能将其复制成三个并行智能体来处理站点的不同部分，有效地动态重新架构自己的结构以最好地实现声明的目标。

### 结论

本质上，AI 智能体代表了从传统模型的重大飞跃，作为感知、规划和行动以实现特定目标的自主系统运行。这种技术的进步正在从单一的工具使用智能体转向处理多方面目标的复杂、协作的多智能体系统。

未来的假设预测通用、个性化甚至物理具身智能体的出现，它们将成为经济中的积极参与者。这种持续发展标志着向自我改进、目标驱动的系统的重大范式转变，这些系统将自动化整个工作流程并从根本上重新定义我们与技术的关系。

### 参考文献

1. Cloudera, Inc. (2025 年 4 月)，96%的企业正在增加其对 AI 智能体的使用。https://www.cloudera.com/about/news-and-blogs/press-releases/2025-04-16-96-percent-of-enterprises-are-expanding-use-of-ai-agents-according-to-latest-data-from-cloudera.html
2. 自主生成式 AI 智能体：https://www.deloitte.com/us/en/insights/industry/technology/technology-media-and-telecom-predictions/2025/autonomous-generative-ai-agents-still-under-development.html
3. Market.us. 全球智能体 AI 市场规模、趋势和预测 2025–2034。https://market.us/report/agentic-ai-market/

---

## 第 1 章：提示链

### 提示链模式概述

提示链，有时称为管道模式，代表了利用大型语言模型（LLMs）处理复杂任务的强大范式。与其期望 LLM 在单一的、整体的步骤中解决复杂问题，提示链提倡分而治之的策略。核心思想是将原始的、令人生畏的问题分解为一系列更小、更可管理的子问题。每个子问题通过专门设计的提示单独解决，一个提示生成的输出作为输入策略性地馈送到链中的后续提示。

这种顺序处理技术固有地在与 LLMs 的交互中引入了模块性和清晰性。通过分解复杂任务，更容易理解和调试每个单独步骤，使整个过程更健壮和可解释。链中的每个步骤都可以精心制作和优化，专注于更大问题的特定方面，导致更准确和集中的输出。

一个步骤的输出作为下一个步骤的输入至关重要。这种信息传递建立了依赖链，因此得名，其中先前操作的上下文和结果指导后续处理。这使得 LLM 能够在其先前工作基础上构建，完善其理解，并逐步接近期望的解决方案。

此外，提示链不仅仅是分解问题；它还使得能够集成外部知识和工具。在每个步骤，可以指示 LLM 与外部系统、API 或数据库交互，丰富其超越其内部训练数据的知识和能力。这种能力极大地扩展了 LLMs 的潜力，使它们不仅作为隔离模型，而且作为更广泛、更智能系统的组成部分发挥作用。

提示链的意义超越了简单的问题解决。它作为构建复杂 AI 智能体的基础技术。这些智能体可以利用提示链在动态环境中自主规划、推理和行动。通过策略性地构建提示序列，智能体可以参与需要多步推理、规划和决策的任务。这种智能体工作流可以更紧密地模仿人类思维过程，允许与复杂域和系统进行更自然和有效的交互。

### 单个提示的局限性：

对于多方面任务，对 LLM 使用单个、复杂的提示可能效率低下，导致模型难以处理约束和指令，可能导致指令忽视，其中提示的部分被忽略；上下文漂移，其中模型失去初始上下文的跟踪；错误传播，其中早期错误放大；提示需要更长的上下文窗口，其中模型获得不足信息来响应；以及幻觉，其中认知负荷增加了错误信息的几率。例如，一个要求分析市场研究报告、总结发现、识别带数据点的趋势并起草电子邮件的查询有失败风险，因为模型可能总结良好但未能提取数据或正确起草电子邮件。

### 通过顺序分解增强可靠性：

提示链通过将复杂任务分解为专注的、顺序的工作流程来解决这些挑战，这显著提高了可靠性和控制。鉴于上述例子，管道或链接方法可以描述如下：

1. 初始提示（总结）："总结以下市场研究报告的关键发现：[文本]。"模型的唯一焦点是总结，增加了这个初始步骤的准确性。
2. 第二提示（趋势识别）："使用总结，识别三个新兴趋势并提取支持每个趋势的具体数据点：[步骤 1 的输出]。"这个提示现在更加受限，直接建立在验证输出之上。
3. 第三提示（电子邮件撰写）："为营销团队起草一个简洁的电子邮件，概述以下趋势及其支持数据：[步骤 2 的输出]。"

这种分解允许对过程更精细的控制。每个步骤更简单且更少歧义，这减少了模型的认知负荷，并导致更准确和可靠的最终输出。这种模块性类似于计算管道，其中每个函数在将其结果传递给下一个之前执行特定操作。为确保每个特定任务的准确响应，模型可以在每个阶段分配不同的角色。例如，在给定场景中，初始提示可以指定为"市场分析师"，后续提示为"贸易分析师"，第三提示为"专家文档撰写者"等等。

### 结构化输出的作用：

提示链的可靠性高度依赖于步骤之间传递的数据完整性。如果一个提示的输出模糊或格式不良，后续提示可能由于故障输入而失败。为了缓解这一点，指定结构化输出格式（如 JSON 或 XML）至关重要。

例如，趋势识别步骤的输出可以格式化为 JSON 对象：

```json
{
  "trends": [
    {
      "trend_name": "AI驱动的个性化",
      "supporting_data": "73%的消费者更愿意与使用个人信息使其购物体验更相关的品牌做生意。"
    },
    {
      "trend_name": "可持续和道德品牌",
      "supporting_data": "具有ESG相关声明的产品销售额在过去五年中增长了28%，而没有ESG相关声明的产品增长了20%。"
    }
  ]
}
```

这种结构化格式确保数据是机器可读的，并且可以精确解析并插入到下一个提示中而不会产生歧义。这种实践最大限度地减少了可能从解释自然语言中产生的错误，是构建健壮的多步 LLM 系统的一个关键组成部分。

### 实际应用和用例

提示链是一种多功能模式，适用于构建智能体系统时的各种场景。其核心实用性在于将复杂问题分解为顺序的、可管理的步骤。以下是几个实际应用和用例：

1. 信息处理工作流：许多任务涉及通过多个转换处理原始信息。例如，总结文档、提取关键实体，然后使用这些实体查询数据库或生成报告。提示链可能如下：
   - 提示 1：从给定 URL 或文档提取文本内容。
   - 提示 2：总结清理后的文本。
   - 提示 3：从摘要或原始文本中提取特定实体（例如，姓名、日期、位置）。
   - 提示 4：使用实体搜索内部知识库。
   - 提示 5：生成包含摘要、实体和搜索结果的最终报告。

这种方法应用于自动内容分析、AI 驱动研究助手开发和复杂报告生成等领域。

2. 复杂查询回答：回答需要多个推理或信息检索步骤的复杂问题是主要用例。例如，"1929 年股市崩盘的主要原因是什么，政府政策如何回应？"
   - 提示 1：识别用户查询中的核心子问题（崩盘原因、政府回应）。
   - 提示 2：专门研究或检索关于 1929 年崩盘原因的信息。
   - 提示 3：专门研究或检索关于政府对 1929 年股市崩盘政策回应的信息。
   - 提示 4：将步骤 2 和 3 的信息综合成对原始查询的连贯回答。

这种顺序处理方法是开发能够进行多步推理和信息综合的 AI 系统的组成部分。当查询不能从单一数据点回答而是需要一系列逻辑步骤或来自多样化来源的信息集成时，需要这种系统。

例如，一个设计用于生成特定主题综合报告的自动研究智能体执行混合计算工作流。最初，系统检索大量相关文章。从每篇文章提取关键信息的后续任务可以为每个源并发执行。这个阶段非常适合并行处理，在那里独立子任务同时运行以最大化效率。然而，一旦个别提取完成，过程变得固有地顺序化。系统必须首先整理提取的数据，然后将其综合成连贯的草稿，最后审查和完善草稿以产生最终报告。这些后期阶段每个都在逻辑上依赖于前面阶段的成功完成。这里就是应用提示链的地方：整理的数据作为综合提示的输入，产生的综合文本成为最终审查提示的输入。因此，复杂操作经常将独立数据收集的并行处理与综合和完善步骤的提示链结合起来。

3. 数据提取和转换：将非结构化文本转换为结构化格式通常通过迭代过程实现，需要顺序修改以提高输出的准确性和完整性。
   - 提示 1：尝试从发票文档中提取特定字段（例如，姓名、地址、金额）。
   - 处理：检查是否提取了所有必需字段以及它们是否符合格式要求。
   - 提示 2（条件）：如果字段缺失或格式错误，制作新提示要求模型专门找到缺失/格式错误的信息，也许提供来自失败尝试的上下文。
   - 处理：再次验证结果。如有必要重复。
   - 输出：提供提取的、验证过的结构化数据。

这种顺序处理方法特别适用于从表单、发票或电子邮件等非结构化来源的数据提取和分析。例如，解决复杂光学字符识别（OCR）问题，如处理 PDF 表单，通过分解的多步骤方法更有效地处理。最初，使用大型语言模型对文档图像执行主要文本提取。在此之后，模型处理原始输出以规范化数据，在这个步骤中它可能将数字文本（如"一千零五十"）转换为数字等价物 1050。LLMs 执行精确数学计算的一个重要挑战。因此，在后续步骤中，系统可以将任何需要的算术操作委托给外部计算器工具。LLM 识别必要的计算，将规范化的数字馈送到工具，然后整合精确结果。这种文本提取、数据规范化和外部工具使用的链接序列实现了最终的准确结果，这通常很难从单一 LLM 查询可靠获得。

4. 内容生成工作流：复杂内容的编写是一项程序性任务，通常分解为不同阶段，包括初始构思、结构大纲、起草和后续修订
   - 提示 1：基于用户的一般兴趣生成 5 个主题想法。
   - 处理：允许用户选择一个想法或自动选择最好的一个。
   - 提示 2：基于选定的主题生成详细大纲。
   - 提示 3：基于大纲中的第一点起草部分。
   - 提示 4：基于大纲中的第二点起草部分，提供前一部分作为上下文。对所有大纲点继续此操作。
   - 提示 5：审查和完善完整草稿的连贯性、语调和语法。

这种方法用于一系列自然语言生成任务，包括创意叙事、技术文档和其他形式的结构化文本内容的自动编写。

5. 有状态的对话智能体：虽然全面的状态管理架构使用比顺序链接更复杂的方法，但提示链为保持对话连续性提供了基本机制。这种技术通过构建每个对话回合作为新的提示来维持上下文，该提示系统地整合对话序列中前面交互的信息或提取的实体。
   - 提示 1：处理用户话语 1，识别意图和关键实体。
   - 处理：用意图和实体更新对话状态。
   - 提示 2：基于当前状态，生成回应和/或识别下一个需要的信息片段。
   - 为后续回合重复，每个新的用户话语启动一个利用积累对话历史（状态）的链。

这个原则是对话智能体开发的基础，使它们能够在扩展的多轮对话中维持上下文和连贯性。通过保留对话历史，系统可以理解和适当地响应依赖于先前交换信息的用户输入。

6. 代码生成和完善：功能代码的生成通常是一个多阶段过程，需要将问题分解为逐步执行的离散逻辑操作序列
   - 提示 1：理解用户的代码功能请求。生成伪代码或大纲。
   - 提示 2：基于大纲编写初始代码草稿。
   - 提示 3：识别代码中的潜在错误或改进领域（也许使用静态分析工具或另一次 LLM 调用）。
   - 提示 4：基于识别的问题重写或改进代码。
   - 提示 5：添加文档或测试用例。

在 AI 辅助软件开发等应用中，提示链的实用性源于其将复杂编码任务分解为一系列可管理子问题的能力。这种模块化结构减少了大型语言模型在每个步骤的操作复杂性。关键是，这种方法还允许在模型调用之间插入确定性逻辑，使得在工作流内能够进行中间数据处理、输出验证和条件分支。通过这种方法，一个单一的、多方面的请求，否则可能导致不可靠或不完整的结果，被转换为由底层执行框架管理的结构化操作序列。

7. 多模态和多步推理：分析具有多样化模态的数据集需要将问题分解为更小的、基于提示的任务。例如，解释一个包含嵌入文本的图片、突出特定文本段的标签和解释每个标签的表格数据的图像，需要这种方法。
   - 提示 1：从用户图像请求中提取和理解文本。
   - 提示 2：将提取的图像文本与其相应标签链接。
   - 提示 3：使用表格解释收集的信息以确定所需输出。

### 动手代码示例

实施提示链范围从脚本内的直接、顺序函数调用到利用专门设计用于管理控制流、状态和组件集成的框架。LangChain、LangGraph、Crew AI 和谷歌智能体开发工具包（Google ADK）等框架为构建和执行这些多步骤过程提供了结构化环境，这对于复杂架构特别有利。

出于演示目的，LangChain 和 LangGraph 是合适的选择，因为它们的核心 API 明确设计用于组合操作链和图。LangChain 为线性序列提供基础抽象，而 LangGraph 将这些能力扩展到支持有状态和循环计算，这对于实现更复杂的智能体行为是必要的。本示例将专注于基本的线性序列。

以下代码实现了一个两步提示链，作为数据处理管道运行。初始阶段旨在解析非结构化文本并提取特定信息。后续阶段然后接收这个提取的输出并将其转换为结构化数据格式。

为了复制这个过程，必须首先安装所需的库。这可以使用以下命令完成：

```bash
pip install langchain langchain-community langchain-openai langgraph
```

注意，langchain-openai 可以替换为适合不同模型提供者的相应包。随后，必须为所选语言模型提供者（如 OpenAI、谷歌 Gemini 或 Anthropic）配置执行环境与必要的 API 凭据。

```python
import os
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

# 为了更好的安全性，从.env文件加载环境变量
# from dotenv import load_dotenv
```

# 第 1 章：提示链（续）

### 上下文工程和提示工程

上下文工程（见图 1）是在令牌生成之前设计、构建和向 AI 模型交付完整信息环境的系统性学科。该方法断言，模型输出的质量较少依赖于模型架构本身，而更多地依赖于所提供上下文的丰富性。

![img_30_0_20251210_191647.png](../images/Agentic%20Design%20Patterns/img_30_0_20251210_191647.png)

图 1：上下文工程是为 AI 构建丰富、全面的信息环境的学科，因为这个上下文的质量是实现高级智能体性能的主要因素。

它代表了从传统提示工程的重大演进，后者主要专注于优化用户即时查询的措辞。上下文工程将这个范围扩展到包括几个信息层，如系统提示，这是一组定义 AI 操作参数的基础指令——例如，"你是一名技术作家；你的语调必须正式和精确。"

上下文通过外部数据进一步丰富。这包括检索文档，AI 主动从知识库中获取信息以通知其响应，例如为项目提取技术规格。它还包含工具输出，这些是 AI 使用外部 API 获取实时数据的结果，如查询日历以确定用户的可用性。这种明确的数据与关键的隐性数据相结合，如用户身份、交互历史和环境状态。

核心原则是，即使是高级模型，在提供有限或构建不良的操作环境视图时也会表现不佳。因此，这种实践将任务从仅仅回答问题重新定义为为智能体构建全面的操作图。例如，一个经过上下文工程的智能体不会仅仅响应查询，而是首先整合用户的日历可用性（工具输出）、与邮件收件人的专业关系（隐性数据）以及先前会议的笔记（检索文档）。这使得模型能够生成高度相关、个性化和实用有用的输出。"工程"组件涉及创建健壮的管道以在运行时获取和转换这些数据，并建立反馈循环以持续改进上下文质量。

为了实施这一点，可以使用专门的调优系统来大规模自动化改进过程。例如，谷歌 Vertex AI 提示优化器等工具可以通过系统地评估针对一组样本输入和预定义评估指标的响应来增强模型性能。这种方法对于适应不同模型的提示和系统指令是有效的，无需大量手动重写。通过向优化器提供样本提示、系统指令和模板，它可以以编程方式优化上下文输入，为实现复杂的上下文工程所需的反馈循环提供了结构化方法。

这种结构化方法是将基本 AI 工具与更复杂的、上下文感知的系统区分开来的方法。它将上下文本身视为主要组件，对智能体知道什么、何时知道以及如何使用这些信息给予关键重要性。该实践确保模型对用户的意图、历史和当前环境有全面的了解。最终，上下文工程是将无状态聊天机器人推进到高度能力强、情境感知系统的关键方法。

### 一览表

**内容**：当在单个提示中处理时，复杂任务经常让 LLMs 不堪重负，导致显著的性能问题。模型的认知负荷增加了忽视指令、丢失上下文和生成错误信息等错误的可能性。单体提示难以有效管理多个约束和顺序推理步骤。这导致不可靠和不准确的输出，因为 LLM 未能处理多方面请求的所有方面。

**原因**：提示链通过将复杂问题分解为一系列更小的、相互关联的子任务提供标准化解决方案。链中的每个步骤使用专注的提示来执行特定操作，显著提高了可靠性和控制性。一个提示的输出作为下一个提示的输入传递，创建逻辑工作流，逐步朝向最终解决方案前进。这种模块化的、分而治之的策略使过程更易管理、更容易调试，并允许在步骤之间集成外部工具或结构化数据格式。

这种模式是开发复杂的、多步骤智能体系统的基础，这些系统能够规划、推理和执行复杂的工作流。

**经验法则**：当任务过于复杂无法在单个提示中处理、涉及多个不同的处理阶段、需要在步骤之间与外部工具交互，或构建需要执行多步推理和维护状态的智能体系统时，使用此模式。

### 视觉摘要

![img_33_0_20251210_191647.png](../images/Agentic%20Design%20Patterns/img_33_0_20251210_191647.png)

图 2：提示链模式：智能体从用户那里接收一系列提示，每个智能体的输出作为链中下一个的输入。

### 关键要点

以下是一些关键要点：

● 提示链将复杂任务分解为一系列更小、专注的步骤。这有时被称为管道模式。
● 链中的每个步骤涉及 LLM 调用或处理逻辑，使用前一步的输出作为输入。
● 此模式提高了与语言模型复杂交互的可靠性和可管理性。
● LangChain/LangGraph 和 Google ADK 等框架提供了强大的工具来定义、管理和执行这些多步骤序列。

### 结论

通过将复杂问题分解为一系列更简单、更易管理的子任务，提示链为引导大型语言模型提供了健壮的框架。这种"分而治之"策略通过一次专注于模型一个特定操作，显著增强了输出的可靠性和控制性。作为一种基础模式，它使能够开发复杂的 AI 智能体，这些智能体能够执行多步推理、工具集成和状态管理。最终，掌握提示链对于构建健壮的、上下文感知的系统至关重要，这些系统能够执行远远超出单个提示能力的复杂工作流。

### 参考文献

1. LangChain LCEL 文档：https://python.langchain.com/v0.2/docs/core_modules/expression_language/
2. LangGraph 文档：https://langchain-ai.github.io/langgraph/
3. 提示工程指南 - 链接提示：https://www.promptingguide.ai/techniques/chaining
4. OpenAI API 文档（一般提示概念）：https://platform.openai.com/docs/guides/gpt/prompting
5. Crew AI 文档（任务和流程）：https://docs.crewai.com/
6. 谷歌 AI 开发者（提示指南）：https://cloud.google.com/discover/what-is-prompt-engineering?hl=en
7. Vertex 提示优化器https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/prompt-optimizer

---

## 第 2 章：路由

### 路由模式概述

虽然通过提示链进行顺序处理是执行确定性、线性语言模型工作流的基础技术，但它在需要自适应响应的场景中的适用性是有限的。现实世界的智能体系统通常必须基于偶然因素（如环境状态、用户输入或先前操作的结果）在多个潜在行动之间进行仲裁。

这种动态决策能力，它控制着流向不同专门功能、工具或子过程的流程，是通过称为路由的机制实现的。

路由将条件逻辑引入智能体的操作框架中，使得能够从固定执行路径转变为模型，在该模型中，智能体动态评估特定标准以从一组可能的后续行动中选择。这允许更灵活和上下文感知的系统行为。

例如，一个设计用于客户咨询的智能体，当配备路由功能时，可以首先分类传入查询以确定用户的意图。基于此分类，然后它可以将查询导向专门智能体进行直接问答、数据库检索工具获取账户信息，或针对复杂问题的升级程序，而不是默认单一、预定的响应路径。

因此，使用路由的更复杂的智能体可以：

1. 分析用户的查询。
2. 基于其意图路由查询：
   - 如果意图是"检查订单状态"，路由到与订单数据库交互的子智能体或工具链。
   - 如果意图是"产品信息"，路由到搜索产品目录的子智能体或链。
   - 如果意图是"技术支持"，路由到访问故障排除指南或升级到人的不同链。
   - 如果意图不明确，路由到澄清子智能体或提示链。

路由模式的核心组件是执行评估并指导流程的机制。这个机制可以通过几种方式实现：

● **基于 LLM 的路由**：语言模型本身可以被提示来分析输入并输出特定的标识符或指令，指示下一步或目的地。例如，提示可能要求 LLM"分析以下用户查询并仅输出类别：'订单状态'、'产品信息'、'技术支持'或'其他'。"然后智能体系统读取此输出并相应地指导工作流。

● **基于嵌入的路由**：输入查询可以转换为向量嵌入（见 RAG，第 14 章）。然后这个嵌入与代表不同路由或能力的嵌入进行比较。查询被路由到其嵌入最相似的路由。这对于语义路由很有用，其中决策基于输入的含义而不仅仅是关键词。

● **基于规则的路由**：这涉及使用预定义的规则或逻辑（例如，if-else 语句，switch cases），基于从输入中提取的关键词、模式或结构化数据。这可以比基于 LLM 的路由更快和更确定，但对于处理细致或新颖的输入灵活性较低。

● **基于机器学习模型的路由**：它采用判别模型，如分类器，该模型已在小的标记数据语料库上进行专门训练以执行路由任务。虽然它与基于嵌入的方法共享概念相似性，但其关键特征是监督微调过程，该过程调整模型的参数以创建专门的路由功能。这种技术与基于 LLM 的路由不同，因为决策组件不是在推理时执行提示的生成模型。相反，路由逻辑编码在微调模型的学习权重中。虽然 LLMs 可能在预处理步骤中使用以生成用于增强训练集的合成数据，但它们不参与实时的路由决策本身。

路由机制可以在智能体操作周期的多个节点实施。它们可以在开始时应用以分类主要任务，在处理链中的中间点以确定后续行动，或在子例程期间从给定集合中选择最合适的工具。

LangChain、LangGraph 和谷歌智能体开发工具包（Google ADK）等计算框架提供了明确定义和管理这种条件逻辑的构造。LangGraph 以其基于状态的图架构，特别适用于复杂路由场景，其中决策取决于整个系统的累积状态。同样，谷歌的 ADK 提供了构建智能体能力和交互模型的基础组件，这些组件作为实施路由逻辑的基础。在这些框架提供的执行环境中，开发人员定义可能的操作路径以及在计算图中指导节点之间转换的函数或基于模型的评估。

路由的实施使得系统能够超越确定性顺序处理。它促进了更具自适应性的执行流的开发，这些流能够动态和适当地响应更广泛的输入和状态变化。

### 实际应用和用例

路由模式是设计自适应智能体系统的关键控制机制，使它们能够根据变量输入和内部状态动态改变其执行路径。它的实用性通过提供必要的条件逻辑层跨越多个领域。

在人机交互中，如虚拟助手或 AI 驱动的导师，路由用于解释用户意图。对自然语言查询的初步分析确定最合适的后续行动，无论是调用特定的信息检索工具、升级到人工操作员，还是基于用户表现选择课程中的下一个模块。这允许系统超越线性对话流并上下文地响应。

在自动化数据和文档处理管道中，路由充当分类和分发功能。传入数据，如电子邮件、支持票据或 API 负载，基于内容、元数据或格式进行分析。然后系统将每个项目导向相应的工作流，如销售潜在客户摄取过程、JSON 或 CSV 格式的特定数据转换功能，或紧急问题升级路径。

在涉及多个专门工具或智能体的复杂系统中，路由充当高级调度器。由用于搜索、总结和分析信息的不同智能体组成的研究系统将使用路由器基于当前目标将任务分配给最合适的智能体。同样，AI 编码助手使用路由来识别编程语言和用户的意图——调试、解释或翻译——然后将代码片段传递给正确的专门工具。

最终，路由提供了逻辑仲裁能力，这对于创建功能多样和上下文感知的系统是必不可少的。它将智能体从预定义序列的静态执行器转变为能够在变化的条件下决定完成任务的最有效方法的动态系统。

### 动手代码示例（LangChain）

在代码中实施路由涉及定义可能的路径和决定采用哪条路径的逻辑。LangChain 和 LangGraph 等框架为此提供了特定的组件和结构。LangGraph 的基于状态的图结构对于可视化和实施路由逻辑特别直观。

这段代码演示了使用 LangChain 和谷歌生成 AI 的简单智能体类系统。它设置了一个"协调器"，根据请求的意图（预订、信息或不明确）将用户请求路由到不同的模拟"子智能体"处理程序。系统使用语言模型对请求进行分类，然后将其委托给适当的处理程序函数，模拟了多智能体架构中常见的基本委托模式。

首先，确保安装了必要的库：

```bash
pip install langchain langgraph google-cloud-aiplatform langchain-google-genai google-adk deprecated pydantic
```

你还需要为你选择的语言模型（例如，OpenAI、谷歌 Gemini、Anthropic）设置你的 API 密钥环境。

```python
# 版权所有 (c) 2025 Marco Fago
# https://www.linkedin.com/in/marco-fago/
#
# 此代码根据MIT许可证授权。
# 有关完整许可证文本，请参见存储库中的LICENSE文件。

from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough, RunnableBranch

# --- 配置 ---

# 确保设置了你的API密钥环境变量（例如，GOOGLE_API_KEY）
try:
    llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0)
    print(f"语言模型已初始化: {llm.model}")
except Exception as e:
    print(f"语言模型初始化错误: {e}")
    llm = None

# --- 定义模拟子智能体处理程序（等同于ADK sub_agents） ---

def booking_handler(request: str) -> str:
    """模拟预订智能体处理请求。"""
    print("\n--- 委托给预订处理程序 ---")
    return f"预订处理程序已处理请求: '{request}'。结果: 模拟预订操作。"

def info_handler(request: str) -> str:
    """模拟信息智能体处理请求。"""
    print("\n--- 委托给信息处理程序 ---")
    return f"信息处理程序已处理请求: '{request}'。结果: 模拟信息检索。"

def unclear_handler(request: str) -> str:
    """处理无法委托的请求。"""
    print("\n--- 处理不明确的请求 ---")
    return f"协调器无法委托请求: '{request}'。请澄清。"

# --- 定义协调器路由链（等同于ADK协调器的指令） ---

# 此链决定委托给哪个处理程序。
coordinator_router_prompt = ChatPromptTemplate.from_messages([
    ("system", """分析用户的请求并确定应该由哪个专门处理程序处理它。
- 如果请求与预订航班或酒店相关，输出 'booker'。
- 对于所有其他一般信息问题，输出 'info'。
- 如果请求不明确或不符合任一类别，输出 'unclear'。
仅输出一个词：'booker'、'info' 或 'unclear'。"""),
    ("user", "{request}")
])

if llm:
    coordinator_router_chain = coordinator_router_prompt | llm | StrOutputParser()

# --- 定义委托逻辑（等同于ADK基于sub_agents的自动流程） ---

# 使用RunnableBranch基于路由链的输出进行路由。

# 为RunnableBranch定义分支
branches = {
    "booker": RunnablePassthrough.assign(output=lambda x: booking_handler(x['request']['request'])),
    "info": RunnablePassthrough.assign(output=lambda x: info_handler(x['request']['request'])),
    "unclear": RunnablePassthrough.assign(output=lambda x: unclear_handler(x['request']['request'])),
}

# 创建RunnableBranch。它接收路由链的输出
# 并将原始输入（'request'）路由到相应的处理程序。
delegation_branch = RunnableBranch(
    (lambda x: x['decision'].strip() == 'booker', branches["booker"]),  # 添加.strip()
    (lambda x: x['decision'].strip() == 'info', branches["info"]),       # 添加.strip()
    branches["unclear"]  # 'unclear'或任何其他输出的默认分支
)

# 将路由链和委托分支组合成单个可运行对象
# 路由链的输出（'decision'）与原始输入（'request'）一起传递
# 给委托分支。
coordinator_agent = {
    "decision": coordinator_router_chain,
    "request": RunnablePassthrough()
} | delegation_branch | (lambda x: x['output'])  # 提取最终输出

# --- 示例用法 ---

def main():
    if not llm:
        print("\n由于LLM初始化失败跳过执行。")
        return

    print("--- 运行预订请求 ---")
    request_a = "为我预订去伦敦的航班。"
    result_a = coordinator_agent.invoke({"request": request_a})
    print(f"最终结果A: {result_a}")

    print("\n--- 运行信息请求 ---")
    request_b = "意大利的首都是什么？"
    result_b = coordinator_agent.invoke({"request": request_b})
    print(f"最终结果B: {result_b}")

    print("\n--- 运行不明确的请求 ---")
    request_c = "告诉我关于量子物理学的知识。"
    result_c = coordinator_agent.invoke({"request": request_c})
    print(f"最终结果C: {result_c}")

if __name__ == "__main__":
    main()
```

如前所述，此 Python 代码使用 LangChain 库和谷歌的生成 AI 模型（特别是 gemini-2.5-flash）构建了一个简单的智能体类系统。详细来说，它定义了三个模拟的子智能体处理程序：booking_handler、info_handler 和 unclear_handler，每个都设计用于处理特定类型的请求。

核心组件是 coordinator_router_chain，它利用 ChatPromptTemplate 指示语言模型将传入的用户请求分类为三个类别之一：'booker'、'info'或'unclear'。然后这个路由链的输出被 RunnableBranch 使用，将原始请求委托给相应的处理程序函数。RunnableBranch 检查来自语言模型的决策，并将请求数据导向 booking_handler、info_handler 或 unclear_handler。

coordinator_agent 结合了这些组件，首先路由请求以进行决策，然后将请求传递给选定的处理程序。最终输出从处理程序的响应中提取。main 函数演示了系统如何处理三个示例请求，展示了不同的输入如何被模拟智能体路由和处理。包含语言模型初始化的错误处理以确保健壮性。代码结构模拟了一个基本的多智能体框架，其中中央协调器基于意图将任务委托给专门的智能体。

### 动手代码示例（Google ADK）

智能体开发工具包（ADK）是一个用于工程智能体系统的框架，提供了定义智能体能力和行为的结构化环境。与基于显式计算图的架构相比，ADK 范式中的路由通常通过定义代表智能体功能的离散"工具"集来实现。响应于用户查询选择合适工具由框架的内部逻辑管理，该逻辑利用底层模型将用户意图与正确的功能处理程序匹配。

此 Python 代码演示了使用谷歌 ADK 库的智能体开发工具包（ADK）应用程序示例。它设置了一个"协调器"智能体，根据定义的指令将用户请求路由到专门的子智能体（"Booker"用于预订，"Info"用于一般信息）。然后子智能体使用特定工具模拟处理请求，展示了智能体系统内的基本委托模式。

```python
# 版权所有 (c) 2025 Marco Fago
#
# 此代码根据MIT许可证授权。
# 有关完整许可证文本，请参见存储库中的LICENSE文件。

import uuid
from typing import Dict, Any, Optional
from google.adk.agents import Agent
from google.adk.runners import InMemoryRunner
from google.adk.tools import FunctionTool
from google.genai import types
from google.adk.events import Event

# --- 定义工具函数 ---

# 这些函数模拟专门智能体的操作。

def booking_handler(request: str) -> str:
    """
    处理航班和酒店的预订请求。
    参数:
        request: 用户的预订请求。
    返回:
        确认已处理预订的消息。
    """
    print("-------------------------- 预订处理程序被调用 ---------------------------")
    return f"已模拟对 '{request}' 的预订操作。"

def info_handler(request: str) -> str:
    """
    处理一般信息请求。
    参数:
        request: 用户的问题。
    返回:
        表示已处理信息请求的消息。
    """
    print("-------------------------- 信息处理程序被调用 ---------------------------")
    return f"已处理对 '{request}' 的信息请求。结果：模拟信息检索。"

def unclear_handler(request: str) -> str:
    """处理无法委托的请求。"""
    return f"协调器无法委托请求: '{request}'。请澄清。"

# --- 从函数创建工具 ---

booking_tool = FunctionTool(booking_handler)
info_tool = FunctionTool(info_handler)

# 定义配备各自工具的专门子智能体
booking_agent = Agent(
    name="Booker",
    model="gemini-2.0-flash",
    description="通过调用预订工具处理所有航班和酒店预订请求的专门智能体。",
    tools=[booking_tool]
)

info_agent = Agent(
    name="Info",
    model="gemini-2.0-flash",
    description="通过调用信息工具提供一般信息并回答用户问题的专门智能体。",
    tools=[info_tool]
)

# 使用显式委托指令定义父智能体
coordinator = Agent(
    name="Coordinator",
    model="gemini-2.0-flash",
    instruction=(
        "你是主协调器。你的唯一任务是分析传入的用户请求 "
        "并将它们委托给适当的专门智能体。不要尝试直接回答用户。\n"
        "- 对于与预订航班或酒店相关的任何请求，委托给'Booker'智能体。\n"
        "- 对于所有其他一般信息问题，委托给'Info'智能体。"
    ),
    description="将用户请求路由到正确专门智能体的协调器。",

    # sub_agents的存在启用了LLM驱动的委托（自动流程）默认。
    sub_agents=[booking_agent, info_agent]
)

# --- 执行逻辑 ---

async def run_coordinator(runner: InMemoryRunner, request: str):
    """使用给定请求运行协调器智能体并委托。"""
    print(f"\n--- 使用请求运行协调器: '{request}' ---")
    final_result = ""
    try:
        user_id = "user_123"
        session_id = str(uuid.uuid4())
        await runner.session_service.create_session(
            app_name=runner.app_name,
            user_id=user_id,
            session_id=session_id
        )

        for event in runner.run(
            user_id=user_id,
            session_id=session_id,
            new_message=types.Content(
                role='user',
                parts=[types.Part(text=request)]
            ),
        ):
            if event.is_final_response() and event.content:
                # 尝试直接从event.content获取文本
                # 以避免迭代部分
                if hasattr(event.content, 'text') and event.content.text:
                    final_result = event.content.text
                elif event.content.parts:
                    # 回退：迭代部分并提取文本（可能触发警告）
                    text_parts = [part.text for part in event.content.parts if part.text]
                    final_result = "".join(text_parts)

                # 假设循环应该在最终响应后中断
                break

        print(f"协调器最终响应: {final_result}")
        return final_result
    except Exception as e:
        print(f"处理你的请求时发生错误: {e}")
        return f"处理你的请求时发生错误: {e}"

async def main():
    """运行ADK示例的主函数。"""
    print("--- 谷歌ADK路由示例（ADK自动流程风格） ---")
    print("注意：这需要安装和验证谷歌ADK。")
    runner = InMemoryRunner(coordinator)

    # 示例用法
    result_a = await run_coordinator(runner, "为我在巴黎预订酒店。")
    print(f"最终输出A: {result_a}")

    result_b = await run_coordinator(runner, "世界上最高的山是什么？")
    print(f"最终输出B: {result_b}")

    result_c = await run_coordinator(runner, "告诉我一个随机的事实。")  # 应该去Info
    print(f"最终输出C: {result_c}")

    result_d = await run_coordinator(runner, "查找下个月去东京的航班。")  # 应该去Booker
    print(f"最终输出D: {result_d}")

if __name__ == "__main__":
    import nest_asyncio
    nest_asyncio.apply()
    await main()
```

此脚本由一个主协调器智能体和两个专门的子智能体组成：Booker 和 Info。每个专门智能体都配备了一个 FunctionTool，它包装了一个模拟操作的 Python 函数。booking_handler 函数模拟处理航班和酒店预订，而 info_handler 函数模拟检索一般信息。虽然当前的协调器逻辑在 main run_coordinator 函数中没有明确使用 unclear_handler 进行委托失败，但它作为协调器无法委托的请求的回退包含在内。

协调器智能体的主要角色，如其指令中所定义的，是分析传入的用户消息并将它们委托给 Booker 或 Info 智能体。由于协调器定义了 sub_agents，这种委托由 ADK 的自动流程机制自动处理。run_coordinator 函数设置一个 InMemoryRunner，创建用户和会话 ID，然后使用 runner 通过协调器智能体处理用户的请求。runner.run 方法处理请求并产生事件，代码从 event.content 中提取最终响应文本。

main 函数通过使用不同的请求运行协调器来演示系统的用法，展示了它如何将预订请求委托给 Booker，将信息请求委托给 Info 智能体。

### 一览表

**内容**：智能体系统通常必须响应各种无法由单一、线性过程处理的输入和情况。简单的顺序工作流缺乏基于上下文做出决策的能力。没有机制为特定任务选择正确的工具或子过程，系统保持刚性和非适应性。这种限制使得构建能够管理现实世界用户请求的复杂性和可变性的复杂应用程序变得困难。

**原因**：路由模式通过将条件逻辑引入智能体的操作框架提供标准化解决方案。它使系统能够首先分析传入查询以确定其意图或性质。基于此分析，智能体动态地将控制流引导到最合适的专门工具、函数或子智能体。这个决策可以由各种方法驱动，包括提示 LLMs、应用预定义规则或使用基于嵌入的语义相似性。

最终，路由将静态、预定的执行路径转变为能够选择最佳可能的行动的灵活和上下文感知的工作流。

**经验法则**：当智能体必须基于用户输入或当前状态在多个不同的工作流、工具或子智能体之间做出决定时，使用路由模式。对于需要分类或分类传入请求以处理不同类型任务的应用程序（如区分销售咨询、技术支持和账户管理问题的客户支持机器人）来说，它是必不可少的。

### 视觉摘要：

![img_47_0_20251210_191647.png](../images/Agentic%20Design%20Patterns/img_47_0_20251210_191647.png)

图 1：路由器模式，使用 LLM 作为路由器

### 关键要点

● 路由使智能体能够基于条件做出关于工作流中下一步的动态决策。
● 它允许智能体处理多样化输入并调整其行为，超越线性执行。
● 路由逻辑可以使用 LLMs、基于规则的系统或嵌入相似性来实施。
● LangGraph 和谷歌 ADK 等框架提供了在智能体工作流内定义和管理路由的结构化方法，尽管采用不同的架构方法。

### 结论

路由模式是构建真正动态和响应式智能体系统的关键步骤。通过实施路由，我们超越了简单的线性执行流，并使我们的智能体能够就如何处理信息、响应用户输入以及利用可用工具或子智能体做出智能决策。

我们已经看到路由如何应用于各个领域，从客户服务聊天机器人到复杂的数据处理管道。分析输入并有条件地指导工作流的能力是创建能够处理现实世界任务固有可变性的智能体的基础。

使用 LangChain 和谷歌 ADK 的代码示例展示了两种不同但有效的路由实施方法。LangGraph 的基于图的结构提供了定义状态和转换的视觉化和显式方式，使其成为具有复杂路由逻辑的复杂、多步骤工作流的理想选择。另一方面，谷歌 ADK 通常专注于定义不同的能力（工具），并依赖框架将用户请求路由到适当的工具处理程序，这对于具有明确定义的离散操作集的智能体来说可能更简单。

掌握路由模式对于构建能够智能地导航不同场景并基于上下文提供定制响应或行动的智能体至关重要。它是创建多功能和健壮的智能体应用程序的关键组成部分。

### 参考文献

1. LangGraph 文档：https://www.langchain.com/
2. 谷歌智能体开发工具包文档：https://google.github.io/adk-docs/

---

## 第 3 章：并行化

### 并行化模式概述

在之前的章节中，我们探讨了用于顺序工作流的提示链和用于动态决策以及在不同路径之间转换的路由。虽然这些模式是必不可少的，但许多复杂的智能体任务涉及可以同时而不是一个接一个地执行的多个子任务。这就是并行化模式变得至关重要的地方。

并行化涉及并发执行多个组件，如 LLM 调用、工具使用，甚至整个子智能体（见图 1）。而不是等待一个步骤完成后再开始下一个，并行执行允许独立任务同时运行，显著减少了可以分解为独立部分的任务的总体执行时间。

考虑一个设计用于研究主题并总结其发现的智能体。顺序方法可能：

1. 搜索来源 A。
2. 总结来源 A。
3. 搜索来源 B。
4. 总结来源 B。
5. 根据总结 A 和 B 综合最终答案。

并行方法可以：

1. 同时搜索来源 A 和来源 B。
2. 两个搜索完成后，同时总结来源 A 和来源 B。
3. 根据总结 A 和 B 综合最终答案（此步骤通常是顺序的，等待并行步骤完成）。

核心思想是识别工作流中不依赖于其他部分输出的部分并并行执行它们。这在处理具有延迟的外部服务（如 API 或数据库）时特别有效，因为你可以并发发出多个请求。

实施并行化通常需要支持异步执行或多线程/多处理的框架。现代智能体框架在设计时就考虑了异步操作，允许你轻松定义可以并行运行的步骤。

![img_50_0_20251210_191647.png](../images/Agentic%20Design%20Patterns/img_50_0_20251210_191647.png)

图 1. 与子智能体并行化的示例

LangChain、LangGraph 和谷歌 ADK 等框架提供了并行执行的机制。在 LangChain 表达式语言（LCEL）中，你可以通过使用|（用于顺序）等运算符组合可运行对象，以及构建具有并发执行分支的链或图来实现并行执行。

LangGraph 凭借其图结构，允许你定义可以从单个状态转换执行的多个节点，有效地在工作流中启用并行分支。谷歌 ADK 提供了强大、原生的机制来促进和管理智能体的并行执行，显著增强了复杂、多智能体系统的效率和可扩展性。ADK 框架内的这种固有能力使开发人员能够设计和实现多个智能体可以并发而不是顺序操作的解决方案。

并行化模式对于提高智能体系统的效率和响应性至关重要，特别是在涉及多个独立查找、计算或与外部服务交互的任务中。它是优化复杂智能体工作流性能的关键技术。

### 实际应用和用例

并行化是跨各种应用程序优化智能体性能的强大模式：

1. **信息收集和研究**：
   同时从多个源收集信息是经典用例。

   - **用例**：研究公司的智能体。
   - **并行任务**：同时搜索新闻文章、提取股票数据、检查社交媒体提及和查询公司数据库。
   - **好处**：比顺序查找更快地收集全面视图。

2. **数据处理和分析**：
   并发应用不同的分析技术或处理不同的数据段。

   - **用例**：分析客户反馈的智能体。
   - **并行任务**：对一批反馈条目同时运行情感分析、提取关键词、分类反馈和识别紧急问题。
   - **好处**：快速提供多方面分析。

3. **多 API 或工具交互**：
   调用多个独立的 API 或工具以收集不同类型的信息或执行不同的操作。

   - **用例**：旅行规划智能体。
   - **并行任务**：同时检查航班价格、搜索酒店可用性、查找当地事件和寻找餐厅推荐。
   - **好处**：更快地呈现完整的旅行计划。

4. **多组件内容生成**：
   并行生成复杂内容的不同部分。

   - **用例**：创建营销电子邮件的智能体。
   - **并行任务**：同时生成主题行、起草电子邮件正文、查找相关图像和创建行动号召按钮文本。
   - **好处**：更高效地组装最终电子邮件。

5. **验证和验证**：
   并发执行多个独立的检查或验证。

   - **用例**：验证用户输入的智能体。
   - **并行任务**：同时检查电子邮件格式、验证电话号码、对照数据库验证地址和检查亵渎内容。
   - **好处**：提供关于输入有效性的更快反馈。

6. **多模态处理**：
   并发处理相同输入的不同模态（文本、图像、音频）。

   - **用例**：分析带有文本和图像的社交媒体帖子的智能体。
   - **并行任务**：同时分析文本的情感和关键词，以及分析图像的对象和场景描述。
   - **好处**：更快地整合来自不同模态的洞察。

7. **A/B 测试或多选项生成**：
   并行生成响应或输出的多个变体以选择最佳的一个。
   - **用例**：生成不同创意文本选项的智能体。
   - **并行任务**：使用略有不同的提示或模型同时为一篇文章生成三个不同的标题。
   - **好处**：允许快速比较和选择最佳选项。

并行化是智能体设计中的基本优化技术，使开发人员能够通过利用独立任务的并发执行来构建更高性能和响应能力的应用程序。

### 动手代码示例（LangChain）

LangChain 框架内的并行执行由 LangChain 表达式语言（LCEL）促进。主要方法涉及在字典或列表构造中构建多个可运行组件。当此集合作为输入传递给链中的后续组件时，LCEL 运行时并发执行包含的可运行对象。

在 LangGraph 的上下文中，此原则应用于图的拓扑结构。通过构建图使得多个节点在缺乏直接顺序依赖性的情况下可以从单个公共节点启动来定义并行工作流。这些并行路径在它们的结果可以在图中后续汇聚点聚合之前独立执行。

以下实现演示了使用 LangChain 框架构建的并行处理工作流。此工作流设计为响应单个用户查询并发执行两个独立操作。这些并行过程被实例化为不同的链或函数，它们各自的输出随后被聚合成统一的结果。

此实现的先决条件包括安装必需的 Python 包，如 langchain、langchain-community 和模型提供程序库（如 langchain-openai）。此外，必须在本地环境中配置所选语言模型的有效 API 密钥以进行身份验证。

```python
import os
import asyncio
from typing import Optional
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import Runnable, RunnableParallel, RunnablePassthrough

# --- 配置 ---

# 确保设置了你的API密钥环境变量（例如，OPENAI_API_KEY）
try:
    llm: Optional[ChatOpenAI] = ChatOpenAI(model="gpt-4o-mini", temperature=0.7)
except Exception as e:
    print(f"语言模型初始化错误: {e}")
    llm = None

# --- 定义独立链 ---

# 这三个链代表可以并行执行的不同任务。
summarize_chain: Runnable = (
    ChatPromptTemplate.from_messages([
        ("system", "简洁地总结以下主题:"),
        ("user", "{topic}")
    ])
    | llm
    | StrOutputParser()
)

questions_chain: Runnable = (
    ChatPromptTemplate.from_messages([
        ("system", "为以下主题生成三个有趣的问题:"),
        ("user", "{topic}")
    ])
    | llm
    | StrOutputParser()
)

terms_chain: Runnable = (
    ChatPromptTemplate.from_messages([
        ("system", "从以下主题中识别5-10个关键术语，用逗号分隔:"),
        ("user", "{topic}")
    ])
    | llm
    | StrOutputParser()
)

# --- 构建并行 + 综合链 ---

# 1. 定义要并行运行的任务块。这些的结果，
#    连同原始主题，将被馈送到下一步。
map_chain = RunnableParallel({
    "summary": summarize_chain,
    "questions": questions_chain,
    "key_terms": terms_chain,
    "topic": RunnablePassthrough(),  # 传递原始主题
})

# 2. 定义将结合并行结果的最终综合提示。
synthesis_prompt = ChatPromptTemplate.from_messages([
    ("system", """基于以下信息:
总结: {summary}
相关问题: {questions}
关键术语: {key_terms}
综合一个全面的答案。"""),
    ("user", "原始主题: {topic}")
])

# 3. 通过将并行结果直接管道传输
#    到综合提示，然后是LLM和输出解析器来构建完整链。
full_parallel_chain = map_chain | synthesis_prompt | llm | StrOutputParser()

# --- 运行链 ---

async def run_parallel_example(topic: str) -> None:
    """
    使用特定主题异步调用并行处理链并打印综合结果。
    参数:
        topic: 要由LangChain链处理的输入主题。
    """
    if not llm:
        print("LLM未初始化。无法运行示例。")
        return

    print(f"\n--- 主题的并行LangChain示例: '{topic}' ---")
    try:
        # `ainvoke`的输入是单个'topic'字符串，
        # 然后传递给`map_chain`中的每个可运行对象。
        response = await full_parallel_chain.ainvoke(topic)
        print("\n--- 最终响应 ---")
        print(response)
    except Exception as e:
        print(f"\n链执行期间发生错误: {e}")

if __name__ == "__main__":
    test_topic = "太空探索的历史"

    # 在Python 3.7+中，asyncio.run是运行异步函数的标准方式。
    asyncio.run(run_parallel_example(test_topic))
```

提供的 Python 代码实现了一个设计为通过利用并行执行来高效处理给定主题的 LangChain 应用程序。注意，asyncio 提供并发性，而不是并行性。它通过使用事件循环在任务空闲时（例如，等待网络请求）智能地在任务之间切换来实现这一点。这产生了多个任务同时进行的效果，但代码本身仍然只由一个线程执行，受到 Python 的全局解释器锁（GIL）的限制。

代码通过导入 langchain_openai 和 langchain_core 中的基本模块开始，包括语言模型、提示、输出解析和可运行结构的组件。代码尝试初始化一个 ChatOpenAI 实例，特别是使用"gpt-4o-mini"模型，并指定温度来控制创造性。在语言模型初始化期间使用 try-except 块以确保健壮性。

然后定义了三个独立的 LangChain"链"，每个都设计用于对输入主题执行不同的任务。第一个链用于简洁地总结主题，使用系统消息和包含主题占位符的用户消息。第二个链配置为生成与主题相关的三个有趣问题。第三个链设置为从输入主题中识别 5 到 10 个关键术语，要求它们用逗号分隔。

这些独立链中的每一个都包括为其特定任务定制的 ChatPromptTemplate，后跟初始化的语言模型和 StrOutputParser 以将输出格式化为字符串。

然后构建一个 RunnableParallel 块来捆绑这三个链，允许它们同时执行。这个并行可运行对象还包括一个 RunnablePassthrough，以确保原始输入主题可用于后续步骤。

为最终综合步骤定义了单独的 ChatPromptTemplate，将总结、问题、关键术语和原始主题作为输入以生成全面的答案。

名为 full_parallel_chain 的端到端处理链通过将 map_chain（并行块）排序到综合提示中，后跟语言模型和输出解析器来创建。提供了一个异步函数 run_parallel_example 来演示如何调用此 full_parallel_chain。此函数接受主题作为输入并使用 ainvoke 来运行异步链。

最后，标准的 Python if **name** == "**main**":块显示如何使用 asyncio.run 执行带有样本主题的 run_parallel_example，在本例中是"太空探索的历史"，以管理异步执行。

本质上，此代码设置了一个工作流，其中多个 LLM 调用（用于总结、问题和术语）针对给定主题同时发生，然后它们的结果由最终 LLM 调用组合。这展示了在智能体工作流中使用 LangChain 进行并行化的核心思想。

### 动手代码示例（Google ADK）

好的，现在让我们转向谷歌 ADK 框架内说明这些概念的具体示例。我们将研究如何应用 ADK 原语，如 ParallelAgent 和 SequentialAgent，来构建利用并发执行以提高效率的智能体流。

```python
from google.adk.agents import LlmAgent, ParallelAgent, SequentialAgent
from google.adk.tools import google_search

GEMINI_MODEL="gemini-2.0-flash"

# --- 1. 定义研究子智能体（并行运行） ---

# 研究员1：可再生能源
researcher_agent_1 = LlmAgent(
    name="RenewableEnergyResearcher",
    model=GEMINI_MODEL,
    instruction="""你是一个专门研究能源的AI研究助手。研究'可再生能源'的最新进展。使用提供的谷歌搜索工具。简洁地总结你的关键发现（1-2句话）。仅输出总结。""",
    description="研究可再生能源。",
    tools=[google_search],

    # 在状态中存储结果供合并智能体使用
    output_key="renewable_energy_result"
)

# 研究员2：电动汽车
researcher_agent_2 = LlmAgent(
    name="EVResearcher",
    model=GEMINI_MODEL,
    instruction="""你是一个专门研究交通的AI研究助手。研究'电动汽车技术'的最新发展。使用提供的谷歌搜索工具。简洁地总结你的关键发现（1-2句话）。仅输出总结。""",
    description="研究电动汽车技术。",
    tools=[google_search],

    # 在状态中存储结果供合并智能体使用
    output_key="ev_technology_result"
)

# 研究员3：碳捕获
researcher_agent_3 = LlmAgent(
    name="CarbonCaptureResearcher",
    model=GEMINI_MODEL,
    instruction="""你是一个专门研究气候解决方案的AI研究助手。研究'碳捕获方法'的现状。使用提供的谷歌搜索工具。简洁地总结你的关键发现（1-2句话）。仅输出总结。""",
    description="研究碳捕获方法。",
    tools=[google_search],

    # 在状态中存储结果供合并智能体使用
    output_key="carbon_capture_result"
)

# --- 2. 创建ParallelAgent（并发运行研究员） ---

# 此智能体协调研究员的并发执行。
# 一旦所有研究员完成并将结果存储在状态中，它就完成。
parallel_research_agent = ParallelAgent(
    name="ParallelWebResearchAgent",
    sub_agents=[researcher_agent_1, researcher_agent_2, researcher_agent_3],
    description="并行运行多个研究智能体以收集信息。"
)

# --- 3. 定义合并智能体（在并行智能体之后运行） ---

# 此智能体获取并行智能体存储在会话状态中的结果
# 并将它们合成为单个、结构化的响应，并注明出处。
merger_agent = LlmAgent(
    name="SynthesisAgent",
    model=GEMINI_MODEL,  # 或者如果需要更强大的模型用于综合
    instruction="""你是一个负责将研究结果组合成结构化报告的AI助手。你的主要任务是综合以下研究摘要，
明确地将发现归因于其源领域。使用每个主题的标题来构建你的响应。
确保报告连贯并平滑地整合关键点。

**关键：你的整个响应必须完全基于下面'输入摘要'中提供的信息。不要添加任何外部知识或进行超出所提供文本的综合。使用以下格式：
## 可再生能源
[来自renewable_energy_result的信息]

## 电动汽车
[来自ev_technology_result的信息]

## 碳捕获
[来自carbon_capture_result的信息]""",
    description="综合并行研究结果。",

    # 注意：这个智能体不需要工具，它只处理来自状态的信息
)

# --- 4. 创建SequentialAgent来组织整个工作流 ---

# 首先运行并行研究，然后运行合并智能体。
full_research_workflow = SequentialAgent(
    name="FullResearchWorkflow",
    sub_agents=[parallel_research_agent, merger_agent],
    description="运行并行研究，然后综合结果。"
)
```

这个 ADK 示例展示了如何通过并行执行来提高研究效率。系统创建三个专门的研究员，每个专注于不同的领域（可再生能源、电动汽车、碳捕获），并同时运行它们以收集信息。一旦所有研究员完成他们的搜索，合并智能体将他们的发现整合成一个连贯的报告。

这种方法展示了并行化的核心优势：通过让独立的研究任务同时运行，系统可以显著快于顺序执行每个任务的方式收集全面的信息。

### 一览表

**内容**：顺序处理可能效率低下，特别是当每个步骤都涉及等待外部系统（如 API 调用）时。当不同任务不依赖于彼此时，一个接一个地执行它们会浪费宝贵的时间和资源。这种线性方法限制了系统的吞吐量，使其在处理大量独立操作时表现不佳。

**原因**：并行化模式通过同时执行多个独立的任务来解决这个低效率问题。而不是等待一个任务完成后再开始下一个，系统启动多个任务，让它们并发运行。这显著减少了完成一组独立任务所需的总时间，因为等待时间被重叠和最小化。该模式在涉及网络请求、数据库查询或其他 I/O 密集型操作的场景中特别有效。

**经验法则**：当你有多个独立的任务可以同时执行而不会相互干扰时使用并行化。这对于信息收集、数据处理、多 API 调用或任何涉及等待外部响应的任务特别有用。

### 关键要点

● 并行化通过并发执行独立任务来显著减少总执行时间。
● 它在处理 I/O 密集型操作（如 API 调用、数据库查询）时特别有效。
● 现代智能体框架（LangChain、LangGraph、谷歌 ADK）提供了内置的并行执行支持。
● 识别可以并行运行的任务部分是有效实施此模式的关键。

### 结论

并行化模式是优化智能体系统性能的基本技术。通过识别和并发执行独立任务，我们可以显著减少总体执行时间并提高系统效率。

该模式特别有价值，当处理涉及多个外部交互、数据处理或信息收集任务时。正如我们所见，现代智能体框架如 LangChain 和谷歌 ADK 提供了强大的原语来使并行化更容易实施。

在构建响应式和高效智能体时，掌握并行化对于创建能够在合理时间内处理复杂、多方面任务的系统至关重要。
